{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))\n",
    "w_lya = 1215.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(regname):\n",
    "    '''\n",
    "    The initial features are:\n",
    "    - The fluxes of the first 53 NBs\n",
    "    - The errors of the first 53 NBs\n",
    "    - 4 BB fluxes\n",
    "    - 4 BB errors\n",
    "    - The estimated L\n",
    "    - The estimated z\n",
    "    TOTAL = 120 features\n",
    "    (PCA to be applied below)\n",
    "    '''\n",
    "\n",
    "    # The data set is the nice_lya sample\n",
    "    NNdata = pd.read_csv(f'MLmodels/datasets/dataset_{regname}_train.csv').to_numpy()[:, 1:]\n",
    "    NNdata_L_input = pd.read_csv(f'MLmodels/datasets/tags_{regname}_train.csv').to_numpy()[:, 1:]\n",
    "    NNdata_L_Arr = pd.read_csv(f'MLmodels/datasets/dataset_{regname}_test.csv').to_numpy()[:, -2].reshape(-1,)\n",
    "    NNdata_test = pd.read_csv(f'MLmodels/datasets/dataset_{regname}_test.csv').to_numpy()[:, 1:]\n",
    "    NNlabels_test = pd.read_csv(f'MLmodels/datasets/tags_{regname}_test.csv').to_numpy()[:, 1:]\n",
    "    print(NNdata_test.shape)\n",
    "\n",
    "    # Take the relative fluxes to the selected one\n",
    "    NB_lya_position = NB_z(NNdata[:, -1].reshape(-1,))\n",
    "    for i, nb in enumerate(NB_lya_position - 2):\n",
    "        NNdata[i, :53] = (\n",
    "            flux_to_mag(NNdata[i, :53], w_central[:53])\n",
    "            - flux_to_mag(NNdata[i, :53][nb - 2], w_central[nb - 2])\n",
    "        )\n",
    "        NNdata[i, 53 : 53 + 4] = flux_to_mag(NNdata[i, 53 : 53 + 4], w_central[-4:])\n",
    "    NB_lya_position = NB_z(NNdata_test[:, -1].reshape(-1,))\n",
    "    for i, nb in enumerate(NB_lya_position - 2):\n",
    "        NNdata_test[i, :53] = (\n",
    "            flux_to_mag(NNdata_test[i, :53], w_central[:53])\n",
    "            - flux_to_mag(NNdata_test[i, :53][nb - 2], w_central[nb - 2])\n",
    "        )\n",
    "        NNdata_test[i, 53 : 53 + 4] = flux_to_mag(NNdata_test[i, 53 : 53 + 4], w_central[-4:])\n",
    "\n",
    "    # NNdata = np.hstack(\n",
    "    #     [\n",
    "    #         NNdata[:, 2:55],\n",
    "    #         NNdata[:, 55 : 55 + 4],\n",
    "    #         NNdata[:, 55 + 4 + 2:]\n",
    "    #     ]\n",
    "    # )\n",
    "    \n",
    "    print(NNdata_test.shape)\n",
    "\n",
    "    N_sources_NN = NNdata.shape[0]\n",
    "\n",
    "    # Shuffle data\n",
    "    # shuffle_idx = np.random.permutation(np.arange(N_sources_NN))\n",
    "    shuffle_idx = np.arange(N_sources_NN)\n",
    "    NNdata = NNdata[shuffle_idx]\n",
    "\n",
    "    NNdata_L_input = NNdata_L_input[shuffle_idx].reshape(-1,)\n",
    "    NNdata_L_input[np.isnan(NNdata_L_input)] = 0\n",
    "    NNdata_is_qso = np.ones(N_sources_NN).astype(bool)\n",
    "    NNdata_is_qso[int(N_sources_NN / 2):] = False\n",
    "    NNdata_is_qso = NNdata_is_qso[shuffle_idx]\n",
    "\n",
    "    # Take logs\n",
    "    # NNdata[:, :53 + 4] = np.log10(NNdata[:, :53 + 4])\n",
    "    NNdata[~np.isfinite(NNdata)] = 0\n",
    "    # NNdata[NNdata > 99.] = 99.\n",
    "\n",
    "    # NNdata_test[:, :53 + 4] = np.log10(NNdata_test[:, :53 + 4])\n",
    "    NNdata_test[~np.isfinite(NNdata_test)] = 0\n",
    "    # NNdata_test[NNdata_test > 99.] = 99.\n",
    "\n",
    "    # Rescale data\n",
    "    mms = MinMaxScaler()\n",
    "    mms.fit(NNdata_test)\n",
    "    NNdata = mms.transform(NNdata)\n",
    "    NNdata_test = mms.transform(NNdata_test)\n",
    "    with open(f'MLmodels/RF{regname}_QSO-SF_scaler.sav', 'wb') as file:\n",
    "        pickle.dump(mms, file)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=0.95, svd_solver='full')\n",
    "\n",
    "    pca.fit(NNdata_test)\n",
    "    with open(f'MLmodels/RF{regname}_QSO-SF_pca.sav', 'wb') as file:\n",
    "        pickle.dump(pca, file)\n",
    "    NNdata = pca.transform(NNdata)\n",
    "    NNdata_test = pca.transform(NNdata_test)\n",
    "\n",
    "    NNdata_train = NNdata\n",
    "    NNlabels_train = NNdata_L_input\n",
    "\n",
    "    NNlabels_train = NNlabels_train.reshape(-1,)\n",
    "    NNlabels_test = NNlabels_test.reshape(-1,)\n",
    "\n",
    "    return NNdata_L_input, NNdata_train, NNdata_test, NNlabels_train, NNlabels_test, NNdata_L_Arr\n",
    "\n",
    "# regname = 'mag23-24'\n",
    "# NNdata_L_input, NNdata_train, NNdata_test, NNlabels_train, NNlabels_test, NNdata_L_Arr = prepare_dataset(regname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search(NNdata_test, NNlabels_test):\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    param_grid = {\n",
    "        'bootstrap': [False],\n",
    "        'max_depth': [80, 100, 125],\n",
    "        'max_features': [0.3],\n",
    "        'min_samples_leaf': [3, 4, 5, 6, 7, 8],\n",
    "        'min_samples_split': [3, 4, 5, 6, 7, 10, 20, 40, 50],\n",
    "        'n_estimators': [100]\n",
    "    }\n",
    "    # Create a based model\n",
    "    rf = RandomForestRegressor()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf, param_grid=param_grid, \n",
    "        cv=KFold(3), n_jobs=-1, pre_dispatch='2*n_jobs',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(NNdata_test, NNlabels_test)\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "# best_params = do_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_and_train(regname):\n",
    "    print(f'#### {regname} ####')\n",
    "    _, NNdata_train, NNdata_test, NNlabels_train, NNlabels_test, _ = prepare_dataset(regname)\n",
    "    \n",
    "    best_params = do_grid_search(NNdata_test, NNlabels_test)\n",
    "\n",
    "    print('Best params:')\n",
    "    print(best_params)\n",
    "\n",
    "    reg = RandomForestRegressor(**best_params)\n",
    "    reg.set_params(n_estimators=400, n_jobs=-1)\n",
    "    reg.fit(NNdata_test, NNlabels_test)\n",
    "\n",
    "    NNdata_test_raw = pd.read_csv(f'MLmodels/datasets/dataset_{regname}_test.csv').to_numpy()[:, 1:]\n",
    "\n",
    "    test_mag = flux_to_mag(NNdata_test_raw[:, 56], 6750)\n",
    "    test_mask = (test_mag < 25)\n",
    "\n",
    "    print(f'Test score = {reg.score(NNdata_test[test_mask], NNlabels_test[test_mask])}')\n",
    "    print(f'Train score = {reg.score(NNdata_train, NNlabels_train)}')\n",
    "\n",
    "    with open(f'MLmodels/RF{regname}_QSO-SF_regressor.sav', 'wb') as file:\n",
    "        pickle.dump(reg, file)\n",
    "\n",
    "grid_search_and_train('mag15-23')\n",
    "grid_search_and_train('mag23-23.5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
