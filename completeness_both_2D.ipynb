{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from my_functions import *\n",
    "from LF_puricomp_corrections import puricomp2d_weights\n",
    "\n",
    "import glob\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))\n",
    "w_lya = 1215.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load my QSO catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/QSO_100000/data.csv'\n",
    "data_qso = pd.read_csv(filename)\n",
    "\n",
    "qso_flx = data_qso.to_numpy()[:, 1 : 60 + 1].T\n",
    "qso_err = data_qso.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "EW_qso = data_qso['EW0'].to_numpy()\n",
    "qso_zspec = data_qso['z'].to_numpy()\n",
    "\n",
    "Lya_fts = pd.read_csv('csv/Lya_fts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SF catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/LAE_10deg_z2-4/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "sf_flx = data.to_numpy()[:, 1 : 60 + 1].T\n",
    "sf_err = data.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "EW_sf = data['EW0'].to_numpy()\n",
    "sf_zspec = data['z'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_flx = np.hstack((qso_flx, sf_flx))\n",
    "pm_err = np.hstack((qso_err, sf_err))\n",
    "zspec = np.concatenate((qso_zspec, sf_zspec))\n",
    "EW_lya = np.concatenate((EW_qso, EW_sf))\n",
    "\n",
    "N_sf = sf_flx.shape[1]\n",
    "N_qso = qso_flx.shape[1]\n",
    "\n",
    "qso_dL = cosmo.luminosity_distance(qso_zspec).to(u.cm).value\n",
    "sf_dL = cosmo.luminosity_distance(sf_zspec).to(u.cm).value\n",
    "\n",
    "sf_L = data['L_lya'].to_numpy()\n",
    "\n",
    "sf_flambda = 10 ** sf_L / (4*np.pi * sf_dL **2)\n",
    "qso_flambda = Lya_fts.LyaF * 1e-17\n",
    "\n",
    "qso_flambda_relerr = Lya_fts.LyaF_err * 1e-17 / qso_flambda\n",
    "\n",
    "qso_L = np.log10(qso_flambda * 4*np.pi * qso_dL ** 2)\n",
    "\n",
    "L_lya = np.concatenate((qso_L, sf_L))\n",
    "fline = np.concatenate((qso_flambda, sf_flambda))\n",
    "\n",
    "is_qso = np.concatenate((np.ones(N_qso), np.zeros(N_sf))).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel sf_flx\n",
    "%xdel sf_err\n",
    "%xdel qso_flx\n",
    "%xdel qso_err\n",
    "%xdel sf_zspec\n",
    "%xdel qso_zspec\n",
    "%xdel EW_sf\n",
    "%xdel EW_qso\n",
    "%xdel qso_dL\n",
    "%xdel sf_L\n",
    "%xdel qso_L\n",
    "%xdel sf_flambda\n",
    "%xdel qso_flambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sources = pm_flx.shape[1]\n",
    "N_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx[-2], w_central[-2])\n",
    "mag[np.isnan(mag)] = 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 20)\n",
    "lya_lines, lya_cont_lines, line_widths = identify_lines(\n",
    "    line, pm_flx, pm_err, first=True, return_line_width=True\n",
    ")\n",
    "lya_lines = np.array(lya_lines)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    400, obs=True)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)\n",
    "\n",
    "# Compute z\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "nice_z = np.abs(z_Arr - zspec) < 0.12\n",
    "\n",
    "%xdel cont_est_other\n",
    "%xdel cont_err_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 16\n",
    "mag_max = 24\n",
    "\n",
    "nb_min = 7\n",
    "nb_max = 15\n",
    "\n",
    "nbs_to_consider = np.arange(nb_min, nb_max + 1)\n",
    "\n",
    "nb_cut = (np.array(lya_lines) >= nb_min) & (np.array(lya_lines) <= nb_max)\n",
    "\n",
    "z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5) / w_lya - 1\n",
    "z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5) / w_lya - 1\n",
    "\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "zspec_cut = (z_min < zspec) & (zspec < z_max)\n",
    "ew_cut = EW_lya > 20\n",
    "mag_cut = (mag > mag_min) & (mag < mag_max)\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_lya, z_Arr\n",
    ")\n",
    "nice_lya = (nice_lya & z_cut & mag_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fractions QSO / SF\n",
    "\n",
    "good_qso = len(np.where(np.where(nice_lya & nice_z)[0] < N_qso)[0])\n",
    "bad_qso = len(np.where(np.where(nice_lya & ~nice_z)[0] < N_qso)[0])\n",
    "N_sel = count_true(nice_lya)\n",
    "N_sel_good = count_true(nice_lya & nice_z)\n",
    "\n",
    "\n",
    "good_frac = good_qso / N_sel_good\n",
    "bad_frac = bad_qso / (N_sel - N_sel_good)\n",
    "\n",
    "purity = count_true(nice_z & nice_lya) / count_true(nice_lya)\n",
    "\n",
    "print(f'Good QSOs: {good_qso} | Bad QSOs: {bad_qso}')\n",
    "print(f'Good SFs: {N_sel_good - good_qso} | Bad SFs: {N_sel - N_sel_good - bad_qso}')\n",
    "print()\n",
    "print('Good frac: {0:0.2f}'.format(good_frac))\n",
    "print('Bad frac: {0:0.2f}'.format(bad_frac))\n",
    "print()\n",
    "print('Purity = {0:0.2f}'.format(purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EW_nb_Arr, EW_nb_e, L_Arr, L_e_Arr, flambda, flambda_e = EW_L_NB(\n",
    "    pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines\n",
    ")\n",
    "\n",
    "# def compute_corrections(flambda, fline, L_Arr):\n",
    "#     F_cor = np.ones(60)\n",
    "\n",
    "#     for nb in nbs_to_consider:\n",
    "#         to_cor = nice_z & (lya_lines == nb) & mag_cut\n",
    "#         F_to_cor = (flambda / fline)[to_cor]\n",
    "#         F_to_cor[np.isinf(F_to_cor)] = np.nan\n",
    "#         F_cor[nb] = np.nanmedian(F_to_cor)\n",
    "\n",
    "#     return F_cor\n",
    "\n",
    "# F_cor = compute_corrections(flambda, fline, L_Arr)\n",
    "\n",
    "# np.save('npy/F_cor.npy', F_cor)\n",
    "\n",
    "# EW_nb_Arr, EW_nb_e, L_Arr, L_e_Arr, flambda, flambda_e = EW_L_NB(\n",
    "#     pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines,\n",
    "#     F_bias=F_cor, nice_lya=nice_lya\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_Lbin_err(L_Arr, L_lya, L_binning):\n",
    "    L_Lbin_err_plus = np.ones(len(L_binning) - 1) * 99\n",
    "    L_Lbin_err_minus = np.ones(len(L_binning) - 1) * 99\n",
    "    median = np.ones(len(L_binning) - 1) * 99\n",
    "    last = [99., 99.]\n",
    "    for i in range(len(L_binning) - 1):\n",
    "        in_bin = (L_Arr >= L_binning[i]) & (L_Arr < L_binning[i + 1])\n",
    "        if count_true(in_bin) == 0:\n",
    "            L_Lbin_err_plus[i] = last[0]\n",
    "            L_Lbin_err_minus[i] = last[1]\n",
    "            continue\n",
    "        perc = np.percentile((L_Arr - L_lya)[in_bin], [16, 50, 84])\n",
    "        L_Lbin_err_plus[i] = perc[2] - perc[1]\n",
    "        L_Lbin_err_minus[i] = perc[1] - perc[0]\n",
    "        \n",
    "        last = [L_Lbin_err_plus[i], L_Lbin_err_minus[i]]\n",
    "        median[i] = perc[1]\n",
    "\n",
    "    return np.vstack((L_Lbin_err_plus, L_Lbin_err_minus)), median\n",
    "\n",
    "L_binning = np.linspace(42, 46, 15 + 1)\n",
    "L_Lbin_err, median_L = compute_L_Lbin_err(L_Arr[nice_z], L_lya[nice_z], L_binning)\n",
    "np.save('npy/L_nb_err.npy', L_Lbin_err)\n",
    "np.save('npy/L_bias.npy', median_L)\n",
    "np.save('npy/L_nb_err_binning.npy', L_binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel pm_flx\n",
    "%xdel pm_err\n",
    "%xdel cont_est_lya\n",
    "%xdel cont_err_lya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "mask = ((mag[is_qso] < 23) & nice_lya[is_qso] & nice_z[is_qso]) & (qso_flambda_relerr < 0.1)\n",
    "Z, x, y = np.histogram2d(\n",
    "    L_lya[is_qso][mask], L_Arr[is_qso][mask],\n",
    "    bins=(np.linspace(42, 47, 30), np.linspace(42, 47, 30))\n",
    ")\n",
    "\n",
    "H_min = np.amin(Z)\n",
    "H_max = np.amax(Z)\n",
    "\n",
    "y_centers = 0.5 * ( y[1:] + y[:-1] )\n",
    "x_centers = 0.5 * ( x[1:] + x[:-1] )\n",
    "\n",
    "N_bins = 10000\n",
    "\n",
    "H_Arr = np.linspace( H_min , H_max , N_bins )[::-1]\n",
    "\n",
    "fact_up_Arr = np.zeros( N_bins )\n",
    "\n",
    "TOTAL_H = np.sum(Z)\n",
    "\n",
    "for iii in range(0, N_bins):\n",
    "\n",
    "    mask = Z > H_Arr[iii]\n",
    "\n",
    "    fact_up_Arr[iii] = np.sum(Z[ mask ]) / TOTAL_H\n",
    "\n",
    "H_value_68 = np.interp(0.683, fact_up_Arr, H_Arr) # 1sigma\n",
    "H_value_95 = np.interp(0.954, fact_up_Arr, H_Arr) # 2sigma\n",
    "H_value_99 = np.interp(0.997, fact_up_Arr, H_Arr) # 2sigma\n",
    "\n",
    "ax.contour(\n",
    "    x_centers, y_centers, Z.T, levels=[H_value_99, H_value_95, H_value_68],\n",
    "    colors='C0'\n",
    ")\n",
    "\n",
    "mask = (~is_qso & (mag < 23) & nice_lya & nice_z)\n",
    "Z, x, y = np.histogram2d(\n",
    "    L_lya[mask], L_Arr[mask],\n",
    "    bins=(np.linspace(42, 47, 30), np.linspace(42, 47, 30))\n",
    ")\n",
    "\n",
    "H_min = np.amin(Z)\n",
    "H_max = np.amax(Z)\n",
    "\n",
    "y_centers = 0.5 * ( y[1:] + y[:-1] )\n",
    "x_centers = 0.5 * ( x[1:] + x[:-1] )\n",
    "\n",
    "N_bins = 10000\n",
    "\n",
    "H_Arr = np.linspace(H_min , H_max , N_bins )[::-1]\n",
    "\n",
    "fact_up_Arr = np.zeros(N_bins)\n",
    "\n",
    "TOTAL_H = np.sum(Z)\n",
    "\n",
    "for iii in range(0, N_bins):\n",
    "\n",
    "    mask = Z > H_Arr[iii]\n",
    "\n",
    "    fact_up_Arr[iii] = np.sum(Z[ mask ]) / TOTAL_H\n",
    "\n",
    "H_value_68 = np.interp(0.683, fact_up_Arr, H_Arr) # 1sigma\n",
    "H_value_95 = np.interp(0.954, fact_up_Arr, H_Arr) # 2sigma\n",
    "H_value_99 = np.interp(0.997, fact_up_Arr, H_Arr) # 2sigma\n",
    "\n",
    "ax.contour(\n",
    "    x_centers, y_centers, Z.T, levels=[H_value_99, H_value_95, H_value_68],\n",
    "    colors='C1'\n",
    ")\n",
    "\n",
    "# ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# ax.scatter(L_lya[nice_lya & is_qso], L_Arr[nice_lya & is_qso],\n",
    "#     label='QSO', alpha=0.3)\n",
    "# ax.scatter(L_lya[nice_lya & ~is_qso], L_Arr[nice_lya & ~is_qso],\n",
    "#     label='SF', alpha=0.3)\n",
    "\n",
    "x = np.linspace(40, 48, 100)\n",
    "ax.plot(x, x, linestyle='--', color='red', label='1:1')\n",
    "\n",
    "# Lx = [(L_binning[i] + L_binning[i + 1]) / 2 for i in range(len(L_binning) - 1)]\n",
    "# ax.plot(Lx, Lx + median_L, c='k')\n",
    "# ax.plot(Lx, Lx + median_L - L_Lbin_err[1], c='gray')\n",
    "# ax.plot(Lx, Lx + median_L + L_Lbin_err[0], c='gray')\n",
    "\n",
    "ax.set_ylabel('Retrieved $\\log L$', fontsize=15)\n",
    "ax.set_xlabel('Real $\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_ylim((42, 47))\n",
    "ax.set_xlim((42, 47))\n",
    "\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < 25) & is_qso)\n",
    "ax.hist(L_Arr[mask], bins=np.linspace(42, 46, 30), color='C0', alpha=0.4, label='QSO')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < 25) & ~is_qso)\n",
    "ax.hist(L_Arr[mask], bins=np.linspace(42, 46, 30), color='C1', alpha=0.4, label='SF')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < 25) & is_qso)\n",
    "ax.hist(L_lya[mask], bins=np.linspace(42, 46, 30), color='C0', histtype='step')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < 25) & ~is_qso)\n",
    "ax.hist(L_lya[mask], bins=np.linspace(42, 46, 30), color='C1', histtype='step')\n",
    "\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlabel(r'log $L_{\\mathrm{Ly}\\alpha}$', fontsize=15)\n",
    "ax.set_ylabel('N', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins_1 = 9\n",
    "N_bins_2 = 6\n",
    "bins = np.concatenate((\n",
    "    np.linspace(42, 44.25, N_bins_1 + 1),\n",
    "    np.linspace(44.25, 45.5, N_bins_2 + 1)[1:]\n",
    "))\n",
    "bin_centers = [(bins[k] + bins[k + 1]) / 2 for k in range(len(bins) - 1)]\n",
    "\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 10 ** 44.65\n",
    "alpha1 = -1.35\n",
    "phistar2 = 10 ** -3.45\n",
    "Lstar2 = 10 ** 42.93\n",
    "alpha2 = -1.93\n",
    "\n",
    "volume = z_volume(z_min, z_max, 200)\n",
    "\n",
    "bins2 = np.linspace(42, 46, 30)\n",
    "h_qso, _ = np.histogram(L_lya[is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "h_sf, _ = np.histogram(L_lya[~is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "\n",
    "b_c = [0.5 * (bins[i] + bins[i + 1]) for i in range(len(bins) - 1)]\n",
    "bw = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "###################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z]\n",
    "badh = L_lya[nice_lya & ~nice_z]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('Total', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z & is_qso]\n",
    "badh = L_lya[nice_lya & ~nice_z & is_qso]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut & is_qso], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('QSO', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z & ~is_qso]\n",
    "badh = L_lya[nice_lya & ~nice_z & ~is_qso]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut & ~is_qso], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('SF', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2d_puricomp(L_Arr, L_lya, mag, L_bins):\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "\n",
    "    height = 1.\n",
    "    width = 1.\n",
    "    height2 = 0.7\n",
    "    spacing = 0.1\n",
    "    cbar_width = 0.06\n",
    "\n",
    "    ax0 = fig.add_axes([0, height2 + spacing, width, height])\n",
    "    ax1 = fig.add_axes([width + spacing, height2 + spacing, width, height])\n",
    "    axc = fig.add_axes([2 * width + 1.5 * spacing, height2 + spacing, cbar_width, height])\n",
    "    ax2 = fig.add_axes([0, 0, width, height2])\n",
    "    ax3 = fig.add_axes([width + spacing, 0, width, height2])\n",
    "\n",
    "    L_bins = np.linspace(42.5, 46, 20)\n",
    "    r_bins = np.linspace(mag_min, mag_max, 20)\n",
    "\n",
    "    L_bins_c = np.array([0.5 * (L_bins[i] + L_bins[i + 1]) for i in range(len(L_bins) - 1)])\n",
    "\n",
    "    # Perturb L\n",
    "    \n",
    "    N_iter = 1000\n",
    "    h2d_nice_i = np.empty((len(L_bins) - 1, len(r_bins) - 1, N_iter))\n",
    "    h2d_sel_i = np.empty((len(L_bins) - 1, len(r_bins) - 1, N_iter))\n",
    "    h1d_nice_i = np.empty((len(L_bins) - 1, N_iter))\n",
    "    h1d_sel_i = np.empty((len(L_bins) - 1, N_iter))\n",
    "\n",
    "    L_binning_position = binned_statistic(\n",
    "        L_Arr, None, 'count', bins=L_binning\n",
    "    ).binnumber\n",
    "    L_binning_position[L_binning_position > len(L_binning) - 2] = len(L_binning) - 2\n",
    "\n",
    "    L_bias = median_L[L_binning_position]\n",
    "\n",
    "    for k in range(N_iter):\n",
    "        L_perturbed = np.log10(\n",
    "            10 ** (L_Arr - L_bias) + L_e_Arr * np.random.randn(len(L_e_Arr))\n",
    "        )\n",
    "        L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "        h2d_nice_i[..., k], _, _ = np.histogram2d(\n",
    "            L_perturbed[nice_lya & nice_z],\n",
    "            mag[nice_lya & nice_z],\n",
    "            bins=[L_bins, r_bins]\n",
    "        )\n",
    "\n",
    "        h2d_sel_i[..., k], _, _ = np.histogram2d(\n",
    "            L_perturbed[nice_lya],\n",
    "            mag[nice_lya],\n",
    "            bins=[L_bins, r_bins]\n",
    "        )\n",
    "\n",
    "        h1d_nice_i[..., k], _ = np.histogram(L_perturbed[nice_lya & nice_z], bins=L_bins)\n",
    "        h1d_sel_i[..., k], _ = np.histogram(L_perturbed[nice_lya], bins=L_bins)\n",
    "\n",
    "    # Take the median\n",
    "    h2d_nice = np.median(h2d_nice_i, axis=2)\n",
    "    h2d_sel = np.median(h2d_sel_i, axis=2)\n",
    "    h1d_nice = np.median(h1d_nice_i, axis=1)\n",
    "    h1d_sel = np.median(h1d_sel_i, axis=1)\n",
    "\n",
    "    # h2d_nice, _, _ = np.histogram2d(\n",
    "    #     L_Arr[nice_lya & nice_z],\n",
    "    #     mag[nice_lya & nice_z],\n",
    "    #     bins=[L_bins, r_bins]\n",
    "    # )\n",
    "    # h2d_sel, _, _ = np.histogram2d(\n",
    "    #     L_Arr[nice_lya],\n",
    "    #     mag[nice_lya],\n",
    "    #     bins=[L_bins, r_bins]\n",
    "    # )\n",
    "\n",
    "    h2d_parent, _, _ = np.histogram2d(\n",
    "        L_lya[zspec_cut & mag_cut & ew_cut],\n",
    "        mag[zspec_cut & mag_cut & ew_cut],\n",
    "        bins=[L_bins, r_bins]\n",
    "    )\n",
    "    h1d_parent, _ = np.histogram(L_lya[zspec_cut & mag_cut & ew_cut], bins=L_bins)\n",
    "    # h1d_nice, _ = np.histogram(L_Arr[nice_lya & nice_z], bins=L_bins)\n",
    "    # h1d_sel, _ = np.histogram(L_Arr[nice_lya], bins=L_bins)\n",
    "\n",
    "    cmap = 'Spectral'\n",
    "\n",
    "    puri2d = h2d_nice / h2d_sel\n",
    "    comp2d = h2d_nice / h2d_parent\n",
    "    puri1d = h1d_nice / h1d_sel\n",
    "    comp1d = h1d_nice / h1d_parent\n",
    "\n",
    "    puri1d[np.isnan(puri1d)] = 0.\n",
    "    comp1d[np.isnan(comp1d)] = 0.\n",
    "\n",
    "    ### PLOT STUFF\n",
    "\n",
    "    sns.heatmap(puri2d.T, ax=ax0, vmin=0, vmax=1, cbar_ax=axc, cmap=cmap)\n",
    "    sns.heatmap(comp2d.T, ax=ax1, vmin=0, vmax=1, cbar=False, cmap=cmap)\n",
    "\n",
    "    ax2.plot(L_bins_c, puri1d, marker='s')\n",
    "    ax3.plot(L_bins_c, comp1d, marker='s')\n",
    "\n",
    "    ### TICKS\n",
    "\n",
    "    xticks = range(len(L_bins))\n",
    "    yticks = range(len(r_bins))\n",
    "    xtick_labels = ['{0:0.1f}'.format(n) for n in L_bins]\n",
    "    ytick_labels = ['{0:0.1f}'.format(n) for n in r_bins]\n",
    "\n",
    "\n",
    "    ax0.set_yticks(yticks)\n",
    "    ax0.set_yticklabels(ytick_labels, rotation='horizontal')\n",
    "    ax0.set_xticks(xticks)\n",
    "    ax0.set_xticklabels(xtick_labels, rotation='vertical')\n",
    "    ax0.yaxis.set_ticks_position('both')\n",
    "    ax0.xaxis.set_ticks_position('both')\n",
    "    ax0.tick_params(axis='y', direction='in', labelsize=14)\n",
    "    ax0.tick_params(axis='x', direction='in', labelsize=14)\n",
    "\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_yticklabels(ytick_labels, rotation='horizontal')\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels(xtick_labels, rotation='vertical')\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax1.tick_params(axis='y', direction='in', labelsize=14)\n",
    "    ax1.tick_params(axis='x', direction='in', labelsize=14)\n",
    "\n",
    "    axc.tick_params(labelsize=14)\n",
    "    ax2.tick_params(labelsize=14)\n",
    "    ax3.tick_params(labelsize=14)\n",
    "\n",
    "    ## Spines\n",
    "    ax0.spines[:].set_visible(True)\n",
    "    ax1.spines[:].set_visible(True)\n",
    "\n",
    "    ## Axes labels\n",
    "    # ax0.set_ylabel('rSDSS')\n",
    "    # ax0.set_xlabel('log L$_\\mathrm{Lya}$')\n",
    "    # ax1.set_ylabel('rSDSS')\n",
    "    # ax1.set_xlabel('log L$_\\mathrm{Lya}$')\n",
    "\n",
    "    ## Axis lims\n",
    "    ax2.set_ylim((0, 1))\n",
    "    # ax3.set_ylim((0, 1))\n",
    "\n",
    "    ## Titles\n",
    "    ax0.set_title('Purity', fontsize=25)\n",
    "    ax1.set_title('Completeness', fontsize=25)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    np.save('npy/puri2d.npy', puri2d)\n",
    "    np.save('npy/comp2d.npy', comp2d)\n",
    "    np.save('npy/puricomp2d_L_bins.npy', L_bins)\n",
    "    np.save('npy/puricomp2d_r_bins.npy', r_bins)\n",
    "\n",
    "    return puri2d, comp2d, L_bins, r_bins\n",
    "puri2d, comp2d, L_bins, r_bins = make_2d_puricomp(L_Arr, L_lya, mag, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lya_intrisic_completeness(L, z, starprob=None):\n",
    "    if starprob == None:\n",
    "        starprob = np.zeros(L.shape)\n",
    "\n",
    "    isstar = (starprob >= 0.5)\n",
    "\n",
    "    ## MiniJPAS limiting r magnitudes\n",
    "    mag = np.ones(L.shape) * 23.6\n",
    "    mag[~isstar] = 22.7\n",
    "\n",
    "    Fline = 10 ** L / (cosmo.luminosity_distance(z).to(u.cm).value ** 2 * 4*np.pi)\n",
    "    fcont = mag_to_flux(mag, 6750)\n",
    "\n",
    "    EW_max = Fline / fcont / (1 + z)\n",
    "\n",
    "    ew_x = np.linspace(20, 1000, 10000)\n",
    "    w_0 = 75\n",
    "    ew_dist = lambda ew_xx: np.exp(-ew_xx / w_0)\n",
    "\n",
    "    total_ew = simpson(ew_dist(ew_x), ew_x)\n",
    "\n",
    "    completeness = np.empty(L.shape)\n",
    "\n",
    "    for src in range(len(L)):\n",
    "        src_ew_x = np.linspace(20, EW_max[src], 1000)\n",
    "        completeness[src] = simpson(ew_dist(src_ew_x), src_ew_x) / total_ew\n",
    "\n",
    "    return completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intcomp = Lya_intrisic_completeness(L_Arr[nice_lya], z_Arr[nice_lya], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection algorithm weights\n",
    "# weights = puricomp2d_weights(L_Arr[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, weights=True):\n",
    "    N_bins = len(bins) - 1\n",
    "\n",
    "    hist_i_mat = np.zeros((1000, N_bins))\n",
    "\n",
    "    L_binning_position = binned_statistic(\n",
    "        L_Arr, None, 'count', bins=L_binning\n",
    "    ).binnumber\n",
    "    L_binning_position[L_binning_position > len(L_binning) - 2] = len(L_binning) - 2\n",
    "\n",
    "    L_err = L_Lbin_err[:, L_binning_position - 1]\n",
    "    L_bias = median_L[L_binning_position]\n",
    "    L_err[0] = 10 ** (L_Arr + L_err[0]) - 10 ** L_Arr\n",
    "    L_err[1] = 10 ** L_Arr - 10 ** (L_Arr - L_err[0])\n",
    "\n",
    "    for k in range(1000):\n",
    "        # randN = np.random.randn(N_sources)\n",
    "        # L_perturbation = np.zeros(N_sources)\n",
    "        # L_perturbation[randN >= 0.] = L_err[0, randN >= 0.] * randN[randN >= 0.]\n",
    "        # L_perturbation[randN < 0.] = L_err[1, randN < 0.] * randN[randN < 0.]\n",
    "\n",
    "        # L_perturbed = np.log10(10 ** (L_Arr - L_bias) + L_perturbation)\n",
    "        L_perturbed = np.log10(\n",
    "            10 ** (L_Arr - L_bias) + L_e_Arr * np.random.randn(len(L_e_Arr))\n",
    "        )\n",
    "        L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "        w = puricomp2d_weights(\n",
    "            L_perturbed[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins\n",
    "        )\n",
    "        if not weights:\n",
    "            w[:] = 1\n",
    "        # w = weights_LF(\n",
    "        #     L_perturbed[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins,\n",
    "        #     z_Arr[nice_lya], None, None\n",
    "        # )\n",
    "        hist = np.histogram(L_perturbed[nice_lya], bins=bins)[0]\n",
    "        hist_poiss_err = np.round(\n",
    "            hist[0] ** 0.5 * np.random.randn(len(bins) - 1), 0\n",
    "        ).astype(int)\n",
    "\n",
    "        hist_binnumber = binned_statistic(L_perturbed[nice_lya], None, 'count', bins=bins)[2]\n",
    "\n",
    "        L_Arr_to_hist = np.array([])\n",
    "        w_Arr_to_hist = np.array([])\n",
    "        for bin in range(N_bins):\n",
    "            where_bin = np.where(hist_binnumber == bin + 1)[0]\n",
    "            try:\n",
    "                idx = np.random.choice(\n",
    "                    where_bin, size=(hist_poiss_err[bin] + hist[bin]),\n",
    "                    replace=True\n",
    "                )\n",
    "                L_Arr_to_hist = np.hstack([L_Arr_to_hist, L_perturbed[nice_lya][idx]])\n",
    "                w_Arr_to_hist = np.hstack([w_Arr_to_hist, w[idx]])\n",
    "            except:\n",
    "                pass\n",
    "        hist_i_mat[k], _ = np.histogram(L_Arr_to_hist, bins=bins, weights=w_Arr_to_hist)\n",
    "\n",
    "    L_LF_err_percentiles = np.percentile(hist_i_mat, [16, 50, 84], axis=0)\n",
    "    return L_LF_err_percentiles\n",
    "\n",
    "# L_e_Arr = np.load('npy/L_nb_err.npy')\n",
    "L_binning = np.load('npy/L_nb_err_binning.npy')\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning)\n",
    "L_LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, False)\n",
    "total_hist = L_LF_err_percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_bins = np.array([(bins[i] + bins[i + 1]) / 2 for i in range(len(bins) - 1)])\n",
    "\n",
    "bin_width = np.array([bins[i + 1] - bins[i] for i in range(len(bins) - 1)])\n",
    "\n",
    "volume = z_volume(z_min, z_max, 200)\n",
    "\n",
    "yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# ax.errorbar(LF_bins, total_hist / volume / bw,\n",
    "#     yerr=[yerr_cor_minus, yerr_cor_plus],\n",
    "#     marker='.', linestyle='', markersize=15, label='Uncorrected')\n",
    "# ax.errorbar(LF_bins, total_hist_cor / volume / bw,\n",
    "#     yerr=(total_hist) ** 0.5 / volume / bw,\n",
    "#     marker='.', linestyle='', markersize=15, label='Corrected')\n",
    "# ax.errorbar(LF_bins, total_hist_cor_cor / volume / bw,\n",
    "#     yerr=(total_hist) ** 0.5 / volume / bw,\n",
    "#     marker='.', linestyle='', markersize=15, label='More corrected')\n",
    "yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "xerr = bin_width / 2\n",
    "ax.errorbar(LF_bins, hist_median / volume / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus], xerr=xerr,\n",
    "    marker='.', linestyle='', markersize=15, c='red',\n",
    "    label='Corrected median histogram')\n",
    "\n",
    "bins2 = np.linspace(42, 46, 30)\n",
    "b_c = [(bins2[i] + bins2[i + 1]) * 0.5 for i in range(len(bins2) - 1)]\n",
    "bw = bins2[1] - bins2[0]\n",
    "h_qso, b = np.histogram(L_lya[is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "h_sf, b = np.histogram(L_lya[~is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "\n",
    "ax.plot(b_c, (h_qso + h_sf) / bw / volume, c='dimgray', zorder=-99, label='Mock', ls='--')\n",
    "\n",
    "Lx = np.linspace(10 ** 42, 10 ** 45.5, 1000)\n",
    "Phi = double_schechter(\n",
    "                Lx, phistar2, Lstar2, alpha2, phistar1, Lstar1, alpha1\n",
    "            ) * Lx * np.log(10)\n",
    "\n",
    "ax.plot(np.log10(Lx), Phi)\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-3)\n",
    "ax.set_xlim(42., 46)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlabel('log L', fontsize=15)\n",
    "ax.set_ylabel('$\\Phi$ [Mpc$^{-3}$ $\\Delta$ log L $^{-1}$]', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "L_binning_position = binned_statistic(\n",
    "    L_Arr[nice_lya], None, 'count', bins=L_binning\n",
    ").binnumber\n",
    "L_binning_position[L_binning_position > len(L_binning) - 2] = len(L_binning) - 2\n",
    "\n",
    "dL_Arr = cosmo.luminosity_distance(z_Arr[nice_lya]).to(u.cm).value\n",
    "\n",
    "# EW_e_Arr_plus = (10 ** (L_Arr[nice_lya] + L_e_Arr[0, L_binning_position - 1]) - 10 ** L_Arr[nice_lya])\\\n",
    "#     / (4*np.pi * dL_Arr**2 * cont_est_lya[lya_lines[nice_lya], nice_lya] * (1 + z_Arr[nice_lya]))\n",
    "\n",
    "# EW_e_Arr_minus = (-10 ** (L_Arr[nice_lya] - L_e_Arr[1, L_binning_position - 1]) + 10 ** L_Arr[nice_lya])\\\n",
    "#     / (4*np.pi * dL_Arr**2 * cont_est_lya[lya_lines[nice_lya], nice_lya] * (1 + z_Arr[nice_lya]))\n",
    "\n",
    "ax.errorbar(\n",
    "    mag[nice_lya], EW_nb_Arr[nice_lya], yerr=EW_nb_e[nice_lya],\n",
    "    color='k', capsize=3, fmt='s', ecolor='dimgray'\n",
    ")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel('r (mag$_\\mathrm{AB}$)', fontsize=15)\n",
    "ax.set_ylabel('EW$_0$ ($\\AA$)', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "mask = nice_lya & nice_z & (mag < 21)\n",
    "ax.scatter(EW_lya[mask], EW_nb_Arr[mask], alpha=0.3)\n",
    "\n",
    "ax.set_ylabel('Retrieved EW0', fontsize=15)\n",
    "ax.set_xlabel('Real EW0', fontsize=15)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.set_ylim((1, 1e4))\n",
    "ax.set_xlim((1, 1e4))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "\n",
    "def do_this():\n",
    "    sigma_interval = np.linspace(0.001, 5, 1000)\n",
    "\n",
    "    mask = nice_lya & nice_z & is_qso\n",
    "    dist = 10 ** L_Arr[mask] - 10 ** L_lya[mask]\n",
    "    h, _ = np.histogram(\n",
    "        np.abs(\n",
    "            dist - np.nanmedian(dist)\n",
    "        ) / L_e_Arr[mask],\n",
    "        bins=sigma_interval\n",
    "    )\n",
    "\n",
    "    h = np.cumsum(h) / np.sum(h)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "    ax.plot(erf(sigma_interval[1:] * 3 ** -0.5), h)\n",
    "    ax.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), ls='--', c='r')\n",
    "\n",
    "    mask = nice_lya & nice_z & ~is_qso\n",
    "    dist = 10 ** L_Arr[mask] - 10 ** L_lya[mask]\n",
    "    h, _ = np.histogram(\n",
    "        np.abs(\n",
    "            dist - np.nanmedian(dist)\n",
    "        ) / L_e_Arr[mask],\n",
    "        bins=sigma_interval\n",
    "    )\n",
    "\n",
    "    h = np.cumsum(h) / np.sum(h)\n",
    "\n",
    "    ax.plot(erf(sigma_interval[1:] * 2 ** -0.5), h)\n",
    "    ax.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), ls='--', c='r')\n",
    "    \n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_xlim((0, 1))\n",
    "\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('erf($\\sigma$')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "do_this()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_this():\n",
    "\n",
    "    mag_bins = np.arange(18, 25, 1)\n",
    "\n",
    "    for i, min_mag in enumerate(mag_bins[:-1]):\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "        max_mag = mag_bins[i + 1]\n",
    "        mag_mask = (mag > min_mag) & (mag < max_mag)\n",
    "        # mask1 = nice_lya & is_qso & mag_mask & nice_z\n",
    "        mask1 = (\n",
    "            nice_z[is_qso] & nice_lya[is_qso] & mag_mask[is_qso]\n",
    "            ) & (qso_flambda_relerr < 0.1)\n",
    "\n",
    "        ax.hist(\n",
    "            (10 ** L_Arr[is_qso][mask1] - 10 ** L_lya[is_qso][mask1]) / L_e_Arr[is_qso][mask1],\n",
    "            bins=np.linspace(-5, 10, 30), histtype='step',\n",
    "            label='$\\mu'\n",
    "        )\n",
    "\n",
    "        dist = (10 ** L_Arr[is_qso][mask1] - 10 ** L_lya[is_qso][mask1]) / L_e_Arr[is_qso][mask1]\n",
    "        dist = dist[(dist < 10) & (dist > -5) & is_qso[is_qso][mask1]]\n",
    "        print('QSO: mean = {}, std = {}'.format(np.nanmean(dist), np.nanstd(dist)))\n",
    "\n",
    "        mask2 = nice_lya & ~is_qso & mag_mask & nice_z\n",
    "        ax.hist(\n",
    "            (10 ** L_Arr[mask2] - 10 ** L_lya[mask2]) / L_e_Arr[mask2],\n",
    "            bins=np.linspace(-5, 10, 30), histtype='step'\n",
    "        )\n",
    "        dist = (10 ** L_Arr[mask2] - 10 ** L_lya[mask2]) / L_e_Arr[mask2]\n",
    "        dist = dist[(dist < 10) & (dist > -5) & ~is_qso[mask2]]\n",
    "        if count_true(mask2) > 2:\n",
    "            print('SF: mean = {}, std = {}'.format(np.nanmean(dist), np.nanstd(dist)))\n",
    "\n",
    "        ax.set_ylabel('N', fontsize=15)\n",
    "        ax.set_xlabel('(L$_\\mathrm{ret}$ - L$_\\mathrm{real}$) / $\\sigma$',\n",
    "            fontsize=15)\n",
    "\n",
    "        ax.set_title(f'{max_mag} > r > {min_mag}', fontsize=20)\n",
    "\n",
    "        # fig.savefig(f'/home/alberto/Desktop/{min_mag}-{max_mag}')\n",
    "        plt.show()\n",
    "\n",
    "do_this()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
