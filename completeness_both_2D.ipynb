{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from my_functions import *\n",
    "from LF_puricomp_corrections import puricomp2d_weights\n",
    "\n",
    "import glob\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))\n",
    "w_lya = 1215.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load my QSO catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/QSO_100000_v7/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data_qso = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "qso_flx = data_qso.to_numpy()[:, 1 : 60 + 1].T\n",
    "qso_err = data_qso.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "EW_qso = data_qso['EW0'].to_numpy()\n",
    "qso_zspec = data_qso['z'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load my GAL catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/GAL_100000/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data_gal = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "gal_flx = data_qso.to_numpy()[:, 1 : 60 + 1].T\n",
    "gal_err = data_qso.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "EW_gal = np.zeros(data_gal['z'].to_numpy().shape)\n",
    "gal_zspec = data_gal['z'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SF catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/LAE_10deg_z2-4_v7/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "sf_flx = data.to_numpy()[:, 1 : 60 + 1].T\n",
    "sf_err = data.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "EW_sf = data['EW0'].to_numpy()\n",
    "sf_zspec = data['z'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_flx = np.hstack((qso_flx, sf_flx, gal_flx))\n",
    "pm_err = np.hstack((qso_err, sf_err, gal_flx))\n",
    "zspec = np.concatenate((qso_zspec, sf_zspec, gal_zspec))\n",
    "EW_lya = np.concatenate((EW_qso, EW_sf, EW_gal))\n",
    "\n",
    "N_sf = sf_flx.shape[1]\n",
    "N_qso = qso_flx.shape[1]\n",
    "N_gal = gal_flx.shape[1]\n",
    "\n",
    "qso_dL = cosmo.luminosity_distance(qso_zspec).to(u.cm).value\n",
    "sf_dL = cosmo.luminosity_distance(sf_zspec).to(u.cm).value\n",
    "\n",
    "sf_L = data['L_lya'].to_numpy()\n",
    "qso_L = data_qso['L_lya'].to_numpy()\n",
    "gal_L = np.zeros(EW_gal.shape)\n",
    "\n",
    "sf_flambda = 10 ** sf_L / (4*np.pi * sf_dL **2)\n",
    "qso_flambda = data_qso['F_line']\n",
    "gal_flambda = np.zeros(EW_gal.shape)\n",
    "\n",
    "L_lya = np.concatenate((qso_L, sf_L, gal_L))\n",
    "fline = np.concatenate((qso_flambda, sf_flambda, gal_flambda))\n",
    "\n",
    "is_qso = np.concatenate((np.ones(N_qso), np.zeros(N_sf + N_gal))).astype(bool)\n",
    "is_sf = np.concatenate((np.zeros(N_qso), np.ones(N_sf), np.zeros(N_gal))).astype(bool)\n",
    "\n",
    "N_sources = pm_flx.shape[1]\n",
    "\n",
    "%xdel sf_flx\n",
    "%xdel sf_err\n",
    "%xdel qso_flx\n",
    "%xdel qso_err\n",
    "%xdel sf_zspec\n",
    "%xdel qso_zspec\n",
    "%xdel EW_sf\n",
    "%xdel EW_qso\n",
    "%xdel qso_dL\n",
    "%xdel sf_L\n",
    "%xdel qso_L\n",
    "%xdel sf_flambda\n",
    "%xdel qso_flambda\n",
    "%xdel mock\n",
    "%xdel data\n",
    "%xdel data_qso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sources = pm_flx.shape[1]\n",
    "N_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx[-2], w_central[-2])\n",
    "mag[np.isnan(mag)] = 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 20)\n",
    "lya_lines, lya_cont_lines, line_widths = identify_lines(\n",
    "    line, pm_flx, pm_err, first=True, return_line_width=True\n",
    ")\n",
    "lya_lines = np.array(lya_lines)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    400, obs=True)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)\n",
    "\n",
    "# Compute z\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "nice_z = np.abs(z_Arr - zspec) < 0.12\n",
    "\n",
    "%xdel cont_est_other\n",
    "%xdel cont_err_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 17\n",
    "mag_max = 25\n",
    "\n",
    "nb_min = 5\n",
    "nb_max = 15\n",
    "\n",
    "# Used later!!\n",
    "L_min = 40\n",
    "L_max = 50\n",
    "\n",
    "nbs_to_consider = np.arange(nb_min, nb_max + 1)\n",
    "\n",
    "nb_cut = (np.array(lya_lines) >= nb_min) & (np.array(lya_lines) <= nb_max)\n",
    "\n",
    "z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5) / w_lya - 1\n",
    "z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5) / w_lya - 1\n",
    "\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "zspec_cut = (z_min < zspec) & (zspec < z_max)\n",
    "ew_cut = EW_lya > 20\n",
    "mag_cut = (mag > mag_min) & (mag < mag_max)\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_lya, z_Arr\n",
    ")\n",
    "nice_lya = (nice_lya & z_cut & mag_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EW_nb_Arr, EW_nb_e, L_Arr, L_e_Arr, flambda, flambda_e = EW_L_NB(\n",
    "    pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, N_nb=0\n",
    ")\n",
    "\n",
    "# # Bias in flambda in each NB\n",
    "# def compute_corrections(flambda, fline):\n",
    "#     F_cor = np.ones(60)\n",
    "\n",
    "#     for nb in nbs_to_consider:\n",
    "#         to_cor = nice_z & (lya_lines == nb) & mag_cut\n",
    "#         F_to_cor = (flambda / fline)[to_cor]\n",
    "#         F_to_cor[np.isinf(F_to_cor)] = np.nan\n",
    "#         F_cor[nb] = np.nanmedian(F_to_cor)\n",
    "\n",
    "#     return F_cor\n",
    "\n",
    "# F_cor = compute_corrections(flambda, fline)\n",
    "\n",
    "# np.save('npy/F_cor.npy', F_cor)\n",
    "\n",
    "# EW_nb_Arr, EW_nb_e, L_Arr, L_e_Arr, flambda, flambda_e = EW_L_NB(\n",
    "#     pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, N_nb=0, F_bias=F_cor\n",
    "# )\n",
    "\n",
    "L_Arr[nice_lya] = ML_predict_L(\n",
    "    pm_flx[:, nice_lya], pm_err[:, nice_lya], z_Arr[nice_lya], L_Arr[nice_lya], 'RF'\n",
    ")\n",
    "\n",
    "# nice_lya[nice_lya] = nice_lya & (L_Arr > L_min) & (L_Arr < L_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_Lbin_err(L_Arr, L_lya, L_binning):\n",
    "    '''\n",
    "    Computes the errors due to dispersion of L_retrieved with some L_retrieved binning\n",
    "    '''\n",
    "    L_Lbin_err_plus = np.ones(len(L_binning) - 1) * 99\n",
    "    L_Lbin_err_minus = np.ones(len(L_binning) - 1) * 99\n",
    "    median = np.ones(len(L_binning) - 1) * 99\n",
    "    last = [99., 99.]\n",
    "    for i in range(len(L_binning) - 1):\n",
    "        in_bin = (10 ** L_Arr >= L_binning[i]) & (10 ** L_Arr < L_binning[i + 1])\n",
    "        if count_true(in_bin) == 0:\n",
    "            L_Lbin_err_plus[i] = last[0]\n",
    "            L_Lbin_err_minus[i] = last[1]\n",
    "            continue\n",
    "        perc = np.nanpercentile((10 ** L_Arr - 10 ** L_lya)[in_bin], [16, 50, 84])\n",
    "        L_Lbin_err_plus[i] = perc[2] - perc[1]\n",
    "        \n",
    "        last = [L_Lbin_err_plus[i], L_Lbin_err_minus[i]]\n",
    "        median[i] = perc[1]\n",
    "\n",
    "    return L_Lbin_err_plus, median\n",
    "\n",
    "L_binning = np.logspace(42, 46, 15 + 1)\n",
    "L_Lbin_err, median_L = compute_L_Lbin_err(\n",
    "    L_Arr[nice_lya & nice_z], L_lya[nice_z & nice_lya], L_binning\n",
    ")\n",
    "np.save('npy/L_nb_err.npy', L_Lbin_err)\n",
    "np.save('npy/L_bias.npy', median_L)\n",
    "np.save('npy/L_nb_err_binning.npy', L_binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply bin err\n",
    "L_binning_position = binned_statistic(\n",
    "        10 ** L_Arr, None, 'count', bins=L_binning\n",
    ").binnumber\n",
    "L_binning_position[L_binning_position > len(L_binning) - 2] = len(L_binning) - 2\n",
    "L_e_Arr = L_Lbin_err[L_binning_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel pm_flx\n",
    "%xdel pm_err\n",
    "%xdel cont_est_lya\n",
    "%xdel cont_err_lya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(is_qso):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "    mask = ((mag[is_qso] < 24) & nice_lya[is_qso] & nice_z[is_qso])\n",
    "    Z, x, y = np.histogram2d(\n",
    "        L_lya[is_qso][mask], L_Arr[is_qso][mask],\n",
    "        bins=(np.linspace(42, 47, 30), np.linspace(42, 47, 30))\n",
    "    )\n",
    "\n",
    "    H_min = np.amin(Z)\n",
    "    H_max = np.amax(Z)\n",
    "\n",
    "    y_centers = 0.5 * ( y[1:] + y[:-1] )\n",
    "    x_centers = 0.5 * ( x[1:] + x[:-1] )\n",
    "\n",
    "    N_bins = 10000\n",
    "\n",
    "    H_Arr = np.linspace(H_min , H_max , N_bins)[::-1]\n",
    "\n",
    "    fact_up_Arr = np.zeros( N_bins )\n",
    "\n",
    "    TOTAL_H = np.sum(Z)\n",
    "\n",
    "    for iii in range(0, N_bins):\n",
    "\n",
    "        mask = Z > H_Arr[iii]\n",
    "\n",
    "        fact_up_Arr[iii] = np.sum(Z[ mask ]) / TOTAL_H\n",
    "\n",
    "    H_value_68 = np.interp(0.683, fact_up_Arr, H_Arr) # 1sigma\n",
    "    H_value_95 = np.interp(0.954, fact_up_Arr, H_Arr) # 2sigma\n",
    "    H_value_99 = np.interp(0.997, fact_up_Arr, H_Arr) # 2sigma\n",
    "\n",
    "    ax.contour(\n",
    "        x_centers, y_centers, Z.T, levels=[H_value_99, H_value_95, H_value_68],\n",
    "        colors='C0'\n",
    "    )\n",
    "\n",
    "    mask = (is_sf & (mag < 24) & nice_lya & nice_z)\n",
    "    Z, x, y = np.histogram2d(\n",
    "        L_lya[mask], L_Arr[mask],\n",
    "        bins=(np.linspace(42, 47, 30), np.linspace(42, 47, 30))\n",
    "    )\n",
    "\n",
    "    H_min = np.amin(Z)\n",
    "    H_max = np.amax(Z)\n",
    "\n",
    "    y_centers = 0.5 * ( y[1:] + y[:-1] )\n",
    "    x_centers = 0.5 * ( x[1:] + x[:-1] )\n",
    "\n",
    "    N_bins = 10000\n",
    "\n",
    "    H_Arr = np.linspace(H_min , H_max , N_bins )[::-1]\n",
    "\n",
    "    fact_up_Arr = np.zeros(N_bins)\n",
    "\n",
    "    TOTAL_H = np.sum(Z)\n",
    "\n",
    "    for iii in range(0, N_bins):\n",
    "\n",
    "        mask = Z > H_Arr[iii]\n",
    "\n",
    "        fact_up_Arr[iii] = np.sum(Z[ mask ]) / TOTAL_H\n",
    "\n",
    "    H_value_68 = np.interp(0.683, fact_up_Arr, H_Arr) # 1sigma\n",
    "    H_value_95 = np.interp(0.954, fact_up_Arr, H_Arr) # 2sigma\n",
    "    H_value_99 = np.interp(0.997, fact_up_Arr, H_Arr) # 2sigma\n",
    "\n",
    "    ax.contour(\n",
    "        x_centers, y_centers, Z.T, levels=[H_value_99, H_value_95, H_value_68],\n",
    "        colors='C1'\n",
    "    )\n",
    "\n",
    "    # ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "    # ax.scatter(L_lya[nice_lya & is_qso], L_Arr[nice_lya & is_qso],\n",
    "    #     label='QSO', alpha=0.3)\n",
    "    # ax.scatter(L_lya[nice_lya & is_sf], L_Arr[nice_lya & is_sf],\n",
    "    #     label='SF', alpha=0.3)\n",
    "\n",
    "    x = np.linspace(40, 48, 100)\n",
    "    ax.plot(x, x, linestyle='--', color='red', label='1:1')\n",
    "\n",
    "    # Lx = [(L_binning[i] + L_binning[i + 1]) / 2 for i in range(len(L_binning) - 1)]\n",
    "    # ax.plot(Lx, Lx + median_L, c='k')\n",
    "    # ax.plot(Lx, Lx + median_L - L_Lbin_err[1], c='gray')\n",
    "    # ax.plot(Lx, Lx + median_L + L_Lbin_err[0], c='gray')\n",
    "\n",
    "    ax.set_ylabel('Retrieved $\\log L$', fontsize=15)\n",
    "    ax.set_xlabel('Real $\\log L$', fontsize=15)\n",
    "\n",
    "    ax.set_ylim((42, 47))\n",
    "    ax.set_xlim((42, 47))\n",
    "\n",
    "    ax.legend(fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_contours(is_qso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < mag_max) & is_qso)\n",
    "ax.hist(L_Arr[mask], bins=np.linspace(42, 46, 30), color='C0', alpha=0.4, label='QSO')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < mag_max) & is_sf)\n",
    "ax.hist(L_Arr[mask], bins=np.linspace(42, 46, 30), color='C1', alpha=0.4, label='SF')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < mag_max) & is_qso)\n",
    "ax.hist(L_lya[mask], bins=np.linspace(42, 46, 30), color='C0', histtype='step')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < mag_max) & is_sf)\n",
    "ax.hist(L_lya[mask], bins=np.linspace(42, 46, 30), color='C1', histtype='step')\n",
    "\n",
    "mask = (nice_lya & nice_z & (mag < mag_max) & ~is_qso & ~is_sf)\n",
    "ax.hist(L_lya[mask], bins=np.linspace(42, 46, 30), color='C2', histtype='step', label='Galaxies')\n",
    "\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlabel(r'log $L_{\\mathrm{Ly}\\alpha}$', fontsize=15)\n",
    "ax.set_ylabel('N', fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Err test\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "ax.hist(\n",
    "    (10 ** L_Arr[nice_lya & nice_z] - 10 ** L_lya[nice_lya & nice_z]) / L_e_Arr[nice_lya & nice_z],\n",
    "    bins=np.linspace(-3, 3, 20)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins_1 = 9\n",
    "N_bins_2 = 9\n",
    "bins = np.concatenate((\n",
    "    np.linspace(42, 43.5, N_bins_1 + 1),\n",
    "    np.linspace(43.5, 45.5, N_bins_2 + 1)[1:]\n",
    "))\n",
    "bin_centers = [(bins[k] + bins[k + 1]) / 2 for k in range(len(bins) - 1)]\n",
    "\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 10 ** 44.65\n",
    "alpha1 = -1.35\n",
    "phistar2 = 10 ** -3.45\n",
    "Lstar2 = 10 ** 42.93\n",
    "alpha2 = -1.93\n",
    "\n",
    "volume = z_volume(z_min, z_max, 200)\n",
    "\n",
    "bins2 = np.linspace(42, 46, 30)\n",
    "h_qso, _ = np.histogram(L_lya[is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "h_sf, _ = np.histogram(L_lya[is_sf & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "\n",
    "b_c = [0.5 * (bins[i] + bins[i + 1]) for i in range(len(bins) - 1)]\n",
    "bw = [bins[i + 1] - bins[i] for i in range(len(bins) - 1)]\n",
    "###################################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z]\n",
    "badh = L_lya[nice_lya & ~nice_z]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('Total', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z & is_qso]\n",
    "badh = L_lya[nice_lya & ~nice_z & is_qso]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut & is_qso], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('QSO', fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "goodh = L_lya[nice_lya & nice_z & is_sf]\n",
    "badh = L_lya[nice_lya & ~nice_z & is_sf]\n",
    "hg, bg = np.histogram(goodh, bins=bins)\n",
    "hb, _ = np.histogram(badh, bins=bins)\n",
    "totals, _ = np.histogram(L_lya[zspec_cut & is_sf], bins=bins)\n",
    "\n",
    "ax.plot(b_c, hg / totals, marker='^', label='Completeness', zorder=99)\n",
    "ax.plot(b_c, hg / (hg + hb), marker='s', label='Purity', zorder=99)\n",
    "\n",
    "ax.set_xlabel('$\\log L$', fontsize=15)\n",
    "\n",
    "ax.set_xlim((42, 45.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_title('SF', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2d_puricomp(L_Arr, L_lya, mag, L_bins):\n",
    "    fig = plt.figure(figsize=(7, 6))\n",
    "\n",
    "    height = 1.\n",
    "    width = 1.\n",
    "    height2 = 0.7\n",
    "    spacing = 0.1\n",
    "    cbar_width = 0.06\n",
    "\n",
    "    ax0 = fig.add_axes([0, height2 + spacing, width, height])\n",
    "    ax1 = fig.add_axes([width + spacing, height2 + spacing, width, height])\n",
    "    axc = fig.add_axes([2 * width + 1.5 * spacing, height2 + spacing, cbar_width, height])\n",
    "    ax2 = fig.add_axes([0, 0, width, height2])\n",
    "    ax3 = fig.add_axes([width + spacing, 0, width, height2])\n",
    "\n",
    "    L_bins = np.linspace(42, 46, 15 + 1)\n",
    "    r_bins = np.linspace(mag_min, mag_max, 15 + 1)\n",
    "\n",
    "    L_bins_c = np.array([0.5 * (L_bins[i] + L_bins[i + 1]) for i in range(len(L_bins) - 1)])\n",
    "\n",
    "    # Perturb L\n",
    "    \n",
    "    N_iter = 1000\n",
    "    h2d_nice_i = np.empty((len(L_bins) - 1, len(r_bins) - 1, N_iter))\n",
    "    h2d_sel_i = np.empty((len(L_bins) - 1, len(r_bins) - 1, N_iter))\n",
    "    h1d_nice_i = np.empty((len(L_bins) - 1, N_iter))\n",
    "    h1d_sel_i = np.empty((len(L_bins) - 1, N_iter))\n",
    "\n",
    "    for k in range(N_iter):\n",
    "        L_perturbed = np.log10(\n",
    "            10 ** L_Arr + L_e_Arr * np.random.randn(len(L_e_Arr))\n",
    "        )\n",
    "        L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "        h2d_nice_i[..., k], _, _ = np.histogram2d(\n",
    "            L_perturbed[nice_lya & nice_z],\n",
    "            mag[nice_lya & nice_z],\n",
    "            bins=[L_bins, r_bins]\n",
    "        )\n",
    "\n",
    "        h2d_sel_i[..., k], _, _ = np.histogram2d(\n",
    "            L_perturbed[nice_lya],\n",
    "            mag[nice_lya],\n",
    "            bins=[L_bins, r_bins]\n",
    "        )\n",
    "\n",
    "        h1d_nice_i[..., k], _ = np.histogram(L_perturbed[nice_lya & nice_z], bins=L_bins)\n",
    "        h1d_sel_i[..., k], _ = np.histogram(L_perturbed[nice_lya], bins=L_bins)\n",
    "\n",
    "    # Take the median\n",
    "    h2d_nice = np.median(h2d_nice_i, axis=2)\n",
    "    h2d_sel = np.median(h2d_sel_i, axis=2)\n",
    "    h1d_nice = np.median(h1d_nice_i, axis=1)\n",
    "    h1d_sel = np.median(h1d_sel_i, axis=1)\n",
    "\n",
    "    h2d_parent, _, _ = np.histogram2d(\n",
    "        L_lya[zspec_cut & mag_cut & ew_cut],\n",
    "        mag[zspec_cut & mag_cut & ew_cut],\n",
    "        bins=[L_bins, r_bins]\n",
    "    )\n",
    "    h1d_parent, _ = np.histogram(L_lya[zspec_cut & mag_cut & ew_cut], bins=L_bins)\n",
    "\n",
    "    cmap = 'Spectral'\n",
    "\n",
    "    puri2d = h2d_nice / h2d_sel\n",
    "    comp2d = h2d_nice / h2d_parent\n",
    "    puri1d = h1d_nice / h1d_sel\n",
    "    comp1d = h1d_nice / h1d_parent\n",
    "\n",
    "    puri1d[np.isnan(puri1d)] = 0.\n",
    "    comp1d[np.isnan(comp1d)] = 0.\n",
    "\n",
    "    ### PLOT STUFF\n",
    "\n",
    "    sns.heatmap(puri2d.T, ax=ax0, vmin=0, vmax=1, cbar_ax=axc, cmap=cmap)\n",
    "    sns.heatmap(comp2d.T, ax=ax1, vmin=0, vmax=1, cbar=False, cmap=cmap)\n",
    "\n",
    "    ax2.plot(L_bins_c, puri1d, marker='s')\n",
    "    ax3.plot(L_bins_c, comp1d, marker='s')\n",
    "\n",
    "    ### TICKS\n",
    "\n",
    "    xticks = range(len(L_bins))\n",
    "    yticks = range(len(r_bins))\n",
    "    xtick_labels = ['{0:0.1f}'.format(n) for n in L_bins]\n",
    "    ytick_labels = ['{0:0.1f}'.format(n) for n in r_bins]\n",
    "\n",
    "\n",
    "    ax0.set_yticks(yticks)\n",
    "    ax0.set_yticklabels(ytick_labels, rotation='horizontal')\n",
    "    ax0.set_xticks(xticks)\n",
    "    ax0.set_xticklabels(xtick_labels, rotation='vertical')\n",
    "    ax0.yaxis.set_ticks_position('both')\n",
    "    ax0.xaxis.set_ticks_position('both')\n",
    "    ax0.tick_params(axis='y', direction='in', labelsize=14)\n",
    "    ax0.tick_params(axis='x', direction='in', labelsize=14)\n",
    "\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_yticklabels(ytick_labels, rotation='horizontal')\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels(xtick_labels, rotation='vertical')\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax1.tick_params(axis='y', direction='in', labelsize=14)\n",
    "    ax1.tick_params(axis='x', direction='in', labelsize=14)\n",
    "\n",
    "    axc.tick_params(labelsize=14)\n",
    "    ax2.tick_params(labelsize=14)\n",
    "    ax3.tick_params(labelsize=14)\n",
    "\n",
    "    ## Spines\n",
    "    ax0.spines[:].set_visible(True)\n",
    "    ax1.spines[:].set_visible(True)\n",
    "\n",
    "    ## Axes labels\n",
    "    # ax0.set_ylabel('rSDSS')\n",
    "    # ax0.set_xlabel('log L$_\\mathrm{Lya}$')\n",
    "    # ax1.set_ylabel('rSDSS')\n",
    "    # ax1.set_xlabel('log L$_\\mathrm{Lya}$')\n",
    "\n",
    "    ## Axis lims\n",
    "    ax2.set_ylim((0, 1))\n",
    "    # ax3.set_ylim((0, 1))\n",
    "\n",
    "    ## Titles\n",
    "    ax0.set_title('Purity', fontsize=25)\n",
    "    ax1.set_title('Completeness', fontsize=25)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    np.save('npy/puri2d.npy', puri2d)\n",
    "    np.save('npy/comp2d.npy', comp2d)\n",
    "    np.save('npy/puricomp2d_L_bins.npy', L_bins)\n",
    "    np.save('npy/puricomp2d_r_bins.npy', r_bins)\n",
    "\n",
    "    return puri2d, comp2d, L_bins, r_bins\n",
    "puri2d, comp2d, L_bins, r_bins = make_2d_puricomp(L_Arr, L_lya, mag, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Lya_intrisic_completeness(L, z, starprob=None):\n",
    "#     if starprob == None:\n",
    "#         starprob = np.zeros(L.shape)\n",
    "\n",
    "#     isstar = (starprob >= 0.5)\n",
    "\n",
    "#     ## MiniJPAS limiting r magnitudes\n",
    "#     mag = np.ones(L.shape) * 23.6\n",
    "#     mag[~isstar] = 22.7\n",
    "\n",
    "#     Fline = 10 ** L / (cosmo.luminosity_distance(z).to(u.cm).value ** 2 * 4*np.pi)\n",
    "#     fcont = mag_to_flux(mag, 6750)\n",
    "\n",
    "#     EW_max = Fline / fcont / (1 + z)\n",
    "\n",
    "#     ew_x = np.linspace(20, 1000, 10000)\n",
    "#     w_0 = 75\n",
    "#     ew_dist = lambda ew_xx: np.exp(-ew_xx / w_0)\n",
    "\n",
    "#     total_ew = simpson(ew_dist(ew_x), ew_x)\n",
    "\n",
    "#     completeness = np.empty(L.shape)\n",
    "\n",
    "#     for src in range(len(L)):\n",
    "#         src_ew_x = np.linspace(20, EW_max[src], 1000)\n",
    "#         completeness[src] = simpson(ew_dist(src_ew_x), src_ew_x) / total_ew\n",
    "\n",
    "#     return completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intcomp = Lya_intrisic_completeness(L_Arr[nice_lya], z_Arr[nice_lya], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection algorithm weights\n",
    "# weights = puricomp2d_weights(L_Arr[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, weights=True):\n",
    "    N_bins = len(bins) - 1\n",
    "\n",
    "    hist_i_mat = np.zeros((1000, N_bins))\n",
    "\n",
    "    for k in range(1000):\n",
    "        # randN = np.random.randn(N_sources)\n",
    "        # L_perturbation = np.zeros(N_sources)\n",
    "        # L_perturbation[randN >= 0.] = L_err[0, randN >= 0.] * randN[randN >= 0.]\n",
    "        # L_perturbation[randN < 0.] = L_err[1, randN < 0.] * randN[randN < 0.]\n",
    "\n",
    "        # L_perturbed = np.log10(10 ** (L_Arr - L_bias) + L_perturbation)\n",
    "        L_perturbed = np.log10(\n",
    "            10 ** L_Arr + L_e_Arr * np.random.randn(len(L_e_Arr))\n",
    "        )\n",
    "        L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "        w = puricomp2d_weights(\n",
    "            L_perturbed[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins\n",
    "        )\n",
    "        if not weights:\n",
    "            w[:] = 1\n",
    "        hist = np.histogram(L_perturbed[nice_lya], bins=bins)[0]\n",
    "        hist_poiss_err = np.round(\n",
    "            hist[0] ** 0.5 * np.random.randn(len(bins) - 1), 0\n",
    "        ).astype(int)\n",
    "\n",
    "        hist_binnumber = binned_statistic(L_perturbed[nice_lya], None, 'count', bins=bins)[2]\n",
    "\n",
    "        L_Arr_to_hist = np.array([])\n",
    "        w_Arr_to_hist = np.array([])\n",
    "        for bin in range(N_bins):\n",
    "            where_bin = np.where(hist_binnumber == bin + 1)[0]\n",
    "            try:\n",
    "                idx = np.random.choice(\n",
    "                    where_bin, size=(hist_poiss_err[bin] + hist[bin]),\n",
    "                    replace=True\n",
    "                )\n",
    "                L_Arr_to_hist = np.hstack([L_Arr_to_hist, L_perturbed[nice_lya][idx]])\n",
    "                w_Arr_to_hist = np.hstack([w_Arr_to_hist, w[idx]])\n",
    "            except:\n",
    "                pass\n",
    "        hist_i_mat[k], _ = np.histogram(L_Arr_to_hist, bins=bins, weights=w_Arr_to_hist)\n",
    "\n",
    "    L_LF_err_percentiles = np.percentile(hist_i_mat, [16, 50, 84], axis=0)\n",
    "    return L_LF_err_percentiles\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins)\n",
    "L_LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, False)\n",
    "total_hist = L_LF_err_percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_bins = np.array([(bins[i] + bins[i + 1]) / 2 for i in range(len(bins) - 1)])\n",
    "\n",
    "bin_width = np.array([bins[i + 1] - bins[i] for i in range(len(bins) - 1)])\n",
    "\n",
    "volume = z_volume(z_min, z_max, 200)\n",
    "\n",
    "yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "xerr = bin_width / 2\n",
    "ax.errorbar(LF_bins, hist_median / volume / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus], xerr=xerr,\n",
    "    marker='.', linestyle='', markersize=15, c='red',\n",
    "    label='Corrected median histogram')\n",
    "\n",
    "bins2 = np.linspace(42, 46, 30)\n",
    "b_c = [(bins2[i] + bins2[i + 1]) * 0.5 for i in range(len(bins2) - 1)]\n",
    "bw = bins2[1] - bins2[0]\n",
    "h_qso, b = np.histogram(L_lya[is_qso & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "h_sf, b = np.histogram(L_lya[is_sf & zspec_cut & ew_cut & mag_cut], bins2)\n",
    "\n",
    "ax.plot(b_c, (h_qso + h_sf) / bw / volume, c='dimgray', zorder=-99, label='Mock', ls='--')\n",
    "\n",
    "Lx = np.linspace(10 ** 42, 10 ** 45.5, 1000)\n",
    "Phi = double_schechter(\n",
    "                Lx, phistar2, Lstar2, alpha2, phistar1, Lstar1, alpha1\n",
    "            ) * Lx * np.log(10)\n",
    "\n",
    "ax.plot(np.log10(Lx), Phi)\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-3)\n",
    "ax.set_xlim(42., 46)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlabel('log L', fontsize=15)\n",
    "ax.set_ylabel('$\\Phi$ [Mpc$^{-3}$ $\\Delta$ log L $^{-1}$]', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
