{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_functions import *\n",
    "import glob\n",
    "\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load QSO catalog\n",
    "filename = ('/home/alberto/cosmos/JPAS_mocks_sep2021/'\n",
    "    'JPAS_mocks_classification_01sep_model11/Fluxes/Qso_jpas_mock_flam_train.cat')\n",
    "\n",
    "my_filter_order = np.arange(60)\n",
    "my_filter_order[[-4, -3, -2, -1]] = np.array([1, 12, 28, 43])\n",
    "my_filter_order[1:-4] += 1\n",
    "my_filter_order[12:-4] += 1\n",
    "my_filter_order[28:-4] += 1\n",
    "my_filter_order[43:-4] += 1\n",
    "\n",
    "qso_flx = pd.read_csv(\n",
    "    filename, sep=' ', usecols=range(2, 2 + 60)\n",
    ").to_numpy().T[my_filter_order]\n",
    "qso_err = pd.read_csv(\n",
    "    filename, sep=' ', usecols=range(2 + 60, 2 + 60 + 60)\n",
    ").to_numpy().T[my_filter_order]\n",
    "qso_zspec = pd.read_csv(filename, sep=' ', usecols=[127]).to_numpy().reshape(-1, )\n",
    "\n",
    "# Randomly sample sources corresponding to 100 deg2\n",
    "idx = np.random.randint(0, 100000, 51000)\n",
    "qso_flx = qso_flx[:, idx]\n",
    "qso_err = qso_err[:, idx]\n",
    "qso_zspec = qso_zspec[idx]\n",
    "\n",
    "Lya_fts = pd.read_csv('csv/Lya_fts.csv')\n",
    "EW_qso = np.abs(Lya_fts.LyaEW)[idx] / qso_zspec\n",
    "\n",
    "# Apply errors\n",
    "np.random.seed(22)\n",
    "qso_flx += qso_err * np.random.normal(size=qso_err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SF catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/LAE_10deg_z2-5/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "sf_flx = data.to_numpy()[:, 1 : 60 + 1].T\n",
    "sf_err = data.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "mag_noerr = flux_to_mag(sf_flx, w_central.reshape(-1, 1))\n",
    "mag_noerr[np.isnan(mag_noerr)] = 99.\n",
    "\n",
    "sf_flx += np.random.normal(size=(sf_err.shape)) * sf_err\n",
    "\n",
    "mag = flux_to_mag(sf_flx, w_central.reshape(-1, 1))\n",
    "mag[np.isnan(mag)] = 99.\n",
    "\n",
    "files2 = []\n",
    "for i in range(len(files)):\n",
    "    files2.append(f'{filename}SEDs{i + 1}.csv')\n",
    "    files2.sort()\n",
    "fi = []\n",
    "for name in files2:\n",
    "    fi.append(pd.read_csv(name, header=None))\n",
    "\n",
    "mock = {}\n",
    "mock['SEDs'] = pd.concat(fi, axis=0, ignore_index=True).to_numpy()\n",
    "mock['w_Arr'] = np.load(filename + 'w_Arr.npy')\n",
    "\n",
    "EW_sf = data['EW0'].to_numpy()\n",
    "sf_zspec = data['z'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_flx = np.hstack((qso_flx, sf_flx))\n",
    "pm_err = np.hstack((qso_err, sf_err))\n",
    "zspec = np.concatenate((qso_zspec, sf_zspec))\n",
    "EW_lya = np.concatenate((EW_qso, EW_sf))\n",
    "\n",
    "N_sf = sf_flx.shape[1]\n",
    "N_qso = qso_flx.shape[1]\n",
    "\n",
    "del sf_flx, sf_err, qso_flx, qso_err, sf_zspec, qso_zspec, EW_sf, EW_qso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lya = 1215.67 # A\n",
    "N_sources = pm_flx.shape[1]\n",
    "N_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx, w_central.reshape(-1, 1))\n",
    "mag[np.isnan(mag)] = 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 40)\n",
    "lya_lines, lya_cont_lines = identify_lines(line, pm_flx, pm_err, first=True)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    160, obs=True)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)\n",
    "\n",
    "# Compute z\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "nice_z = np.abs(z_Arr - zspec) < 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 18\n",
    "mag_max = 24\n",
    "\n",
    "z_min = 2.5\n",
    "z_max = 3.5\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_lya, z_Arr\n",
    ") & (mag[-2] > mag_min) & z_cut & (mag[-2] < mag_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fractions QSO / SF\n",
    "\n",
    "good_qso = len(np.where(np.where(nice_lya & nice_z)[0] < N_qso)[0])\n",
    "bad_qso = len(np.where(np.where(nice_lya & ~nice_z)[0] < N_qso)[0])\n",
    "N_sel = count_true(nice_lya)\n",
    "N_sel_good = count_true(nice_lya & nice_z)\n",
    "\n",
    "\n",
    "good_frac = good_qso / N_sel_good\n",
    "bad_frac = bad_qso / (N_sel - N_sel_good)\n",
    "\n",
    "purity = count_true(nice_z & nice_lya) / count_true(nice_lya)\n",
    "\n",
    "print(f'Good QSOs: {good_qso} | Bad QSOs: {bad_qso}')\n",
    "print(f'Good SFs: {N_sel_good - good_qso} | Bad SFs: {N_sel - N_sel_good - bad_qso}')\n",
    "print()\n",
    "print('Good frac: {0:0.2f}'.format(good_frac))\n",
    "print('Bad frac: {0:0.2f}'.format(bad_frac))\n",
    "print()\n",
    "print('Purity = {0:0.2f}'.format(purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EW_err(fnb, fnb_err, fcont, fcont_err, z, z_err, fwhm):\n",
    "    e1 = fnb_err * fwhm / fcont / (1 + z)\n",
    "    e2 = fcont_err * fwhm / (-fcont ** -2 * (1 + z))\n",
    "    e3 = z_err * fwhm * (fnb - fcont) / fcont * (-1) / ((1 + z) ** 2)\n",
    "\n",
    "    return (e1**2 + e2**2 + e3**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EW_nb_Arr = np.zeros(N_sources)\n",
    "EW_nb_e = np.copy(EW_nb_Arr)\n",
    "L_Arr = np.zeros(N_sources)\n",
    "\n",
    "for src in range(N_sources):\n",
    "    l = lya_lines[src]\n",
    "    EW_nb_Arr[src] = nb_fwhm_Arr[l] * (pm_flx[l, src] - cont_est_lya[l, src])\\\n",
    "        / cont_est_lya[l, src] / (1 + np.array(z_Arr[src]))\n",
    "    EW_nb_e[src] = EW_err(\n",
    "        pm_flx[l, src], pm_err[l, src], cont_est_lya[l, src], cont_err_lya[l, src],\n",
    "        z_Arr[src], 0.06, 147\n",
    "    )\n",
    "\n",
    "    dL = cosmo.luminosity_distance(z_Arr[src]).to(u.cm).value\n",
    "    L_Arr[src] = np.log10(EW_nb_Arr[src] * cont_est_lya[l, src] * 4 * np.pi * dL**2 / 147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "h = ax.hist2d(zspec[nice_lya], z_Arr[nice_lya],\n",
    "    bins=(np.linspace(0, 3.5, 15), np.linspace(2.5, 3.5, 15)))\n",
    "fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "x = np.linspace(2, 4, 100)\n",
    "ax.plot(x, x, c='red')\n",
    "\n",
    "ax.set_xlabel('z$_\\mathrm{spec}$', fontsize=15)\n",
    "ax.set_ylabel('Retrieved z', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in np.random.choice(np.where(nice_lya)[0], 20):\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    ax = plot_JPAS_source(pm_flx[:, src], pm_err[:, src])\n",
    "    print(f'z_NB = {z_Arr[src]}')\n",
    "    print(f'zspec = {zspec[src]}')\n",
    "    print('EW0 = {0:0.1f} +- {1:0.1f}'.format(EW_nb_Arr[src], EW_nb_e[src]))\n",
    "    # print(f'EW0_lya = {EW_lya[src]}')\n",
    "    ax.axvline(w_central[lya_lines[src]], label='Selected NB')\n",
    "    if zspec[src] > 1.9:\n",
    "        ax.axvline(w_lya * (1 + zspec[src]), ls='--', c='red', label=r'Lya $\\lambda$')\n",
    "    ax.plot(w_central[1:54], cont_est_lya[1:-2, src], ls='--', c='black')\n",
    "\n",
    "    ax.legend(fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "bins = np.linspace(18, 26, 20)\n",
    "\n",
    "ax.hist(mag[-2][nice_lya & z_cut & nice_z], label='Good z', histtype='step', bins=bins)\n",
    "ax.hist(mag[-2][nice_lya & z_cut & ~nice_z], label='Bad z', histtype='step', bins=bins)\n",
    "\n",
    "ax.legend(fontsize=15, loc=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "####\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "bins = np.linspace(0, 300, 30)\n",
    "\n",
    "goodh = EW_nb_Arr[nice_lya & nice_z]\n",
    "badh = EW_nb_Arr[nice_lya & ~nice_z]\n",
    "\n",
    "ax.hist(goodh, label='Good z', histtype='step', bins=bins)\n",
    "ax.hist(badh, label='Bad z', histtype='step', bins=bins)\n",
    "\n",
    "ax.legend(fontsize=15, loc=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "####\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "bins = np.linspace(40.8, 43, 30)\n",
    "\n",
    "goodh = L_Arr[nice_lya & z_cut & nice_z]\n",
    "badh = L_Arr[nice_lya & z_cut & ~nice_z]\n",
    "\n",
    "ax.hist(goodh, label='Good z', histtype='step', bins=bins)\n",
    "ax.hist(badh, label='Bad z', histtype='step', bins=bins)\n",
    "\n",
    "ax.legend(fontsize=15, loc=2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
