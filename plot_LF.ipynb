{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import pandas as pd\n",
    "from minijpas_LF_and_puricomp import effective_volume\n",
    "from my_functions import double_schechter, bin_centers, z_volume\n",
    "from my_functions import central_wavelength, nb_fwhm, schechter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference LFs\n",
    "pathname = '/home/alberto/almacen/literature_LF_data'\n",
    "\n",
    "# Blanc 2011 (z=1.9--3.8)\n",
    "filename = f'{pathname}/blanc2011_allz.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "b11 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Blanc 2011 ($z=1.9-3.8$)',\n",
    "    'fmt': 'h',\n",
    "}\n",
    "\n",
    "# Gronwall 2007 (z=3.1)\n",
    "filename = f'{pathname}/gronwall2007_z3.1.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "g07 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Gronwall 2007 ($z=3.1$)',\n",
    "    'fmt': 'x'\n",
    "}\n",
    "\n",
    "# Konno 2016 (z=2.2)\n",
    "filename = f'{pathname}/konno2016_z2.2_corrected.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "k16 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Konno 2016 ($z=2.2$)',\n",
    "    'fmt': '^'\n",
    "}\n",
    "\n",
    "# Matthee 2017 (z=2.2)\n",
    "filename = f'{pathname}/matthee2017_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "m17a = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Matthee 2017 ($z=2.2$)',\n",
    "    'fmt': '*'\n",
    "}\n",
    "\n",
    "# Matthee 2017 (z=2.4)\n",
    "filename = f'{pathname}/matthee2017_z2.4.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "m17b = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Matthee 2017 ($z=2.4$)',\n",
    "    'fmt': '*'\n",
    "}\n",
    "\n",
    "# Ouchi 2008 (z=3.1)\n",
    "filename = f'{pathname}/ouchi2008_z3.1.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "u08 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Ouchi 2008 ($z=3.1$)',\n",
    "    'fmt': 'o'\n",
    "}\n",
    "\n",
    "# Sobral 2016 (z=2.2)\n",
    "filename = f'{pathname}/sobral2016_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s16 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Sobral 2016 ($z=2.2$)',\n",
    "    'fmt': 'D'\n",
    "}\n",
    "\n",
    "# Sobral 2017 (z=2.2)\n",
    "filename = f'{pathname}/sobral2017_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s17 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Sobral 2017 ($z=2.2$)',\n",
    "    'fmt': 'D'\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=2.5)\n",
    "filename = f'{pathname}/sobral2018_z2.5.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18a = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Sobral 2018 ($z=2.5$)',\n",
    "    'fmt': 'D'\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.0)\n",
    "filename = f'{pathname}/sobral2018_z3.0.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18b = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Sobral 2018 ($z=3.0$)',\n",
    "    'fmt': 'D'\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.2)\n",
    "filename = f'{pathname}/sobral2018_z3.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18c = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'label': 'Sobral 2018 ($z=3.2$)',\n",
    "    'fmt': 'D'\n",
    "}\n",
    "\n",
    "# Spinoso 2020\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0395_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z225 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'label': 'Spinoso 2020 ($z=2.25$)',\n",
    "    'fmt': 'X'\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0410_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z237 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'label': 'Spinoso 2020 ($z=2.37$)',\n",
    "    'fmt': 'X'\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0430_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z254 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'label': 'Spinoso 2020 ($z=2.54$)',\n",
    "    'fmt': 'X'\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0515_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z324 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'label': 'Spinoso 2020 ($z=3.24$)',\n",
    "    'fmt': 'X'\n",
    "}\n",
    "\n",
    "# Zhang 2021 (z=2.0-3.5)\n",
    "df = pd.read_csv('csv/Zhang2021_LF.csv')\n",
    "z21 = {\n",
    "    'logL': df['Llya'],\n",
    "    'Phi': df['Phi'],\n",
    "    'yerr_plus': df['yerr_plus'] - df['Phi'],\n",
    "    'yerr_minus': df['Phi'] - df['yerr_minus'],\n",
    "    'label': 'Zhang 2021 ($z=2.0-3.5$)',\n",
    "    'fmt': 'd'\n",
    "}\n",
    "\n",
    "# Liu 2022 (z=1.88-3.53)\n",
    "df = pd.read_csv('csv/Liu_LF.csv')\n",
    "l22 = {\n",
    "    'logL': df['logLya'],\n",
    "    'Phi': df['Phi'],\n",
    "    'yerr_plus': df['yerr'],\n",
    "    'yerr_minus': df['yerr'],\n",
    "    'label': 'Liu 2022 ($z=1.9-3.5$)',\n",
    "    'fmt': 'v'\n",
    "}\n",
    "\n",
    "# Assign colors\n",
    "LF_ref_list = [b11, g07, k16, m17a, m17b, u08, s16, s17, s18a,\n",
    "               s18b, s18c, ds20_z225, ds20_z237, ds20_z254,\n",
    "               ds20_z324, z21, l22]\n",
    "for i, lf_dict in enumerate(LF_ref_list):\n",
    "    lf_dict['color'] = f'C{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_list = [[1, 5], [4, 8], [7, 11], [10, 14], [13, 17], [16, 20]]\n",
    "qso_factor = 1.0\n",
    "comb_nbs_list = nbs_list\n",
    "\n",
    "w_central = central_wavelength()\n",
    "w_lya = 1215.67\n",
    "nb_fwhm_Arr = nb_fwhm(np.arange(60))\n",
    "L_binning = np.load('npy/L_nb_err_binning.npy')\n",
    "b = np.log10(L_binning)\n",
    "LF_bins = np.array([(b[i] + b[i + 1]) / 2 for i in range(len(b) - 1)])\n",
    "bin_width = np.array([b[i + 1] - b[i] for i in range(len(b) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_puricomp2d import load_puricomp1d\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7), sharey=True)\n",
    "\n",
    "comp_den_def = None\n",
    "total_comp_list = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    # A text with the redshift interval\n",
    "    ax.set_title(fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$')\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    # Define the survey list in order\n",
    "    survey_list = [f'AEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "    # Bin centers\n",
    "    bc = [puricomp_bins[i: i + 2].sum() * 0.5 for i in range(len(puricomp_bins) - 1)]\n",
    "\n",
    "    # Plot the individual comps\n",
    "    for j, comp in enumerate(comp_list):\n",
    "        ax.plot(bc, comp, ls=':', alpha=0.6, marker='s', markersize=10,\n",
    "                label=survey_list[j], c=f'C{j + 2}')\n",
    "\n",
    "    # Total comp\n",
    "    total_comp_num = (np.array(comp_list) *\n",
    "                      np.array(comp_den_list)).sum(axis=0)\n",
    "    total_comp_den = np.array(comp_den_list).sum(axis=0)\n",
    "    total_comp_err = (total_comp_num / total_comp_den ** 2 +\n",
    "                      total_comp_num ** 2 / total_comp_den ** 4 * total_comp_num) ** 0.5\n",
    "    total_comp_err[~np.isfinite(total_comp_err)] = 0\n",
    "    if comp_den_def is None:\n",
    "        comp_den_def = total_comp_den\n",
    "        comp_num_def = total_comp_num\n",
    "    else:\n",
    "        comp_den_def += total_comp_den\n",
    "        comp_num_def += total_comp_num\n",
    "    total_comp = total_comp_num / total_comp_den\n",
    "    total_comp[~np.isfinite(total_comp)] = 0\n",
    "    total_comp_list.append(total_comp)\n",
    "    ax.errorbar(bc, total_comp, ls='-', fmt='s', c='k',\n",
    "                markersize=9, yerr=total_comp_err,\n",
    "                capsize=4)\n",
    "    # Dummy point\n",
    "    ax.errorbar([], [], markersize=9, c='k', label='Total', marker='s', ls='')\n",
    "   \n",
    "    ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    # ax.set_xticks([43, 43.5, 44, 44.5, 45, 45.5])\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=20)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'Completeness', fontsize=20)\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Multi_comp.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7), sharey=True)\n",
    "\n",
    "puri_den_def = None\n",
    "total_puri_list = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    # A text with the redshift interval\n",
    "    ax.set_title(fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$')\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    # Define the survey list in order\n",
    "    survey_list = [f'AEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "    # Bin centers\n",
    "    bc = [puricomp_bins[i: i + 2].sum() * 0.5 for i in range(len(puricomp_bins) - 1)]\n",
    "\n",
    "    # Plot the individual puris\n",
    "    for j, puri in enumerate(puri_list):\n",
    "        ax.plot(bc, puri, ls=':', alpha=0.6, marker='s',\n",
    "                markersize=10, label=survey_list[j], c=f'C{j + 2}')\n",
    "\n",
    "    # Total puri\n",
    "    total_puri_num = (np.array(puri_list) *\n",
    "                      np.array(puri_den_list)).sum(axis=0)\n",
    "    total_puri_den = np.array(puri_den_list).sum(axis=0)\n",
    "    total_puri = total_puri_num / total_puri_den\n",
    "    total_puri_err = (total_puri_num / total_puri_den ** 2 +\n",
    "                      total_puri_num ** 2 / total_puri_den ** 4 * total_puri_num) ** 0.5\n",
    "    total_puri_err[~np.isfinite(total_puri_err)] = 0\n",
    "    if puri_den_def is None:\n",
    "        puri_den_def = total_puri_den\n",
    "        puri_num_def = total_puri_num\n",
    "    else:\n",
    "        puri_den_def += total_puri_den\n",
    "        puri_num_def += total_puri_num\n",
    "    total_puri[~np.isfinite(total_puri)] = 0.\n",
    "    total_puri_list.append(total_puri)\n",
    "    ax.errorbar(bc, total_puri, ls='-', fmt='s', c='k',\n",
    "                markersize=9, yerr=total_puri_err,\n",
    "                capsize=4)\n",
    "    np.save(f'npy/puri_1d_{nb1}-{nb2}', total_puri)\n",
    "    np.save(f'npy/puri_1d_bc', bc)\n",
    "\n",
    "    # Dummy point\n",
    "    ax.errorbar([], [], markersize=9, c='k', label='Total', marker='s', ls='')\n",
    "\n",
    "    ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    # ax.set_xticks([43, 43.5, 44, 44.5, 45, 45.5])\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(\n",
    "            r'$\\log L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=20)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'Purity', fontsize=20)\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Multi_puri.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_puricomp(puri, comp, min_puri=0.2, min_comp=0.2):\n",
    "    return (puri > min_puri) & (comp > min_comp)\n",
    "\n",
    "min_N_bin = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharey=True)\n",
    "\n",
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(np.arange(60))\n",
    "w_lya = 1215.67\n",
    "\n",
    "# My fit\n",
    "Lstar_fit = 44.61\n",
    "Phistar_fit = -6.03\n",
    "alpha = -1.5\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "Phi_center = schechter(Lx, 10**Phistar_fit, 10**Lstar_fit, alpha) * Lx * np.log(10)\n",
    "\n",
    "reference_LFs = [\n",
    "    [s17, m17b, k16, ds20_z225, ds20_z237],\n",
    "    [s18a, m17b, b11, ds20_z237],\n",
    "    [s18b, u08, b11, ds20_z324],\n",
    "    [s18c, s18b, u08, b11, ds20_z324],\n",
    "    [b11, u08, s18b, s18c],\n",
    "    [b11]\n",
    "]\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    this_hist = None\n",
    "    this_volume = effective_volume(nb1, nb2, 'both')\n",
    "    for survey_name in survey_list:\n",
    "            pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "            filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "            hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "            if this_hist is None:\n",
    "                this_hist = hist_i_mat\n",
    "            else:\n",
    "                this_hist += hist_i_mat\n",
    "            filename_dict = f'{pathname}/LFs.pkl'\n",
    "            with open(filename_dict, 'rb') as file:\n",
    "                LF_raw = pickle.load(file)['LF_total_raw']\n",
    "\n",
    "    L_LF_err_percentiles = np.percentile(this_hist, [16, 50, 84], axis=0)\n",
    "    LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "    LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "    yerr_plus = (hist_median + LF_err_plus **\n",
    "                        2) ** 0.5 / bin_width / this_volume\n",
    "    yerr_minus = (hist_median + LF_err_minus **\n",
    "                        2) ** 0.5 / bin_width / this_volume\n",
    "\n",
    "\n",
    "    this_LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': hist_median / bin_width / this_volume,\n",
    "        'LF_total_err': [yerr_minus, yerr_plus],\n",
    "        'LF_total_uncorr': LF_raw,\n",
    "    }\n",
    "\n",
    "    this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "    this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "    \n",
    "    ax.text(42.6, 1e-2, fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$', fontsize=13)\n",
    "    \n",
    "    puricomp_mask = mask_puricomp(this_puri, this_comp)\\\n",
    "        & (this_LF_dict['LF_total_uncorr'] * bin_width * this_volume >= min_N_bin)\n",
    "    ax.errorbar(this_LF_dict['LF_bins'][puricomp_mask],\n",
    "            this_LF_dict['LF_total'][puricomp_mask],\n",
    "            yerr=np.array(this_LF_dict['LF_total_err'])[:2, puricomp_mask],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='k', markeredgecolor='k', markerfacecolor='red',\n",
    "            markeredgewidth=1, markersize=8,\n",
    "            capsize=4, label='This work (good points)', zorder=99)\n",
    "    # Dummy for legend\n",
    "    ax.plot([], [], ls='', marker='s', markersize=8, markerfacecolor='none',\n",
    "            markeredgecolor='k', label='This work (bad points)')\n",
    "    ax.errorbar(this_LF_dict['LF_bins'][~puricomp_mask],\n",
    "            this_LF_dict['LF_total'][~puricomp_mask],\n",
    "            yerr=np.array(this_LF_dict['LF_total_err'])[:2, ~puricomp_mask],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='k', markeredgecolor='k', markerfacecolor='none',\n",
    "            markeredgewidth=1, markersize=8,\n",
    "            capsize=4, zorder=99)\n",
    "    ax.plot(this_LF_dict['LF_bins'], this_LF_dict['LF_total_uncorr'],\n",
    "            marker='^', markerfacecolor='none', markeredgecolor='dimgray',\n",
    "            markeredgewidth=1, markersize=8, ls='', label='This work (uncorrected)',\n",
    "            zorder=97)\n",
    "\n",
    "    for j, lf in enumerate(reference_LFs[i]):\n",
    "        ax.errorbar(lf['logL'], lf['Phi'],\n",
    "                    yerr=[lf['yerr_minus'], lf['yerr_plus']],\n",
    "                    linestyle='', fmt=lf['fmt'], c=lf['color'],\n",
    "                    alpha=0.8, label=lf['label'], capsize=3, zorder=i)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=15)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log L^{-1}$]', fontsize=15)\n",
    "\n",
    "    ax.set_ylim(1e-8, 1e-1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.set_xticks(np.arange(42.5, 46, 0.5))\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    order = np.arange(len(handles))\n",
    "    order[:3] = [2, 0, 1]\n",
    "    ax.legend(np.array(handles, dtype=object)[order],\n",
    "              np.array(labels, dtype=object)[order],\n",
    "              fontsize=10, ncol=1, loc=0)\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.03, hspace=0.12)\n",
    "fig.savefig('figures/Multi_LF.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import schechter\n",
    "\n",
    "# My LF\n",
    "survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "total_volume = 0.\n",
    "for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "    total_volume += effective_volume(this_nb_min, this_nb_max, 'both')\n",
    "masked_volume = None\n",
    "hist_mat = None\n",
    "LF_raw = None\n",
    "for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "    this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "    this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "    this_hist = None\n",
    "    for survey_name in survey_list:\n",
    "        pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "        filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "        hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "        if this_hist is None:\n",
    "            this_hist = hist_i_mat\n",
    "        else:\n",
    "            this_hist += hist_i_mat\n",
    "    this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "    this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, 'both')\n",
    "\n",
    "    filename_dict = f'{pathname}/LFs.pkl'\n",
    "    with open(filename_dict, 'rb') as file:\n",
    "        this_LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "        if LF_raw is None:\n",
    "            LF_raw = this_LF_raw\n",
    "        else:\n",
    "            LF_raw += this_LF_raw\n",
    "        \n",
    "    # Set masked bins by puricomp_mask to 0\n",
    "    puricomp_mask = mask_puricomp(this_puri, this_comp) & (this_LF_raw >= min_N_bin)\n",
    "    this_hist[:, ~puricomp_mask] = 0.\n",
    "    this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "    if masked_volume is None:\n",
    "        masked_volume = this_volume\n",
    "    else:\n",
    "        masked_volume += this_volume\n",
    "\n",
    "    if hist_mat is None:\n",
    "        hist_mat = this_hist\n",
    "    else:\n",
    "        hist_mat = hist_mat + this_hist\n",
    "\n",
    "hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "mask_low_N = (LF_raw < min_N_bin)\n",
    "for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "    h[mask_low_N] = 0.\n",
    "\n",
    "volwid = total_volume * bin_width\n",
    "yerr_plus = (hist_median + volwid * (LF_err_plus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "yerr_minus = (hist_median + volwid * (LF_err_minus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "\n",
    "LF_dict = {\n",
    "    'LF_bins': LF_bins,\n",
    "    'LF_total': hist_median,\n",
    "    'LF_total_uncorr': LF_raw / total_volume,\n",
    "    'LF_total_err': [yerr_minus, yerr_plus]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# My LF\n",
    "ax.errorbar(LF_dict['LF_bins'], LF_dict['LF_total'],\n",
    "            yerr=LF_dict['LF_total_err'][:2],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='k', markeredgecolor='k', markerfacecolor='red',\n",
    "            markeredgewidth=1.5, markersize=8,\n",
    "            capsize=4, label='This work (corrected)', zorder=99)\n",
    "\n",
    "# My uncorr LF\n",
    "ax.plot(LF_dict['LF_bins'], LF_dict['LF_total_uncorr'],\n",
    "        marker='^', markerfacecolor='none', markeredgecolor='dimgray',\n",
    "        markeredgewidth=2, markersize=8, ls='', label='This work (uncorrected)',\n",
    "        zorder=97)\n",
    "\n",
    "# Other LFs\n",
    "ref_LFs_to_plot = [l22, z21]\n",
    "for i, lf in enumerate(ref_LFs_to_plot):\n",
    "    ax.errorbar(lf['logL'], lf['Phi'],\n",
    "                yerr=[lf['yerr_minus'], lf['yerr_plus']],\n",
    "                linestyle='', fmt=lf['fmt'], c=lf['color'],\n",
    "                alpha=0.8, label=lf['label'], capsize=3, zorder=i)\n",
    "\n",
    "# Plot the reference LF curves\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 44.65\n",
    "alpha1 = -1.35\n",
    "phistar2 = -3.45\n",
    "Lstar2 = 42.93\n",
    "alpha2 = -1.93\n",
    "\n",
    "Phi_center = double_schechter(\n",
    "    Lx, phistar1, 10 ** Lstar1, alpha1, 10 ** phistar2, 10 ** Lstar2, alpha2\n",
    ") * Lx * np.log(10)\n",
    "\n",
    "ax.plot(\n",
    "    np.log10(Lx), Phi_center, ls='-.', alpha=0.7,\n",
    "    label='Spinoso2020 ($z=2.2-3.25$)', zorder=51,\n",
    "    color='C7'\n",
    ")\n",
    "\n",
    "phistar1 = 10 ** -3.41\n",
    "Lstar1 = 10 ** 42.87\n",
    "alpha1 = -1.7\n",
    "phistar2 = 10 ** -5.85\n",
    "Lstar2 = 10 ** 44.6\n",
    "alpha2 = -1.2\n",
    "\n",
    "Phi_center = double_schechter(\n",
    "    Lx, phistar1, Lstar1, alpha1, phistar2, Lstar2, alpha2\n",
    ") * Lx * np.log(10)\n",
    "\n",
    "ax.plot(\n",
    "    np.log10(Lx), Phi_center, ls='--', alpha=0.7,\n",
    "    label='Zhang2021 ($z=2-3.2$)', zorder=50,\n",
    "    color='C8'\n",
    ")\n",
    "\n",
    "\n",
    "# Dummy to add text to legend\n",
    "ax.plot([], [], ls='', label=r'$\\bf{z = 2.0-3.1}$')\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-2)\n",
    "ax.set_xlim(42.5, 45.5)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log L^{-1}$]', fontsize=15)\n",
    "\n",
    "ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "order = np.array([3, 0, 4, 5, 6, 1, 2])\n",
    "ax.legend(np.array(handles, dtype=object)[order],\n",
    "          np.array(labels, dtype=object)[order], fontsize=9, ncol=1)\n",
    "\n",
    "fig.savefig('figures/Combined_LF.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My LF\n",
    "survey_list_list = [\n",
    "    ['minijpasAEGIS001'],\n",
    "    ['minijpasAEGIS002'],\n",
    "    ['minijpasAEGIS003'],\n",
    "    ['minijpasAEGIS004'],\n",
    "    ['jnep'],\n",
    "    [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for jjj, survey_list in enumerate(survey_list_list):\n",
    "    total_volume = 0.\n",
    "    for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "        total_volume += effective_volume(this_nb_min, this_nb_max, 'both')\n",
    "    masked_volume = None\n",
    "    hist_mat = None\n",
    "    LF_raw = None\n",
    "    for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "        this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "        this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "        this_hist = None\n",
    "        for survey_name in survey_list:\n",
    "            pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "            filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "            hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "            if this_hist is None:\n",
    "                this_hist = hist_i_mat\n",
    "            else:\n",
    "                this_hist += hist_i_mat\n",
    "        this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "        this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, 'both') / 5\n",
    "\n",
    "        filename_dict = f'{pathname}/LFs.pkl'\n",
    "        with open(filename_dict, 'rb') as file:\n",
    "            this_LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "            if LF_raw is None:\n",
    "                LF_raw = this_LF_raw\n",
    "            else:\n",
    "                LF_raw += this_LF_raw\n",
    "            \n",
    "        # Set masked bins by puricomp_mask to 0\n",
    "        puricomp_mask = mask_puricomp(this_puri, this_comp) & (this_LF_raw >= min_N_bin)\n",
    "        this_hist[:, ~puricomp_mask] = 0.\n",
    "        this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "        if masked_volume is None:\n",
    "            masked_volume = this_volume\n",
    "        else:\n",
    "            masked_volume += this_volume\n",
    "\n",
    "        if hist_mat is None:\n",
    "            hist_mat = this_hist\n",
    "        else:\n",
    "            hist_mat = hist_mat + this_hist\n",
    "\n",
    "    hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "    L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "    LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "    LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "    mask_low_N = (LF_raw < min_N_bin)\n",
    "    for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "        h[mask_low_N] = 0.\n",
    "\n",
    "    volwid = total_volume * bin_width\n",
    "    yerr_plus = (hist_median + volwid * (LF_err_plus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "    yerr_minus = (hist_median + volwid * (LF_err_minus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "\n",
    "    LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': hist_median,\n",
    "        'LF_total_uncorr': LF_raw / total_volume,\n",
    "        'LF_total_err': [yerr_minus, yerr_plus]\n",
    "    }\n",
    "\n",
    "\n",
    "    # My LF\n",
    "    ax.errorbar(LF_dict['LF_bins'], LF_dict['LF_total'],\n",
    "                yerr=LF_dict['LF_total_err'][:2],\n",
    "                linestyle='', fmt='s',\n",
    "                ecolor='k', mfc=f'C{jjj + 3}', mec='k',\n",
    "                markeredgewidth=1.5, markersize=8,\n",
    "                capsize=4, label='This work (corrected)', zorder=99)\n",
    "\n",
    "# My uncorr LF\n",
    "ax.plot(LF_dict['LF_bins'], LF_dict['LF_total_uncorr'],\n",
    "        marker='^', markerfacecolor='none', markeredgecolor='dimgray',\n",
    "        markeredgewidth=2, markersize=8, ls='', label='This work (uncorrected)',\n",
    "        zorder=97)\n",
    "\n",
    "# Other LFs\n",
    "ref_LFs_to_plot = [l22, z21]\n",
    "for i, lf in enumerate(ref_LFs_to_plot):\n",
    "    ax.errorbar(lf['logL'], lf['Phi'],\n",
    "                yerr=[lf['yerr_minus'], lf['yerr_plus']],\n",
    "                linestyle='', fmt=lf['fmt'], c=lf['color'],\n",
    "                alpha=0.8, label=lf['label'], capsize=3, zorder=i)\n",
    "\n",
    "# Dummy to add text to legend\n",
    "ax.plot([], [], ls='', label=r'$\\bf{z = 2.0-3.1}$')\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-2)\n",
    "ax.set_xlim(42.5, 45.5)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log L^{-1}$]', fontsize=15)\n",
    "\n",
    "ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# order = np.array([3, 0, 4, 5, 6, 1, 2])\n",
    "# ax.legend(np.array(handles, dtype=object)[order],\n",
    "#         np.array(labels, dtype=object)[order], fontsize=9, ncol=1)\n",
    "\n",
    "fig.savefig('figures/Combined_LF_fields.pdf',\n",
    "            bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "total_puri_num = None\n",
    "\n",
    "for i in range(6):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    if total_puri_num is None:\n",
    "        total_puri_num = (np.array(puri_list) * np.array(puri_den_list))\n",
    "        total_puri_den = np.array(puri_den_list)\n",
    "        total_comp_num = (np.array(comp_list) * np.array(comp_den_list))\n",
    "        total_comp_den = np.array(comp_den_list)\n",
    "    else:\n",
    "        total_puri_num += (np.array(puri_list) * np.array(puri_den_list))\n",
    "        total_puri_den += np.array(puri_den_list)\n",
    "        total_comp_num += (np.array(comp_list) * np.array(comp_den_list))\n",
    "        total_comp_den += np.array(comp_den_list)\n",
    "\n",
    "for i, puri in enumerate(puri_list):\n",
    "    puri = total_puri_num[i] / total_puri_den[i]\n",
    "    axs[0].plot(bc, puri, ls='--', alpha=0.6, marker='s', markersize=10,\n",
    "                color=f'C{i + 2}', label=this_survey_list[i])\n",
    "\n",
    "for i, comp in enumerate(comp_list):\n",
    "    comp = total_comp_num[i] / total_comp_den[i]\n",
    "    axs[1].plot(bc, comp, ls='--', alpha=0.6, marker='s', markersize=10,\n",
    "                color=f'C{i + 2}')\n",
    "\n",
    "combined_puri = puri_num_def / puri_den_def\n",
    "combined_puri[~np.isfinite(combined_puri)] = 0.\n",
    "combined_comp = comp_num_def / comp_den_def\n",
    "combined_comp[~np.isfinite(combined_comp)] = 0.\n",
    "total_comp_err = (comp_num_def / comp_den_def ** 2 +\n",
    "                    comp_num_def ** 2 / comp_den_def ** 4 * comp_num_def) ** 0.5\n",
    "total_comp_err[~np.isfinite(total_comp_err)] = 0\n",
    "total_puri_err = (puri_num_def / puri_den_def ** 2 +\n",
    "                    puri_num_def ** 2 / puri_den_def ** 4 * puri_num_def) ** 0.5\n",
    "total_puri_err[~np.isfinite(total_puri_err)] = 0\n",
    "\n",
    "axs[0].errorbar(bc, combined_puri, ls='-', fmt='s', color='black',\n",
    "            markersize=10, label='Total', yerr=total_puri_err, capsize=4)\n",
    "axs[1].errorbar(bc, combined_comp, ls='-', fmt='s', color='black',\n",
    "            markersize=10, yerr=total_comp_err, capsize=4)\n",
    "\n",
    "np.save(f'tmp/comb_puri_{qso_factor:0.1f}', combined_puri)\n",
    "np.save(f'tmp/comb_puri_err_{qso_factor:0.1f}', total_puri_err)\n",
    "\n",
    "# Font size\n",
    "fs = 15\n",
    "\n",
    "axs[0].legend(loc=0, fontsize=14)\n",
    "\n",
    "axs[1].set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=20)\n",
    "axs[0].set_ylabel('Purity', fontsize=20)\n",
    "axs[1].set_ylabel('Completeness', fontsize=20)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(labelsize=fs, direction='in', length=6)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.savefig('figures/Combined_puricomp.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_L_min = 43.5\n",
    "what_bins = (LF_dict['LF_bins'] > this_L_min)\n",
    "what_bins_comp = (np.array(bc) > this_L_min)\n",
    "N_LAEs = (LF_dict['LF_total'] * volwid)[what_bins].sum() / 1.14\n",
    "this_total_comp = comp_num_def[what_bins_comp].sum() / comp_den_def[what_bins_comp].sum()\n",
    "print(f'N_LAEs = {N_LAEs:0.1f}')\n",
    "print(f'median comp = {this_total_comp:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qsofrac_LF(qso_factor):\n",
    "    # My LF\n",
    "    survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "    total_volume = 0.\n",
    "    for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "        total_volume += effective_volume(this_nb_min, this_nb_max, 'both')\n",
    "    masked_volume = None\n",
    "    hist_mat = None\n",
    "    LF_raw = None\n",
    "    for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "        this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "        this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "        this_hist = None\n",
    "        for survey_name in survey_list:\n",
    "            pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "            filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "            hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "            if this_hist is None:\n",
    "                this_hist = hist_i_mat\n",
    "            else:\n",
    "                this_hist += hist_i_mat\n",
    "        this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "        this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, 'both')\n",
    "\n",
    "        filename_dict = f'{pathname}/LFs.pkl'\n",
    "        with open(filename_dict, 'rb') as file:\n",
    "            if LF_raw is None:\n",
    "                LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "            else:\n",
    "                LF_raw += pickle.load(file)['LF_total_raw'] * this_volume\n",
    "            \n",
    "        # Set masked bins by puricomp_mask to 0\n",
    "        puricomp_mask = mask_puricomp(this_puri, this_comp)\n",
    "        this_hist[:, ~puricomp_mask] = 0.\n",
    "        this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "        if masked_volume is None:\n",
    "            masked_volume = this_volume\n",
    "        else:\n",
    "            masked_volume += this_volume\n",
    "\n",
    "        if hist_mat is None:\n",
    "            hist_mat = this_hist\n",
    "        else:\n",
    "            hist_mat = hist_mat + this_hist\n",
    "\n",
    "    hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "    L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "    LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "    LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "    mask_low_N = (LF_raw < min_N_bin)\n",
    "    for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "        h[mask_low_N] = 0.\n",
    "\n",
    "    volwid = total_volume * bin_width\n",
    "    yerr_plus = (hist_median + volwid * (LF_err_plus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "    yerr_minus = (hist_median + volwid * (LF_err_minus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "\n",
    "    LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': hist_median,\n",
    "        'LF_total_uncorr': LF_raw / total_volume,\n",
    "        'LF_total_err': [yerr_minus, yerr_plus]\n",
    "    }\n",
    "        \n",
    "    return LF_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MOCK\n",
    "import glob\n",
    "from my_functions import flux_to_mag\n",
    "\n",
    "name = 'QSO_LAES'\n",
    "\n",
    "filename = f'/home/alberto/almacen/Source_cats/{name}/'\n",
    "files = glob.glob(filename + 'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "how_many = 99999999999\n",
    "for i, name in enumerate(files):\n",
    "    if i == how_many: break\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data_qso = pd.concat(fi, axis=0, ignore_index=True)\n",
    "L_lya_mock = data_qso['L_lya']\n",
    "pm_flx_mock = data_qso.to_numpy()[:, 1: 60 + 1].T\n",
    "mag_mock = flux_to_mag(pm_flx_mock[-2], w_central[-2])\n",
    "z_mock = data_qso['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(5, 4), sharex=True,\n",
    "                        gridspec_kw=dict(height_ratios=[2, 1]))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.12)\n",
    "\n",
    "\n",
    "for ii, qso_frac in enumerate([1.0, 1.5, 0.5]):\n",
    "    iii = ii + 7\n",
    "    this_LF_dict = load_qsofrac_LF(qso_frac)\n",
    "\n",
    "    if ii == 0:\n",
    "        z_mock_min, z_mock_max = 2, 4\n",
    "        mock_mask = (mag_mock > 17) & (mag_mock < 24) &\\\n",
    "            (z_mock > z_mock_min) & (z_mock < z_mock_max)\n",
    "        bins = np.arange(42, 47, 0.05)\n",
    "        bin_w = bins[1] - bins[0]\n",
    "        volume = z_volume(z_mock_min, z_mock_max, 400)\n",
    "        ax0.hist(L_lya_mock[mock_mask], bins,\n",
    "                    weights=np.full(L_lya_mock[mock_mask].shape,\n",
    "                                    (volume * bin_w) ** -1),\n",
    "                histtype='step')\n",
    "    ax0.errorbar(this_LF_dict['LF_bins'], this_LF_dict['LF_total'],\n",
    "            yerr=(this_LF_dict['LF_total_err'][:2] if ii == 0 else None),\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor=f'C{iii}', markeredgecolor=f'C{iii}', markerfacecolor='none',\n",
    "            markeredgewidth=1.5, markersize=6,\n",
    "            capsize=4, zorder=99-iii)\n",
    "    # Dummy for legend\n",
    "    ax0.plot([], [], ls='', marker='s', markersize=6, markeredgewidth=1.5,\n",
    "             markerfacecolor='none', label=fr'$\\rho=${qso_frac}', color=f'C{iii}')\n",
    "\n",
    "    #### PURICOMP ####\n",
    "\n",
    "    this_puri = np.load(f'tmp/comb_puri_{qso_frac:0.1f}.npy')\n",
    "    this_puri_err = np.load(f'tmp/comb_puri_err_{qso_frac:0.1f}.npy')\n",
    "\n",
    "    ax1.errorbar(bc, this_puri, ls='-', c=f'C{iii}', fmt='',\n",
    "                       yerr=this_puri_err, capsize=0)\n",
    "\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.tick_params(direction='in', which='both', labelsize=11)\n",
    "    ax1.set_yticks(np.arange(0, 1.25, 0.25))\n",
    "    ax1.set_yticklabels(['0.0', '', '0.5', '', '1.0'])\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "\n",
    "    ##################\n",
    "\n",
    "    ax0.set_ylim(1e-8, 5e-4)\n",
    "    ax0.set_xlim(42.3, 45.7)\n",
    "    ax0.set_yscale('log')\n",
    "    ax0.tick_params(direction='in', which='both', labelsize=11)\n",
    "    ax0.yaxis.set_ticks_position('both')\n",
    "    ax0.xaxis.set_ticks_position('both')\n",
    "    ax0.set_ylabel(r'$\\Phi$ (Mpc$^{-3}\\,\\Delta\\log L^{-1}$)', fontsize=12)\n",
    "    ax0.legend(fontsize=10, loc=0)\n",
    "\n",
    "    ax1.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=12)\n",
    "    ax1.set_ylabel('Purity', fontsize=12)\n",
    "\n",
    "fig.savefig('figures/rho_LF_puri_one.pdf', bbox_inches='tight',\n",
    "            facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
