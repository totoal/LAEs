{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "import pandas as pd\n",
    "from minijpas_LF_and_puricomp import effective_volume\n",
    "from my_functions import double_schechter, bin_centers, z_volume\n",
    "from my_functions import central_wavelength, nb_fwhm, schechter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmology_convert import *\n",
    "\n",
    "# Load reference LFs\n",
    "pathname = '/home/alberto/almacen/literature_LF_data'\n",
    "\n",
    "# Blanc 2011 (z=1.9--3.8)\n",
    "filename = f'{pathname}/blanc2011_allz.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "b11 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': (3.8 + 1.9) * 0.5,\n",
    "    'label': 'Blanc 2011 ($z=1.9-3.8$)',\n",
    "    'fmt': 'h',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Gronwall 2007 (z=3.1)\n",
    "filename = f'{pathname}/gronwall2007_z3.1.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "g07 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 3.1,\n",
    "    'label': 'Gronwall 2007 ($z=3.1$)',\n",
    "    'fmt': 'x',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Konno 2016 (z=2.2)\n",
    "filename = f'{pathname}/konno2016_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter=',')\n",
    "k16 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_down'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_up'],\n",
    "    'z': 2.2,\n",
    "    'label': 'Konno 2016 ($z=2.2$)',\n",
    "    'fmt': '^',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Matthee 2017 (z=2.2)\n",
    "filename = f'{pathname}/matthee2017_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "m17a = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 2.2,\n",
    "    'label': 'Matthee 2017 ($z=2.2$)',\n",
    "    'fmt': '*',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Matthee 2017 (z=2.4)\n",
    "filename = f'{pathname}/matthee2017_z2.4.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "m17b = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 2.4,\n",
    "    'label': 'Matthee 2017 ($z=2.4$)',\n",
    "    'fmt': '*',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Ouchi 2008 (z=3.1)\n",
    "filename = f'{pathname}/ouchi2008_z3.1.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "u08 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 3.1,\n",
    "    'label': 'Ouchi 2008 ($z=3.1$)',\n",
    "    'fmt': 'o',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2016 (z=2.2)\n",
    "filename = f'{pathname}/sobral2016_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s16 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 2.2,\n",
    "    'label': 'Sobral 2016 ($z=2.2$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2017 (z=2.2)\n",
    "filename = f'{pathname}/sobral2017_z2.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s17 = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 2.2,\n",
    "    'label': 'Sobral 2017 ($z=2.2$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=2.5)\n",
    "filename = f'{pathname}/sobral2018_z2.5.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18a = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 2.5,\n",
    "    'label': 'Sobral 2018 ($z=2.5$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.0)\n",
    "filename = f'{pathname}/sobral2018_z3.0.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18b = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 3.0,\n",
    "    'label': 'Sobral 2018 ($z=3.0$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.2)\n",
    "filename = f'{pathname}/sobral2018_z3.2.txt'\n",
    "df = pd.read_table(filename, delimiter='\\t')\n",
    "s18c = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': df['phi'],\n",
    "    'yerr_plus': df['phi_err_up'] - df['phi'],\n",
    "    'yerr_minus': df['phi'] - df['phi_err_down'],\n",
    "    'z': 3.2,\n",
    "    'label': 'Sobral 2018 ($z=3.2$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=2.8)\n",
    "filename = f'{pathname}/sobral2018_z2.8.txt'\n",
    "df = pd.read_table(filename, delimiter=',')\n",
    "s18d = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': 10 ** (df['phi']),\n",
    "    'yerr_plus': 10 ** df['phi_err_up'] - 10 ** df['phi'],\n",
    "    'yerr_minus': 10 ** df['phi'] - 10 ** df['phi_err_down'],\n",
    "    'z': 2.8,\n",
    "    'label': 'Sobral 2018 ($z=2.8$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.3)\n",
    "filename = f'{pathname}/sobral2018_z3.3.txt'\n",
    "df = pd.read_table(filename, delimiter=',')\n",
    "s18e = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': 10 ** (df['phi']),\n",
    "    'yerr_plus': 10 ** df['phi_err_up'] - 10 ** df['phi'],\n",
    "    'yerr_minus': 10 ** df['phi'] - 10 ** df['phi_err_down'],\n",
    "    'z': 3.3,\n",
    "    'label': 'Sobral 2018 ($z=3.3$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Sobral 2018 (z=3.7)\n",
    "filename = f'{pathname}/sobral2018_z3.7.txt'\n",
    "df = pd.read_table(filename, delimiter=',')\n",
    "s18f = {\n",
    "    'logL': df['LogLya'],\n",
    "    'Phi': 10 ** (df['phi']),\n",
    "    'yerr_plus': 10 ** df['phi_err_up'] - 10 ** df['phi'],\n",
    "    'yerr_minus': 10 ** df['phi'] - 10 ** df['phi_err_down'],\n",
    "    'z': 3.7,\n",
    "    'label': 'Sobral 2018 ($z=3.7$)',\n",
    "    'fmt': 'D',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "\n",
    "# Spinoso 2020\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0395_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z225 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'z': 2.25,\n",
    "    'label': 'Spinoso 2020 ($z=2.25$)',\n",
    "    'fmt': 'X',\n",
    "    'H0': 67.3,\n",
    "    'Om0': 0.315,\n",
    "    'Ode0': 0.685\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0410_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z237 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'z': 2.37,\n",
    "    'label': 'Spinoso 2020 ($z=2.37$)',\n",
    "    'fmt': 'X',\n",
    "    'H0': 67.3,\n",
    "    'Om0': 0.315,\n",
    "    'Ode0': 0.685\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0430_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z254 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'z': 2.54,\n",
    "    'label': 'Spinoso 2020 ($z=2.54$)',\n",
    "    'fmt': 'X',\n",
    "    'H0': 67.3,\n",
    "    'Om0': 0.315,\n",
    "    'Ode0': 0.685\n",
    "}\n",
    "\n",
    "fnam = '/home/alberto/almacen/literature_LF_data/LF_data_SpinosoEtAl2020/20200518_J0515_SNR5_LFdata.txt'\n",
    "loglya, ModLF, ModLF_pc16, ModLF_pc84 = np.genfromtxt(fnam, skip_header=3, usecols=(0,6,7,8), unpack=True)\n",
    "dLogL = loglya[1] - loglya[0]\n",
    "snr = ModLF / ModLF_pc16\n",
    "ds20_z324 = {\n",
    "    'logL': loglya[snr > 1],\n",
    "    'Phi': ModLF[snr > 1],\n",
    "    'yerr_plus': ModLF_pc84[snr > 1],\n",
    "    'yerr_minus': ModLF_pc16[snr > 1],\n",
    "    'z': 3.24,\n",
    "    'label': 'Spinoso 2020 ($z=3.24$)',\n",
    "    'fmt': 'X',\n",
    "    'H0': 67.3,\n",
    "    'Om0': 0.315,\n",
    "    'Ode0': 0.685\n",
    "}\n",
    "\n",
    "# Zhang 2021 (z=2.0-3.5)\n",
    "df = pd.read_csv('csv/Zhang2021_LF.csv')\n",
    "z21 = {\n",
    "    'logL': df['Llya'],\n",
    "    'Phi': df['Phi'],\n",
    "    'yerr_plus': df['yerr_plus'] - df['Phi'],\n",
    "    'yerr_minus': df['Phi'] - df['yerr_minus'],\n",
    "    'z': (2.0 + 3.5) * 0.5,\n",
    "    'label': 'Zhang 2021 ($z=2.0-3.5$)',\n",
    "    'fmt': 'd',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Liu 2022 (z=1.88-3.53)\n",
    "df = pd.read_csv('csv/Liu_LF.csv')\n",
    "l22 = {\n",
    "    'logL': df['logLya'],\n",
    "    'Phi': df['Phi'],\n",
    "    'yerr_plus': df['yerr'],\n",
    "    'yerr_minus': df['yerr'],\n",
    "    'z': (1.88 + 3.53) * 0.5,\n",
    "    'label': 'Liu 2022 ($z=1.9-3.5$)',\n",
    "    'fmt': 'v',\n",
    "    'H0': 70,\n",
    "    'Om0': 0.3,\n",
    "    'Ode0': 0.7\n",
    "}\n",
    "\n",
    "# Assign colors\n",
    "LF_ref_list = [b11, g07, k16, m17a, m17b, u08, s16, s17, s18a,\n",
    "               s18b, s18c, s18d, s18e, s18f, ds20_z225, ds20_z237,\n",
    "               ds20_z254, ds20_z324, z21, l22]\n",
    "for i, lf_dict in enumerate(LF_ref_list):\n",
    "    lf_dict['color'] = f'C{i}'\n",
    "\n",
    "# Conver to my cosmology\n",
    "for lf_dict in LF_ref_list:\n",
    "    args = (lf_dict['logL'], lf_dict['z'], lf_dict['H0'],\n",
    "            lf_dict['Om0'], lf_dict['Ode0'])\n",
    "    lf_dict['logL'] = convert_cosmology_luminosity(*args)\n",
    "\n",
    "    args = (lf_dict['Phi'], lf_dict['z'], lf_dict['H0'],\n",
    "            lf_dict['Om0'], lf_dict['Ode0'])\n",
    "    lf_dict['Phi'] = convert_cosmology_Phi(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_list = [[1, 5], [4, 8], [7, 11], [10, 14], [13, 17], [16, 20]]\n",
    "qso_factor = 1.0\n",
    "comb_nbs_list = nbs_list\n",
    "\n",
    "w_central = central_wavelength()\n",
    "w_lya = 1215.67\n",
    "nb_fwhm_Arr = nb_fwhm(np.arange(60))\n",
    "L_binning = np.load('npy/L_nb_err_binning.npy')\n",
    "b = np.log10(L_binning)\n",
    "LF_bins = np.array([(b[i] + b[i + 1]) / 2 for i in range(len(b) - 1)])\n",
    "bin_width = np.array([b[i + 1] - b[i] for i in range(len(b) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_puricomp2d import load_puricomp1d\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7), sharey=True)\n",
    "\n",
    "comp_den_def = None\n",
    "total_comp_list = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    # A text with the redshift interval\n",
    "    ax.set_title(fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$')\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    # Define the survey list in order\n",
    "    survey_list = [f'AEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "    # Bin centers\n",
    "    bc = [puricomp_bins[i: i + 2].sum() * 0.5 for i in range(len(puricomp_bins) - 1)]\n",
    "\n",
    "    # Plot the individual comps\n",
    "    for j, comp in enumerate(comp_list):\n",
    "        ax.plot(bc, comp, ls=':', alpha=0.6, marker='s', markersize=10,\n",
    "                label=survey_list[j], c=f'C{j + 2}')\n",
    "\n",
    "    # Total comp\n",
    "    total_comp_num = (np.array(comp_list) *\n",
    "                      np.array(comp_den_list)).sum(axis=0)\n",
    "    total_comp_den = np.array(comp_den_list).sum(axis=0)\n",
    "    total_comp_err = (total_comp_num / total_comp_den ** 2 +\n",
    "                      total_comp_num ** 2 / total_comp_den ** 4 * total_comp_num) ** 0.5\n",
    "    total_comp_err[~np.isfinite(total_comp_err)] = 0\n",
    "    if comp_den_def is None:\n",
    "        comp_den_def = total_comp_den\n",
    "        comp_num_def = total_comp_num\n",
    "    else:\n",
    "        comp_den_def += total_comp_den\n",
    "        comp_num_def += total_comp_num\n",
    "    total_comp = total_comp_num / total_comp_den\n",
    "    total_comp[~np.isfinite(total_comp)] = 0\n",
    "    total_comp_list.append(total_comp)\n",
    "    ax.errorbar(bc, total_comp, ls='-', fmt='s', c='k',\n",
    "                markersize=9, yerr=total_comp_err,\n",
    "                capsize=4)\n",
    "    # Dummy point\n",
    "    ax.errorbar([], [], markersize=9, c='k', label='Total', marker='s', ls='')\n",
    "   \n",
    "    ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    # ax.set_xticks([43, 43.5, 44, 44.5, 45, 45.5])\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=20)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'Completeness', fontsize=20)\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False)\n",
    "\n",
    "np.save('npy/total_comp_list', total_comp_list)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Multi_comp.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7), sharey=True)\n",
    "\n",
    "puri_den_def = None\n",
    "total_puri_list = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    # A text with the redshift interval\n",
    "    ax.set_title(fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$')\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    # Define the survey list in order\n",
    "    survey_list = [f'AEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "    # Bin centers\n",
    "    bc = [puricomp_bins[i: i + 2].sum() * 0.5 for i in range(len(puricomp_bins) - 1)]\n",
    "\n",
    "    # Plot the individual puris\n",
    "    for j, puri in enumerate(puri_list):\n",
    "        ax.plot(bc, puri, ls=':', alpha=0.6, marker='s',\n",
    "                markersize=10, label=survey_list[j], c=f'C{j + 2}')\n",
    "\n",
    "    # Total puri\n",
    "    total_puri_num = (np.array(puri_list) *\n",
    "                      np.array(puri_den_list)).sum(axis=0)\n",
    "    total_puri_den = np.array(puri_den_list).sum(axis=0)\n",
    "    total_puri = total_puri_num / total_puri_den\n",
    "    total_puri_err = (total_puri_num / total_puri_den ** 2 +\n",
    "                      total_puri_num ** 2 / total_puri_den ** 4 * total_puri_num) ** 0.5\n",
    "    total_puri_err[~np.isfinite(total_puri_err)] = 0\n",
    "    if puri_den_def is None:\n",
    "        puri_den_def = total_puri_den\n",
    "        puri_num_def = total_puri_num\n",
    "    else:\n",
    "        puri_den_def += total_puri_den\n",
    "        puri_num_def += total_puri_num\n",
    "    total_puri[~np.isfinite(total_puri)] = 0.\n",
    "    total_puri_list.append(total_puri)\n",
    "    ax.errorbar(bc, total_puri, ls='-', fmt='s', c='k',\n",
    "                markersize=9, yerr=total_puri_err,\n",
    "                capsize=4)\n",
    "    np.save(f'npy/puri_1d_{nb1}-{nb2}', total_puri)\n",
    "    np.save(f'npy/puri_1d_bc', bc)\n",
    "\n",
    "    # Dummy point\n",
    "    ax.errorbar([], [], markersize=9, c='k', label='Total', marker='s', ls='')\n",
    "\n",
    "    ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    # ax.set_xticks([43, 43.5, 44, 44.5, 45, 45.5])\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(\n",
    "            r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=20)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'Purity', fontsize=20)\n",
    "    if i == 0:\n",
    "        ax.legend(frameon=False)\n",
    "\n",
    "np.save('npy/total_puri_list', np.array(total_puri_list))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/Multi_puri.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_puricomp(puri, comp, min_puri=0.0, min_comp=0.0):\n",
    "    return (puri > min_puri) & (comp > min_comp)\n",
    "\n",
    "min_N_bin = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My fit\n",
    "def load_mcmc_schechter_fit():\n",
    "    flat_samples = np.load('npy/mcmc_schechter_fit_chain.npy')\n",
    "\n",
    "    Phi_fit_i = []\n",
    "    for ii, step in enumerate(flat_samples[::-1]):\n",
    "        if ii == 10_000:\n",
    "            break\n",
    "        Phi_fit_i.append(schechter(Lx, 10**step[0], 10**step[1], step[2])\n",
    "                        * Lx * np.log(10))\n",
    "    Phi_fit_84 = np.percentile(Phi_fit_i, 84, axis=0)\n",
    "    Phi_fit_16 = np.percentile(Phi_fit_i, 16, axis=0)\n",
    "    Phi_fit_50 = np.percentile(Phi_fit_i, 50, axis=0)\n",
    "    return Phi_fit_16, Phi_fit_50, Phi_fit_84\n",
    "\n",
    "# The fitting curve\n",
    "def power_fit(Lx, A, B):\n",
    "    return 10 ** (A * (np.log10(Lx) - 43.5) + B)\n",
    "    \n",
    "def load_mcmc_powerlaw_fit():\n",
    "    flat_samples = np.load('npy/mcmc_powerlaw_fit_chain.npy')\n",
    "\n",
    "    Phi_fit_i = []\n",
    "    for ii, step in enumerate(flat_samples[::-1]):\n",
    "        if ii == 10_000:\n",
    "            break\n",
    "        Phi_fit_i.append(power_fit(Lx, step[0], step[1]))\n",
    "    Phi_fit_84 = np.percentile(Phi_fit_i, 84, axis=0)\n",
    "    Phi_fit_16 = np.percentile(Phi_fit_i, 16, axis=0)\n",
    "    Phi_fit_50 = np.percentile(Phi_fit_i, 50, axis=0)\n",
    "    return Phi_fit_16, Phi_fit_50, Phi_fit_84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharey=True, sharex=True,\n",
    "                         width_ratios=[1, 1, 1], height_ratios=[1, 1])\n",
    "\n",
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(np.arange(60))\n",
    "w_lya = 1215.67\n",
    "\n",
    "reference_LFs = [\n",
    "    [s17, m17b, m17a, k16, ds20_z225, ds20_z237],\n",
    "    [s18a, m17b, ds20_z237],\n",
    "    [s18d, s18b],\n",
    "    [s18c, s18b, s18d, u08, ds20_z324],\n",
    "    [u08, s18e, s18c],\n",
    "    [s18f]\n",
    "]\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    [nb1, nb2] = nbs_list[i]\n",
    "\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    this_hist = None\n",
    "    this_volume = effective_volume(nb1, nb2, 'both')\n",
    "    pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "\n",
    "    for survey_name in survey_list:\n",
    "        filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "        hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "        this_field_LF = hist_i_mat / effective_volume(nb1, nb2, survey_name) / bin_width\n",
    "\n",
    "        if this_hist is None:\n",
    "            this_hist = hist_i_mat\n",
    "            field_LF_mat = this_field_LF\n",
    "        else:\n",
    "            this_hist += hist_i_mat\n",
    "            field_LF_mat = np.vstack([field_LF_mat, this_field_LF])\n",
    "        filename_dict = f'{pathname}/LFs.pkl'\n",
    "        with open(filename_dict, 'rb') as file:\n",
    "            LF_raw = pickle.load(file)['LF_total_raw']\n",
    "\n",
    "\n",
    "    L_LF_err_percentiles = np.percentile(this_hist, [16, 50, 84], axis=0)\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "    # hist_median = np.nanmean(this_hist, axis=0)\n",
    "\n",
    "    yerr_minus = np.load(f'{pathname}/LF_err_minus.npy')\n",
    "    yerr_plus = np.load(f'{pathname}/LF_err_plus.npy')\n",
    "    \n",
    "    this_LF = hist_median / bin_width / this_volume\n",
    "    LF_boots = np.load(f'{pathname}/median_LF_boots.npy')\n",
    "    # Fix yerr_minus when LF_boots == 0\n",
    "    yerr_minus[LF_boots == 0] = this_LF[LF_boots == 0]\n",
    "\n",
    "    this_LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': this_LF,\n",
    "        'LF_total_err': [yerr_minus, yerr_plus],\n",
    "        'LF_total_uncorr': hist_median,\n",
    "    }\n",
    "\n",
    "    this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "    this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "\n",
    "    ax.text(42.46, 1e-2, fr'$\\bf z={z_min:0.1f}-{z_max:0.1f}$', fontsize=15)\n",
    "\n",
    "    puricomp_mask = mask_puricomp(this_puri, this_comp)\\\n",
    "        & (hist_median >= min_N_bin)\n",
    "    ax.errorbar(this_LF_dict['LF_bins'][puricomp_mask],\n",
    "            this_LF_dict['LF_total'][puricomp_mask],\n",
    "            yerr=np.array(this_LF_dict['LF_total_err'])[:2, puricomp_mask],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='k', markeredgecolor='k', markerfacecolor='red',\n",
    "            markeredgewidth=1, markersize=8,\n",
    "            capsize=4, label='This work', zorder=99)\n",
    "    # Dummy for legend\n",
    "    ax.plot([], [], ls='', marker='s', markersize=8, markerfacecolor='none',\n",
    "            markeredgecolor='k')\n",
    "    ax.errorbar(this_LF_dict['LF_bins'][~puricomp_mask],\n",
    "            this_LF_dict['LF_total'][~puricomp_mask],\n",
    "            yerr=np.array(this_LF_dict['LF_total_err'])[:2, ~puricomp_mask],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='gray', markeredgecolor='k', markerfacecolor='none',\n",
    "            markeredgewidth=1, markersize=8,\n",
    "            capsize=4, zorder=99)\n",
    "\n",
    "    # My fit\n",
    "    Lx = np.logspace(43.3, 44.6, 1000)\n",
    "    # Phi_fit_16, Phi_fit_50, Phi_fit_84 = load_mcmc_schechter_fit()\n",
    "    # ax.plot(np.log10(Lx), Phi_fit_50,\n",
    "    #         ls='-', c='C0', zorder=96, label='Best fit ($z=2.0$-$3.8$)')\n",
    "    Phi_fit_16, Phi_fit_50, Phi_fit_84 = load_mcmc_powerlaw_fit()\n",
    "    ax.plot(np.log10(Lx), Phi_fit_50,\n",
    "            ls='--', lw=2.5, c='r', zorder=96)\n",
    "\n",
    "    for j, lf in enumerate(reference_LFs[i]):\n",
    "        ax.errorbar(lf['logL'], lf['Phi'],\n",
    "                    yerr=[lf['yerr_minus'], lf['yerr_plus']],\n",
    "                    linestyle='', fmt=lf['fmt'], c=lf['color'],\n",
    "                    alpha=0.8, label=lf['label'], capsize=3, zorder=i)\n",
    "\n",
    "    if i > 2:\n",
    "        ax.set_xlabel(r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=15)\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log_{10}L^{-1}$]', fontsize=15)\n",
    "\n",
    "    ax.set_ylim(1e-8, 1e-1)\n",
    "    ax.set_xlim(42.3, 45.7)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.tick_params(labelsize=17, direction='in', which='both')\n",
    "    ax.set_yticks(np.logspace(-8, -1, 8))\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.set_xticks(np.arange(42.5, 46, 0.5))\n",
    "\n",
    "    # handles, labels = ax.get_legend_handles_labels()\n",
    "    # order = np.arange(len(handles))\n",
    "    # order[:2] = [1, 0]\n",
    "    # ax.legend(np.array(handles, dtype=object)[order],\n",
    "    #           np.array(labels, dtype=object)[order],\n",
    "    #           fontsize=11, ncol=1, loc=0)\n",
    "    ax.legend(fontsize=11)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.03, hspace=0.05)\n",
    "fig.savefig('figures/Multi_LF.pdf', bbox_inches='tight', facecolor='w', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import schechter\n",
    "\n",
    "# My LF\n",
    "survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "total_volume = 0.\n",
    "for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "    total_volume += effective_volume(this_nb_min, this_nb_max, 'both')\n",
    "masked_volume = None\n",
    "hist_mat = None\n",
    "LF_raw = None\n",
    "for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "    this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "    this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "    this_hist = None\n",
    "    for survey_name in survey_list:\n",
    "        pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "        filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "        hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "        this_field_LF = hist_i_mat / effective_volume(nb1, nb2, survey_name) / bin_width\n",
    "\n",
    "        if this_hist is None:\n",
    "            this_hist = hist_i_mat\n",
    "            field_LF_mat = this_field_LF\n",
    "        else:\n",
    "            this_hist += hist_i_mat\n",
    "            field_LF_mat = np.vstack([field_LF_mat, this_field_LF])\n",
    "\n",
    "    this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "    this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, 'both')\n",
    "\n",
    "    filename_dict = f'{pathname}/LFs.pkl'\n",
    "    with open(filename_dict, 'rb') as file:\n",
    "        this_LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "        if LF_raw is None:\n",
    "            LF_raw = this_LF_raw\n",
    "        else:\n",
    "            LF_raw += this_LF_raw\n",
    "        \n",
    "    # Set masked bins by puricomp_mask to 0\n",
    "    N_median_hist = np.nanmedian(this_hist, axis=0) * total_volume * bin_width\n",
    "    puricomp_mask = mask_puricomp(this_puri, this_comp) & (N_median_hist >= min_N_bin)\n",
    "    this_hist[:, ~puricomp_mask] = 0.\n",
    "    this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "    if masked_volume is None:\n",
    "        masked_volume = this_volume\n",
    "    else:\n",
    "        masked_volume += this_volume\n",
    "\n",
    "    if hist_mat is None:\n",
    "        hist_mat = this_hist\n",
    "    else:\n",
    "        hist_mat = hist_mat + this_hist\n",
    "    \n",
    "hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "# hist_median = np.nanmean(hist_mat, axis=0)\n",
    "\n",
    "mask_low_N = (LF_raw < min_N_bin)\n",
    "for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "    h[mask_low_N] = 0.\n",
    "\n",
    "volwid = total_volume * bin_width\n",
    "\n",
    "load_LF_name = '/home/alberto/cosmos/LAEs/Luminosity_functions/Total_LF'\n",
    "\n",
    "yerr_plus = np.load(f'{load_LF_name}/LF_err_plus.npy')\n",
    "yerr_minus = np.load(f'{load_LF_name}/LF_err_minus.npy')\n",
    "\n",
    "LF_boots = np.load(f'{load_LF_name}/median_LF_boots.npy')\n",
    "# Fix yerr_minus:\n",
    "yerr_minus[LF_boots == 0] = hist_median[LF_boots == 0]\n",
    "\n",
    "\n",
    "LF_dict = {\n",
    "    'LF_bins': LF_bins,\n",
    "    'LF_total': hist_median,\n",
    "    'LF_total_err': [yerr_minus, yerr_plus]\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# My LF\n",
    "ax.errorbar(LF_dict['LF_bins'], LF_dict['LF_total'],\n",
    "            yerr=LF_dict['LF_total_err'][:2],\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor='k', markeredgecolor='k', markerfacecolor='red',\n",
    "            markeredgewidth=1.5, markersize=7,\n",
    "            capsize=4, label='This work', zorder=99)\n",
    "\n",
    "# Other LFs\n",
    "ref_LFs_to_plot = [l22, z21, b11]\n",
    "for i, lf in enumerate(ref_LFs_to_plot):\n",
    "    ax.errorbar(lf['logL'], lf['Phi'],\n",
    "                yerr=[lf['yerr_minus'], lf['yerr_plus']],\n",
    "                linestyle='', fmt=lf['fmt'], c=lf['color'],\n",
    "                mec='dimgray', ecolor='dimgray',\n",
    "                alpha=0.8, label=lf['label'], capsize=3, zorder=i)\n",
    "\n",
    "# Dummy to add text to legend\n",
    "ax.plot([], [], ls='', label=r'$\\bf{z = 2.05-3.75}$')\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-2)\n",
    "ax.set_xlim(42.5, 45.5)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=18)\n",
    "ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log_{10}L^{-1}$]', fontsize=18)\n",
    "\n",
    "ax.tick_params(labelsize=18, direction='in', which='both')\n",
    "ax.set_yticks(np.logspace(-8, -2, 7))\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# order = np.array([1, 2, 0, 3, 4, 5])\n",
    "# ax.legend(np.array(handles, dtype=object)[order],\n",
    "#           np.array(labels, dtype=object)[order], fontsize=10, ncol=1)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "fig.savefig('figures/Combined_LF.pdf', bbox_inches='tight', facecolor='w', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My LF\n",
    "survey_list_list = [\n",
    "    [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep'],\n",
    "    ['minijpasAEGIS001'],\n",
    "    ['minijpasAEGIS002'],\n",
    "    ['minijpasAEGIS003'],\n",
    "    ['minijpasAEGIS004'],\n",
    "    ['jnep'],\n",
    "]\n",
    "survey_list_area = ['both'] + [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "labels_list = ['All'] + [f'AEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "\n",
    "fig, (ax, axx) = plt.subplots(2,figsize=(6, 5), height_ratios=(2, 1),\n",
    "                              sharex=True)\n",
    "\n",
    "for jjj, survey_list in enumerate(survey_list_list):\n",
    "    total_volume = 0.\n",
    "    survey_area_name = survey_list_area[jjj]\n",
    "    for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "        total_volume += effective_volume(this_nb_min, this_nb_max, survey_area_name)\n",
    "    masked_volume = None\n",
    "    hist_mat = None\n",
    "    LF_raw = None\n",
    "    for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "        this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "        this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "        this_hist = None\n",
    "        for survey_name in survey_list:\n",
    "            pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "            filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "            hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "            if this_hist is None:\n",
    "                this_hist = hist_i_mat\n",
    "            else:\n",
    "                this_hist += hist_i_mat\n",
    "        this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "        this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, survey_area_name)\n",
    "\n",
    "        filename_dict = f'{pathname}/LFs.pkl'\n",
    "        with open(filename_dict, 'rb') as file:\n",
    "            this_LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "            if LF_raw is None:\n",
    "                LF_raw = this_LF_raw\n",
    "            else:\n",
    "                LF_raw += this_LF_raw\n",
    "            \n",
    "        # Set masked bins by puricomp_mask to 0\n",
    "        puricomp_mask = mask_puricomp(this_puri, this_comp) & (this_LF_raw >= min_N_bin)\n",
    "        # puricomp_mask = np.ones_like(this_LF_raw).astype(bool)\n",
    "        this_hist[:, ~puricomp_mask] = 0.\n",
    "        this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "        if masked_volume is None:\n",
    "            masked_volume = this_volume\n",
    "        else:\n",
    "            masked_volume += this_volume\n",
    "\n",
    "        if hist_mat is None:\n",
    "            hist_mat = this_hist\n",
    "        else:\n",
    "            hist_mat = hist_mat + this_hist\n",
    "\n",
    "    hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "    L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "    LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "    LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "    mask_low_N = (LF_raw < min_N_bin)\n",
    "    for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "        h[mask_low_N] = 0.\n",
    "\n",
    "    volwid = total_volume * bin_width\n",
    "    yerr_plus = (hist_median + volwid * (LF_err_plus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "    yerr_minus = (hist_median + volwid * (LF_err_minus) ** 2) ** 0.5 * volwid ** -0.5\n",
    "\n",
    "    LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': hist_median,\n",
    "        'LF_total_uncorr': LF_raw / total_volume,\n",
    "        'LF_total_err': [yerr_minus, yerr_plus]\n",
    "    }\n",
    "\n",
    "\n",
    "    # My LF\n",
    "    ax.errorbar(LF_dict['LF_bins'], LF_dict['LF_total'],\n",
    "                yerr=LF_dict['LF_total_err'][:2],\n",
    "                linestyle='', fmt='s',\n",
    "                ecolor=('k' if jjj == 0 else 'none'),\n",
    "                mec=(f'C{jjj + 6}' if jjj > 0 else 'k'),\n",
    "                mfc=('none' if jjj > 0 else 'r'),\n",
    "                markeredgewidth=1.5, markersize=7,\n",
    "                capsize=4,\n",
    "                zorder=jjj, label=labels_list[jjj])\n",
    "    \n",
    "    # Save the reference LF\n",
    "    if jjj == 0:\n",
    "        lf_ref = np.log10(LF_dict['LF_total'])\n",
    "\n",
    "    lf_diff = np.log10(LF_dict['LF_total']) - lf_ref\n",
    "\n",
    "    if jjj > 0:\n",
    "        axx.errorbar(LF_dict['LF_bins'] + 0.001 * jjj, lf_diff,\n",
    "                     ls='', marker='s', mfc='none', mec=f'C{jjj + 6}',\n",
    "                     ms=7)\n",
    "\n",
    "# My fit\n",
    "Lstar_fit = 44.84734\n",
    "Phistar_fit = -6.07145\n",
    "alpha = -1.56333\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "Phi_fit = schechter(Lx, 10**Phistar_fit, 10**Lstar_fit, alpha) * Lx * np.log(10)\n",
    "ax.plot(np.log10(Lx), Phi_fit,\n",
    "        ls='--', c='darkslategray', zorder=96)\n",
    "\n",
    "axx.axhline(0, ls='--', c='k', zorder=-999)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.set_ylim(1e-8, 1e-2)\n",
    "ax.set_xlim(42.5, 45.5)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "axx.set_xlabel(r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log_{10}L^{-1}$]', fontsize=15)\n",
    "axx.set_ylabel(r'$\\Delta\\log\\Phi$', fontsize=15)\n",
    "\n",
    "ax.tick_params(labelsize=14, direction='in', which='both')\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "\n",
    "axx.tick_params(labelsize=14, direction='in', which='both')\n",
    "axx.yaxis.set_ticks_position('both')\n",
    "axx.xaxis.set_ticks_position('both')\n",
    "\n",
    "fig.savefig('figures/Combined_LF_fields.pdf',\n",
    "            bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['J-NEP']\n",
    "this_nbs_list = [[1, 5], [4, 8], [7, 11], [10, 14], [13, 17], [16, 20]]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "total_puri_num = None\n",
    "\n",
    "for i in range(6):\n",
    "    [nb1, nb2] = this_nbs_list[i]\n",
    "    z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "    this_dirname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "    comp_list, _, _, puri_list, comp_den_list, _, _, puri_den_list, puricomp_bins = \\\n",
    "        load_puricomp1d(this_dirname)\n",
    "\n",
    "    if total_puri_num is None:\n",
    "        total_puri_num = (np.array(puri_list) * np.array(puri_den_list))\n",
    "        total_puri_den = np.array(puri_den_list)\n",
    "        total_comp_num = (np.array(comp_list) * np.array(comp_den_list))\n",
    "        total_comp_den = np.array(comp_den_list)\n",
    "    else:\n",
    "        total_puri_num += (np.array(puri_list) * np.array(puri_den_list))\n",
    "        total_puri_den += np.array(puri_den_list)\n",
    "        total_comp_num += (np.array(comp_list) * np.array(comp_den_list))\n",
    "        total_comp_den += np.array(comp_den_list)\n",
    "    \n",
    "    # Plot puricomp in z bins\n",
    "    this_comp_num = (np.array(comp_list) *\n",
    "                     np.array(comp_den_list)).sum(axis=0)\n",
    "    this_comp_den = np.array(comp_den_list).sum(axis=0)\n",
    "    this_comp_err = (this_comp_num / this_comp_den ** 2 +\n",
    "                     this_comp_num ** 2 / this_comp_den ** 4 * this_comp_num) ** 0.5\n",
    "    this_puri_num = (np.array(puri_list) *\n",
    "                     np.array(puri_den_list)).sum(axis=0)\n",
    "    this_puri_den = np.array(puri_den_list).sum(axis=0)\n",
    "    this_puri_err = (this_puri_num / this_puri_den ** 2 +\n",
    "                     this_puri_num ** 2 / this_puri_den ** 4 * this_puri_num) ** 0.5\n",
    "    this_comp = this_comp_num / this_comp_den\n",
    "    this_puri = this_puri_num / this_puri_den\n",
    "    this_puri[~np.isfinite(this_puri)] = 0\n",
    "    \n",
    "    ls = ('-' if i < 6 else '--')\n",
    "    \n",
    "    axs[1].errorbar(np.array(bc) + 0.01 * i, this_comp, yerr=this_comp_err * 0,\n",
    "                    c=f'C{i}', lw=2, ls=ls)\n",
    "    axs[0].errorbar(np.array(bc) + 0.01 * i, this_puri, yerr=this_puri_err * 0,\n",
    "                    c=f'C{i}', lw=2, ls=ls)\n",
    "    axs[0].plot([], [], label=f'$z={z_min:0.1f}$-${z_max:0.1f}$',\n",
    "                c=f'C{i}', lw=2, ls=ls)\n",
    "\n",
    "\n",
    "combined_puri = puri_num_def / puri_den_def\n",
    "combined_puri[~np.isfinite(combined_puri)] = 0.\n",
    "combined_comp = comp_num_def / comp_den_def\n",
    "combined_comp[~np.isfinite(combined_comp)] = 0.\n",
    "total_comp_err = (comp_num_def / comp_den_def ** 2 +\n",
    "                    comp_num_def ** 2 / comp_den_def ** 4 * comp_num_def) ** 0.5\n",
    "total_comp_err[~np.isfinite(total_comp_err)] = 0\n",
    "total_puri_err = (puri_num_def / puri_den_def ** 2 +\n",
    "                    puri_num_def ** 2 / puri_den_def ** 4 * puri_num_def) ** 0.5\n",
    "total_puri_err[~np.isfinite(total_puri_err)] = 0\n",
    "\n",
    "axs[0].errorbar(bc, combined_puri, ls='-', fmt='s', color='black',\n",
    "            markersize=10, label='Total', yerr=total_puri_err, capsize=4)\n",
    "axs[1].errorbar(bc, combined_comp, ls='-', fmt='s', color='black',\n",
    "            markersize=10, yerr=total_comp_err, capsize=4)\n",
    "\n",
    "# np.save(f'tmp/comb_puri_{qso_factor:0.1f}', combined_puri)\n",
    "# np.save(f'tmp/comb_puri_err_{qso_factor:0.1f}', total_puri_err)\n",
    "\n",
    "# Font size\n",
    "fs = 20\n",
    "\n",
    "axs[0].legend(loc=0, fontsize=15)\n",
    "\n",
    "axs[1].set_xlabel(r'$\\log_{10}L_{\\mathrm{Ly}\\alpha}$ [erg$\\,$s$^{-1}$]', fontsize=20)\n",
    "axs[0].set_ylabel('Purity', fontsize=25)\n",
    "axs[1].set_ylabel('Completeness', fontsize=25)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(labelsize=fs, direction='in', length=6)\n",
    "    ax.yaxis.set_ticks_position('both')\n",
    "    ax.xaxis.set_ticks_position('both')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(42.3, 45.5)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.savefig('figures/Combined_puricomp.pdf', bbox_inches='tight', facecolor='w', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_L_min = 43.5\n",
    "what_bins = (LF_dict['LF_bins'] > this_L_min)\n",
    "what_bins_comp = (np.array(bc) > this_L_min)\n",
    "N_LAEs = (LF_dict['LF_total'] * volwid)[what_bins].sum() / 1.14\n",
    "this_total_comp = comp_num_def[what_bins_comp].sum() / comp_den_def[what_bins_comp].sum()\n",
    "print(f'N_LAEs = {N_LAEs:0.1f}')\n",
    "print(f'median comp = {this_total_comp:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qsofrac_LF(qso_factor):\n",
    "    # My LF\n",
    "    survey_list = [f'minijpasAEGIS00{i}' for i in range(1, 4 + 1)] + ['jnep']\n",
    "\n",
    "    total_volume = 0.\n",
    "    for [this_nb_min, this_nb_max] in comb_nbs_list:\n",
    "        total_volume += effective_volume(this_nb_min, this_nb_max, 'both')\n",
    "    masked_volume = None\n",
    "    hist_mat = None\n",
    "    LF_raw = None\n",
    "    for i, [nb1, nb2] in enumerate(comb_nbs_list):\n",
    "        this_puri = np.interp(LF_bins, bc, np.array(total_puri_list[i]))\n",
    "        this_comp = np.interp(LF_bins, bc, np.array(total_comp_list[i]))\n",
    "        this_hist = None\n",
    "        for survey_name in survey_list:\n",
    "            pathname = f'Luminosity_functions/LF_r17-24_nb{nb1}-{nb2}_ew30_ewoth100_nb_{qso_factor:0.1f}'\n",
    "            filename_hist = f'{pathname}/hist_i_mat_{survey_name}.npy'\n",
    "            hist_i_mat = np.load(filename_hist)\n",
    "\n",
    "            this_field_LF = hist_i_mat / effective_volume(nb1, nb2, survey_name) / bin_width\n",
    "\n",
    "            if this_hist is None:\n",
    "                this_hist = hist_i_mat\n",
    "                field_LF_mat = this_field_LF\n",
    "            else:\n",
    "                this_hist += hist_i_mat\n",
    "                field_LF_mat = np.vstack([field_LF_mat, this_field_LF])\n",
    "\n",
    "        this_hist = this_hist / total_volume / bin_width\n",
    "\n",
    "        this_volume = np.ones_like(LF_bins) * effective_volume(nb1, nb2, 'both')\n",
    "\n",
    "        filename_dict = f'{pathname}/LFs.pkl'\n",
    "        with open(filename_dict, 'rb') as file:\n",
    "            this_LF_raw = pickle.load(file)['LF_total_raw'] * this_volume\n",
    "            if LF_raw is None:\n",
    "                LF_raw = this_LF_raw\n",
    "            else:\n",
    "                LF_raw += this_LF_raw\n",
    "\n",
    "        # Set masked bins by puricomp_mask to 0\n",
    "        N_median_hist = np.nanmedian(this_hist, axis=0) * total_volume * bin_width\n",
    "        puricomp_mask = mask_puricomp(this_puri, this_comp) & (N_median_hist >= min_N_bin)\n",
    "        this_hist[:, ~puricomp_mask] = 0.\n",
    "        this_volume[~puricomp_mask] = 0.\n",
    "\n",
    "        if masked_volume is None:\n",
    "            masked_volume = this_volume\n",
    "        else:\n",
    "            masked_volume += this_volume\n",
    "\n",
    "        if hist_mat is None:\n",
    "            hist_mat = this_hist\n",
    "        else:\n",
    "            hist_mat = hist_mat + this_hist\n",
    "\n",
    "    hist_mat = hist_mat * total_volume / masked_volume\n",
    "\n",
    "    # Field by field variation\n",
    "    field_L_LF_err_percentiles = np.nanpercentile(field_LF_mat, [16, 50, 84], axis=0)\n",
    "    field_LF_err_plus = field_L_LF_err_percentiles[2] - field_L_LF_err_percentiles[1]\n",
    "    field_LF_err_minus = field_L_LF_err_percentiles[1] - field_L_LF_err_percentiles[0]\n",
    "\n",
    "    L_LF_err_percentiles = np.nanpercentile(hist_mat, [16, 50, 84], axis=0)\n",
    "    LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "    LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "    hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "    mask_low_N = (LF_raw < min_N_bin)\n",
    "    for h in [LF_err_plus, LF_err_minus, hist_median]:\n",
    "        h[mask_low_N] = 0.\n",
    "\n",
    "    volwid = total_volume * bin_width\n",
    "\n",
    "    load_LF_name = '/home/alberto/cosmos/LAEs/Luminosity_functions/Total_LF'\n",
    "\n",
    "    yerr_plus = np.load(f'{load_LF_name}/LF_err_plus.npy')\n",
    "    yerr_minus = np.load(f'{load_LF_name}/LF_err_minus.npy')\n",
    "\n",
    "    LF_boots = np.load(f'{load_LF_name}/median_LF_boots.npy')\n",
    "    # Fix yerr_minus:\n",
    "    yerr_minus[LF_boots == 0] = hist_median[LF_boots == 0]\n",
    "\n",
    "\n",
    "    LF_dict = {\n",
    "        'LF_bins': LF_bins,\n",
    "        'LF_total': hist_median,\n",
    "    'LF_total_err': [yerr_minus, yerr_plus]\n",
    "}\n",
    "        \n",
    "    return LF_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MOCK\n",
    "import glob\n",
    "from my_functions import flux_to_mag\n",
    "\n",
    "name = 'QSO_LAES'\n",
    "\n",
    "filename = f'/home/alberto/almacen/Source_cats/{name}/'\n",
    "files = glob.glob(filename + 'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "how_many = 99999999999\n",
    "for i, name in enumerate(files):\n",
    "    if i == how_many: break\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data_qso = pd.concat(fi, axis=0, ignore_index=True)\n",
    "L_lya_mock = data_qso['L_lya']\n",
    "pm_flx_mock = data_qso.to_numpy()[:, 1: 60 + 1].T\n",
    "mag_mock = flux_to_mag(pm_flx_mock[-2], w_central[-2])\n",
    "z_mock = data_qso['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(5, 4), sharex=True,\n",
    "                        gridspec_kw=dict(height_ratios=[2, 1]))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.12)\n",
    "\n",
    "\n",
    "for ii, qso_frac in enumerate([0.1, 0.5, 1.0, 1.5, 2.0]):\n",
    "    iii = ii + 0\n",
    "    this_LF_dict = load_qsofrac_LF(qso_frac)\n",
    "\n",
    "    if ii >= 0:\n",
    "        z_mock_min, z_mock_max = 2, 4\n",
    "        mock_mask = (mag_mock > 17) & (mag_mock < 24) &\\\n",
    "            (z_mock > z_mock_min) & (z_mock < z_mock_max)\n",
    "        bins = np.arange(42, 47, 0.05)\n",
    "        bin_w = bins[1] - bins[0]\n",
    "        volume = z_volume(z_mock_min, z_mock_max, 400)\n",
    "        ax0.hist(L_lya_mock[mock_mask], bins,\n",
    "                 weights=np.full(L_lya_mock[mock_mask].shape,\n",
    "                 (volume * bin_w) ** -1 * qso_frac),\n",
    "                 histtype='step', color=f'C{iii}')\n",
    "    ax0.errorbar(this_LF_dict['LF_bins'], this_LF_dict['LF_total'],\n",
    "            yerr=(this_LF_dict['LF_total_err'][:2] if ii == 2 else None),\n",
    "            linestyle='', fmt='s',\n",
    "            ecolor=f'k', markeredgecolor=f'C{iii}', markerfacecolor='none',\n",
    "            markeredgewidth=1.5, markersize=6,\n",
    "            capsize=4, zorder=99-iii)\n",
    "    # Dummy for legend\n",
    "    ax0.plot([], [], ls='', marker='s', markersize=6, markeredgewidth=1.5,\n",
    "             markerfacecolor='none', label=fr'$\\rho=${qso_frac}', color=f'C{iii}')\n",
    "\n",
    "    #### PURICOMP ####\n",
    "\n",
    "    this_puri = np.load(f'tmp/comb_puri_{qso_frac:0.1f}.npy')\n",
    "    this_puri_err = np.load(f'tmp/comb_puri_err_{qso_frac:0.1f}.npy')\n",
    "\n",
    "    ax1.errorbar(bc, this_puri, ls='-', c=f'C{iii}', fmt='',\n",
    "                       yerr=this_puri_err, capsize=0)\n",
    "\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.tick_params(direction='in', which='both', labelsize=16)\n",
    "    ax1.set_yticks(np.arange(0, 1.25, 0.25))\n",
    "    ax1.set_yticklabels(['0.0', '', '0.5', '', '1.0'])\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "\n",
    "    ##################\n",
    "\n",
    "    ax0.set_ylim(1e-7, 1e-4)\n",
    "    ax0.set_xlim(42.3, 45.7)\n",
    "    ax0.set_yscale('log')\n",
    "    ax0.set_yticks([1e-7, 1e-6, 1e-5, 1e-4])\n",
    "    # ax0.set_yticklabels([-7, -6, -5, -4])\n",
    "    ax0.tick_params(direction='in', which='both', labelsize=16)\n",
    "    ax0.yaxis.set_ticks_position('both')\n",
    "    ax0.xaxis.set_ticks_position('both')\n",
    "    ax0.set_ylabel(r'$\\Phi$ [Mpc$^{-3}\\,\\Delta\\log L^{-1}$]', fontsize=18)\n",
    "    ax0.legend(fontsize=12, loc=0)\n",
    "\n",
    "    ax1.set_xlabel(r'$\\log L_{\\mathrm{Ly}\\alpha}$ (erg$\\,$s$^{-1}$)', fontsize=18)\n",
    "    ax1.set_ylabel('Purity', fontsize=18)\n",
    "\n",
    "fig.savefig('figures/rho_LF_puri_one.pdf', bbox_inches='tight',\n",
    "            facecolor='w', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate my Power-law fit\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "Lx = np.logspace(43, 47, 1000)\n",
    "logLx = np.log10(Lx)\n",
    "Phi_fit_16, Phi_fit_50, Phi_fit_84 = load_mcmc_powerlaw_fit()\n",
    "\n",
    "# Integration limits\n",
    "L_min, L_max = 43.5, 44.5\n",
    "L_int_mask = (logLx >= L_min) & (logLx <= L_max)\n",
    "dlogL = 0.1\n",
    "\n",
    "# Compute the volume\n",
    "z_min, z_max = 2.05, 3.75\n",
    "area_obs = 1\n",
    "vol_int = z_volume(z_min, z_max, area_obs)\n",
    "\n",
    "int_16 = simpson(Phi_fit_16[L_int_mask], logLx[L_int_mask], dlogL) * vol_int\n",
    "int_50 = simpson(Phi_fit_50[L_int_mask], logLx[L_int_mask], dlogL) * vol_int\n",
    "int_84 = simpson(Phi_fit_84[L_int_mask], logLx[L_int_mask], dlogL) * vol_int\n",
    "\n",
    "print(f'$N_$ = {int_50:0.1f} + {int_84 - int_50:0.1f} - {int_50 - int_16:0.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate Schechter\n",
    "\n",
    "Phistar = 3.33e-6\n",
    "Lstar = 10 ** 44.65\n",
    "alpha = -1.34\n",
    "\n",
    "Lx = np.logspace(43, 47, 1000)\n",
    "\n",
    "# Integration limits\n",
    "L_min, L_max = 45.54, 500\n",
    "L_int_mask = (Lx >= 10 ** L_min) & (Lx <= 10 ** L_max)\n",
    "dL = 10 ** 40\n",
    "\n",
    "# Compute the volume\n",
    "nb1, nb2 = 11, 11\n",
    "\n",
    "z_min = (w_central[nb1] - nb_fwhm_Arr[nb1] * 0.5) / w_lya - 1\n",
    "z_max = (w_central[nb2] + nb_fwhm_Arr[nb2] * 0.5) / w_lya - 1\n",
    "\n",
    "area_obs = 8500\n",
    "vol_int = z_volume(z_min, z_max, area_obs)\n",
    "\n",
    "Phi = schechter(Lx, Phistar, Lstar, alpha)\n",
    "\n",
    "int_50 = simpson(Phi[L_int_mask], Lx[L_int_mask], dL) * vol_int\n",
    "\n",
    "print(int_50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
