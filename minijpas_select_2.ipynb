{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_functions import *\n",
    "from LumFunc_miniJPAS import LumFunc_hist\n",
    "from scipy.integrate import simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_converter = lambda s: np.array(s.split()).astype(float)\n",
    "sum_flags = lambda s: np.sum(np.array(s.split()).astype(float))\n",
    "\n",
    "cat = pd.read_csv('csv/minijpas.Flambda_photoz_gaia_7.csv', sep=',', header=1,\n",
    "    converters={0: int, 1: int, 2: split_converter, 3: split_converter, 4: sum_flags,\n",
    "    5: sum_flags})\n",
    "\n",
    "cat = cat[np.array([len(x) for x in cat['FLUX_AUTO']]) != 0] # Drop bad rows due to bad query\n",
    "cat = cat[(cat.FLAGS == 0) & (cat.MASK_FLAGS == 0)] # Drop flagged\n",
    "cat = cat.reset_index()\n",
    "\n",
    "pm_flx = np.stack(cat['FLUX_AUTO'].to_numpy()).T * 1e-19\n",
    "pm_err = np.stack(cat['FLUX_RELERR_AUTO'].to_numpy()).T * pm_flx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx, np.array(w_central.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mag[-2], bins=np.linspace(15, 26, 30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lya = 1215.67 # A\n",
    "\n",
    "N_sources = len(cat['FLUX_AUTO'])\n",
    "z_nb_Arr = w_central[:-4] / w_lya - 1\n",
    "print(N_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_mask = mask_proper_motion(cat)\n",
    "mag_mask = mag[-2] > 17\n",
    "\n",
    "mask = pm_mask & mag_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 30, mask=mask)\n",
    "lya_lines, lya_cont_lines = identify_lines(line, pm_flx, pm_err, first=True)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    400, obs=True, mask=mask)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 17\n",
    "mag_max = 30\n",
    "\n",
    "mag_cut = (mag[-2] > mag_min) & (mag[-2] < mag_max)\n",
    "\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "##\n",
    "nb_min = 5\n",
    "nb_max = 25\n",
    "\n",
    "nbs_to_consider = np.arange(nb_min, nb_max + 1)\n",
    "\n",
    "nb_cut = (np.array(lya_lines) >= nb_min) & (np.array(lya_lines) <= nb_max)\n",
    "\n",
    "z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5)/ w_lya - 1\n",
    "z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5)/ w_lya - 1\n",
    "\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "\n",
    "mask = z_cut & mag_cut\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_other, z_Arr, mask=mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(nice_lya)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, src in enumerate(np.where(nice_lya)[0]):\n",
    "    if k == 5: break\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plot_JPAS_source(pm_flx[:, src], pm_err[:, src])\n",
    "    print(f'z_NB = {z_Arr[src]}')\n",
    "    \n",
    "    ax.plot(w_central[:56], cont_est_lya[:, src], ls='--', c='black')\n",
    "\n",
    "    ax.axvline(w_central[lya_lines[src]], label='Selected NB')\n",
    "    ax.legend(fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = 20\n",
    "bins = np.linspace(42.5, 45.25, N_bins + 1)\n",
    "\n",
    "_, _, L_Arr, L_e_Arr = EW_L_NB(\n",
    "    pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, nice_lya\n",
    ")\n",
    "L_Arr -= 0.04206043155753747\n",
    "\n",
    "\n",
    "total_hist, b = np.histogram(L_Arr[nice_lya], bins=bins)\n",
    "\n",
    "LF_bins = [(b[i] + b[i + 1]) / 2 for i in range(len(b) - 1)]\n",
    "bin_width = b[1] - b[0]\n",
    "volume = z_volume(z_min, z_max, 0.895)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.array([ 0.        ,  0.        ,  0.        , 38.90654585,  9.08544692,\n",
    "        6.9789645 ,  2.21477827,  1.24907731,  0.63762022,  0.70178861,\n",
    "        0.80105365,  0.8532261 ,  1.13501275,  1.77083291,  3.20890848,\n",
    "        4.80531436,  6.27717816,  7.13079086,  8.78795319, 11.30359997])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's compute the error contributio due to L uncertainty as in Spinoso2020:\n",
    "# Perturbing the L with its error and computing 1000 Luminosity functions with\n",
    "# the result.\n",
    "\n",
    "hist_i_mat = np.zeros((1000, N_bins))\n",
    "for k in range(1000):\n",
    "    L_perturbed = np.log10(10 ** L_Arr + L_e_Arr * np.random.randn(N_sources))\n",
    "\n",
    "    hist_i_mat[k], _ = np.histogram(L_perturbed[nice_lya], bins=bins)\n",
    "hist_i_mat *= correct\n",
    "\n",
    "L_LF_err_percentiles = np.percentile(hist_i_mat, [16, 50, 84], axis=0)\n",
    "L_LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "yerr_cor_plus = ((total_hist * correct) ** 0.5 + L_LF_err_plus)\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = ((total_hist * correct) ** 0.5 + L_LF_err_minus)\\\n",
    "     / volume / bin_width\n",
    "\n",
    "ax.errorbar(LF_bins, total_hist / volume / bin_width,\n",
    "    yerr= total_hist ** 0.5 / volume / bin_width,\n",
    "    marker='.', linestyle='', markersize=15, label='Uncorrected')\n",
    "ax.errorbar(LF_bins, total_hist / volume / bin_width * correct,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus],\n",
    "    marker='.', linestyle='', markersize=15, label='Corrected')\n",
    "# ax.errorbar(LF_bins, hist_median / volume / bin_width * correct,\n",
    "#     yerr= [yerr_cor_minus, yerr_cor_plus],\n",
    "#     marker='.', linestyle='', markersize=15, label='Corrected median histogram')\n",
    "\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 10 ** 44.65\n",
    "alpha1 = -1.35\n",
    "Phi1 = schechter(Lx, phistar1, Lstar1, alpha1) * Lx * np.log(10)\n",
    "\n",
    "phistar2 = 10 ** -3.45\n",
    "Lstar2 = 10 ** 42.93\n",
    "alpha2 = -1.93\n",
    "Phi2 = schechter(Lx, phistar2, Lstar2, alpha2) * Lx * np.log(10)\n",
    "\n",
    "ax.plot(np.log10(Lx), Phi1, label='Spinoso 2020 (QSO)')\n",
    "ax.plot(np.log10(Lx), Phi2, label='Sobral 2018 (SF)')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$L_{\\mathrm{Ly}\\alpha}$ (erg s$^{-1}$)', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ (Mpc$^{-3}\\,\\Delta\\logL^{-1}$)',\n",
    "    fontsize=15)\n",
    "ax.set_ylim(1e-8, 5e-3)\n",
    "ax.set_xlim(42, 45.5)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = z_volume(2.45, 3.54, 0.895)\n",
    "\n",
    "L_integrate = np.linspace(10 ** 43.5, 10 ** 44.55, 1000)\n",
    "Phi_integrate = schechter(L_integrate, phistar1, Lstar1, alpha1)\n",
    "\n",
    "L_integrate2 = 10 ** np.linspace(43, 43.4, 1000)\n",
    "Phi_integrate2 = schechter(L_integrate2, phistar1, Lstar1, alpha1)\n",
    "\n",
    "Nt = simpson(Phi_integrate, L_integrate) * vol\n",
    "Ne = Nt - simpson(Phi_integrate2, L_integrate2) * vol\n",
    "\n",
    "print('N_expected = {0:0.0f} +- {1:0.0f}'.format(Nt, Ne))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46cea94afe1f0d88e229837b28e72c2401fa9cb21844b20e15824a5f97d32088"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
