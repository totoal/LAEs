{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_functions import *\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "from scipy.stats import binned_statistic_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zero_point_error(tile_id_Arr):\n",
    "    ## Load Zero Point magnitudes\n",
    "    zpt_cat = pd.read_csv('csv/minijpas.CalibTileImage.csv', sep=',', header=1)\n",
    "\n",
    "    zpt_mag = zpt_cat['ZPT'].to_numpy()\n",
    "    zpt_err = zpt_cat['ERRZPT'].to_numpy()\n",
    "\n",
    "    ones = np.ones((len(w_central), len(zpt_mag)))\n",
    "\n",
    "    zpt_err = (\n",
    "        mag_to_flux(ones * zpt_mag, w_central.reshape(-1, 1))\n",
    "        - mag_to_flux(ones * (zpt_mag + zpt_err), w_central.reshape(-1, 1))\n",
    "    )\n",
    "\n",
    "    # Duplicate rows to match the tile_ID of each source\n",
    "    idx = np.empty(tile_id_Arr.shape).astype(int)\n",
    "\n",
    "    zpt_id = zpt_cat['TILE_ID'].to_numpy()\n",
    "    for src in range(len(tile_id_Arr)):\n",
    "        idx[src] = np.where(\n",
    "            (zpt_id == tile_id_Arr[src]) & (zpt_cat['IS_REFERENCE_METHOD'] == 1)\n",
    "        )[0][0]\n",
    "    \n",
    "    zpt_err = zpt_err[:, idx]\n",
    "\n",
    "    return zpt_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_converter = lambda s: np.array(s.split()).astype(float)\n",
    "sum_flags = lambda s: np.sum(np.array(s.split()).astype(float))\n",
    "\n",
    "cat = pd.read_csv('csv/minijpas.Flambda_aper3_photoz_gaia_3.csv', sep=',', header=1,\n",
    "    converters={0: int, 1: int, 2: split_converter, 3: split_converter, 4: sum_flags,\n",
    "    5: sum_flags})\n",
    "\n",
    "cat = cat[np.array([len(x) for x in cat['FLUX_APER_3_0']]) != 0] # Drop bad rows due to bad query\n",
    "cat = cat[(cat.FLAGS == 0) & (cat.MASK_FLAGS == 0)] # Drop flagged\n",
    "cat = cat.reset_index()\n",
    "\n",
    "tile_id = cat['TILE_ID'].to_numpy()\n",
    "\n",
    "pm_flx = np.stack(cat['FLUX_APER_3_0'].to_numpy()).T * 1e-19\n",
    "pm_err = np.stack(cat['FLUX_RELERR_APER_3_0'].to_numpy()).T * pm_flx\n",
    "\n",
    "pm_err = (pm_err ** 2 + Zero_point_error(cat['TILE_ID']) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx[-2], w_central[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lya = 1215.67 # A\n",
    "\n",
    "N_sources = len(cat['FLUX_APER_3_0'])\n",
    "z_nb_Arr = w_central[:-4] / w_lya - 1\n",
    "print(N_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_mask = mask_proper_motion(cat)\n",
    "mag_mask = mag > 17\n",
    "\n",
    "mask = pm_mask & mag_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 20, mask=mask)\n",
    "lya_lines, lya_cont_lines = identify_lines(line, pm_flx, pm_err, first=True)\n",
    "lya_lines = np.array(lya_lines)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    400, obs=True, mask=mask)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 17\n",
    "mag_max = 24\n",
    "\n",
    "mag_cut = (mag > mag_min) & (mag < mag_max)\n",
    "\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "##\n",
    "nb_min = 5\n",
    "nb_max = 20\n",
    "\n",
    "nbs_to_consider = np.arange(nb_min, nb_max + 1)\n",
    "\n",
    "nb_cut = (np.array(lya_lines) >= nb_min) & (np.array(lya_lines) <= nb_max)\n",
    "\n",
    "z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5)/ w_lya - 1\n",
    "z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5)/ w_lya - 1\n",
    "\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "\n",
    "mask = z_cut & mag_cut\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_other, z_Arr, mask=mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(nice_lya)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, src in enumerate(np.where(nice_lya)[0]):\n",
    "    if k == 5: break\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plot_JPAS_source(pm_flx[:, src], pm_err[:, src])\n",
    "    print(f'z_NB = {z_Arr[src]}')\n",
    "    \n",
    "    ax.plot(w_central[:56], cont_est_lya[:, src], ls='--', c='black')\n",
    "\n",
    "    ax.axvline(w_central[lya_lines[src]], label='Selected NB')\n",
    "    ax.legend(fontsize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_cor = np.array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       0.35371549, 0.80495827, 0.68250439, 0.40929278, 0.72569364,\n",
    "       0.70629624, 1.11747569, 0.43438307, 0.77575306, 0.55578691,\n",
    "       0.7410738 , 0.69597519, 0.90738277, 0.85715703, 0.55912331,\n",
    "       0.86807824, 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness_curve(m50, k, mag):\n",
    "    return 1. - 1. / (np.exp(-k * (mag - m50)) + 1)\n",
    "\n",
    "def intrinsic_completeness(star_prob, r_Arr, tile_id):\n",
    "    TileImage = pd.read_csv('csv/minijpas.TileImage.csv', header=1)\n",
    "    where = np.zeros(r_Arr.shape).astype(int)\n",
    "\n",
    "    for src in range(len(r_Arr)):\n",
    "        where[src] = np.where(\n",
    "            (TileImage['TILE_ID'] == tile_id[src])\n",
    "            & (TileImage['FILTER_ID'] == 59)\n",
    "        )[0]\n",
    "\n",
    "    m50s = TileImage['M50S'][where]\n",
    "    ks = TileImage['KS'][where]\n",
    "    m50g = TileImage['M50G'][where]\n",
    "    kg = TileImage['KG'][where]\n",
    "\n",
    "    isstar = (star_prob >= 0.5).to_numpy()\n",
    "\n",
    "    intcomp = np.empty(r_Arr.shape)\n",
    "    intcomp[isstar] = completeness_curve(m50s[isstar], ks[isstar], r_Arr[isstar])\n",
    "    intcomp[~isstar] = completeness_curve(m50g[~isstar], kg[~isstar], r_Arr[~isstar])\n",
    "\n",
    "    return intcomp\n",
    "\n",
    "intrinsic_comp = intrinsic_completeness(\n",
    "    cat['morph_prob_star'][nice_lya], mag[nice_lya], tile_id[nice_lya]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_LF(L_Arr, r_Arr, puri2d, comp2d, L_bins, r_bins):\n",
    "    w_mat = puri2d / comp2d\n",
    "    w_mat[np.isnan(w_mat) | np.isinf(w_mat)] = 0.\n",
    "\n",
    "    # Add a zeros row to w_mat for perturbed luminosities exceeding the binning\n",
    "    w_mat = np.vstack([w_mat, np.zeros(w_mat.shape[1])])\n",
    "\n",
    "    bs = binned_statistic_2d(\n",
    "        L_Arr, r_Arr, None, 'count', bins=[L_bins, r_bins], expand_binnumbers=True\n",
    "    )\n",
    "    xx, yy = bs.binnumber\n",
    "\n",
    "    return w_mat[xx - 1, yy - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, L_Arr, _, _, _ = EW_L_NB(\n",
    "    pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, nice_lya=nice_lya,\n",
    "    F_bias=F_cor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_bins = np.load('npy/puricomp2d_L_bins.npy')\n",
    "r_bins = np.load('npy/puricomp2d_r_bins.npy')\n",
    "puri2d = np.load('npy/puri2d.npy')\n",
    "comp2d = np.load('npy/comp2d.npy')\n",
    "\n",
    "# Selection algorithm weights\n",
    "weights = weights_LF(L_Arr[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins)\n",
    "\n",
    "# Add the intrinsic completeness\n",
    "weights /= intrinsic_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins_1 = 6\n",
    "N_bins_2 = 3\n",
    "bins = np.concatenate((\n",
    "    np.linspace(43.2, 44.25, N_bins_1 + 1),\n",
    "    np.linspace(44.25, 45.5, N_bins_2 + 1)[1:]\n",
    "))\n",
    "\n",
    "total_hist_cor, b = np.histogram(L_Arr[nice_lya], bins=bins, weights=weights)\n",
    "total_hist, b = np.histogram(L_Arr[nice_lya], bins=bins)\n",
    "\n",
    "LF_bins = np.array([(b[i] + b[i + 1]) / 2 for i in range(len(b) - 1)])\n",
    "\n",
    "bin_width = np.array([b[i + 1] - b[i] for i in range(len(b) - 1)])\n",
    "\n",
    "volume = z_volume(z_min, z_max, 0.895)\n",
    "\n",
    "total_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's compute the error contribution due to L uncertainty as in Spinoso2020:\n",
    "# Perturbing the L with its error and computing 1000 Luminosity functions with\n",
    "# the result.\n",
    "\n",
    "L_e_Arr = np.load('npy/L_nb_err.npy')[lya_lines]\n",
    "\n",
    "hist_i_mat = np.zeros((1000, N_bins_1 + N_bins_2))\n",
    "for k in range(1000):\n",
    "    L_perturbed = L_Arr + L_e_Arr * np.random.randn(N_sources)\n",
    "    L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "    w = weights_LF(\n",
    "        L_perturbed[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins\n",
    "    )\n",
    "    hist_i_mat[k], _ = np.histogram(L_perturbed[nice_lya], bins=bins, weights=w)\n",
    "\n",
    "L_LF_err_percentiles = np.percentile(hist_i_mat, [16, 50, 84], axis=0)\n",
    "L_LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "# TODO: this\n",
    "for k in range(1000):\n",
    "    add_sources = int(np.random.randn(total_hist.shape) * total_hist ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "yerr_cor_plus = (total_hist_cor + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (total_hist_cor + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "xerr = bin_width / 2\n",
    "\n",
    "ax.errorbar(LF_bins, total_hist / volume / bin_width,\n",
    "    yerr= total_hist ** 0.5 / volume / bin_width,\n",
    "    xerr=xerr,\n",
    "    marker='.', linestyle='', markersize=15, label='Uncorrected')\n",
    "ax.errorbar(LF_bins + 0.007, total_hist_cor / volume / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus],\n",
    "    xerr=xerr,\n",
    "    marker='.', linestyle='', markersize=15, label='Corrected')\n",
    "# yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "#      / volume / bin_width\n",
    "# yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "#      / volume / bin_width\n",
    "# xerr = bin_width / 2\n",
    "# ax.errorbar(LF_bins, hist_median / volume / bin_width,\n",
    "#     yerr= [yerr_cor_minus, yerr_cor_plus],\n",
    "#     marker='.', linestyle='', markersize=15, label='Corrected median histogram')\n",
    "\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 10 ** 44.65\n",
    "alpha1 = -1.35\n",
    "Phi1 = schechter(Lx, phistar1, Lstar1, alpha1) * Lx * np.log(10)\n",
    "\n",
    "phistar2 = 10 ** -3.45\n",
    "Lstar2 = 10 ** 42.93\n",
    "alpha2 = -1.93\n",
    "Phi2 = schechter(Lx, phistar2, Lstar2, alpha2) * Lx * np.log(10)\n",
    "\n",
    "ax.plot(np.log10(Lx), Phi1, label='Spinoso 2020 (QSO)')\n",
    "ax.plot(np.log10(Lx), Phi2, label='Sobral 2018 (SF)')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$L_{\\mathrm{Ly}\\alpha}$ (erg s$^{-1}$)', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ (Mpc$^{-3}\\,\\Delta\\logL^{-1}$)',\n",
    "    fontsize=15)\n",
    "ax.set_ylim(1e-8, 5e-4)\n",
    "ax.set_xlim(42.75, 45.5)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_hist_cor)\n",
    "print(total_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cat['morph_prob_star'][nice_lya], 30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46cea94afe1f0d88e229837b28e72c2401fa9cb21844b20e15824a5f97d32088"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
