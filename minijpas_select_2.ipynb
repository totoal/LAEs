{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from my_functions import *\n",
    "from LF_puricomp_corrections import weights_LF\n",
    "\n",
    "from scipy.stats import binned_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zero_point_error(tile_id_Arr, catname):\n",
    "    ## Load Zero Point magnitudes\n",
    "    zpt_cat = pd.read_csv(f'csv/{catname}.CalibTileImage.csv', sep=',', header=1)\n",
    "\n",
    "    zpt_mag = zpt_cat['ZPT'].to_numpy()\n",
    "    zpt_err = zpt_cat['ERRZPT'].to_numpy()\n",
    "\n",
    "    ones = np.ones((len(w_central), len(zpt_mag)))\n",
    "\n",
    "    zpt_err = (\n",
    "        mag_to_flux(ones * zpt_mag, w_central.reshape(-1, 1))\n",
    "        - mag_to_flux(ones * (zpt_mag + zpt_err), w_central.reshape(-1, 1))\n",
    "    )\n",
    "\n",
    "    # Duplicate rows to match the tile_ID of each source\n",
    "    idx = np.empty(tile_id_Arr.shape).astype(int)\n",
    "\n",
    "    zpt_id = zpt_cat['TILE_ID'].to_numpy()\n",
    "    for src in range(len(tile_id_Arr)):\n",
    "        idx[src] = np.where(\n",
    "            (zpt_id == tile_id_Arr[src]) & (zpt_cat['IS_REFERENCE_METHOD'] == 1)\n",
    "        )[0][0]\n",
    "    \n",
    "    zpt_err = zpt_err[:, idx]\n",
    "\n",
    "    return zpt_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_converter = lambda s: np.array(s.split()).astype(float)\n",
    "sum_flags = lambda s: np.sum(np.array(s.split()).astype(float))\n",
    "\n",
    "def load_stuff():\n",
    "    pm_flx = np.array([]).reshape(60, 0)\n",
    "    pm_err = np.array([]).reshape(60, 0)\n",
    "    tile_id = np.array([])\n",
    "    parallax_sn = np.array([])\n",
    "    pmra_sn = np.array([])\n",
    "    pmdec_sn = np.array([])\n",
    "    starprob = np.array([])\n",
    "    spCl = np.array([])\n",
    "    zsp = np.array([])\n",
    "    N_minijpas = 0\n",
    "    for name in ['minijpas', 'jnep']:\n",
    "        cat = pd.read_csv(f'csv/{name}.Flambda_aper3_photoz_gaia_3.csv', sep=',', header=1,\n",
    "            converters={0: int, 1: int, 2: split_converter, 3: split_converter, 4: sum_flags,\n",
    "            5: sum_flags})\n",
    "\n",
    "        cat = cat[np.array([len(x) for x in cat['FLUX_APER_3_0']]) != 0] # Drop bad rows due to bad query\n",
    "        cat = cat[(cat.FLAGS == 0) & (cat.MASK_FLAGS == 0)] # Drop flagged\n",
    "        cat = cat.reset_index()\n",
    "\n",
    "        tile_id_i = cat['TILE_ID'].to_numpy()\n",
    "\n",
    "        parallax_i = cat['parallax'].to_numpy() / cat['parallax_error'].to_numpy()\n",
    "        pmra_i = cat['pmra'].to_numpy() / cat['pmra_error'].to_numpy()\n",
    "        pmdec_i = cat['pmdec'].to_numpy() / cat['pmdec_error'].to_numpy()\n",
    "\n",
    "        pm_flx_i = np.stack(cat['FLUX_APER_3_0'].to_numpy()).T * 1e-19\n",
    "        pm_err_i = np.stack(cat['FLUX_RELERR_APER_3_0'].to_numpy()).T * pm_flx_i\n",
    "\n",
    "        if name == 'minijpas':\n",
    "            N_minijpas = pm_flx_i.shape[1]\n",
    "\n",
    "        starprob_i = cat['morph_prob_star']\n",
    "\n",
    "        pm_err_i = (pm_err_i ** 2 + Zero_point_error(cat['TILE_ID'], name) ** 2) ** 0.5\n",
    "\n",
    "        spCl_i = cat['spCl']\n",
    "        zsp_i = cat['zsp']\n",
    "\n",
    "        pm_flx = np.hstack((pm_flx, pm_flx_i))\n",
    "        pm_err = np.hstack((pm_err, pm_err_i))\n",
    "        tile_id = np.concatenate((tile_id, tile_id_i))\n",
    "        pmra_sn = np.concatenate((pmra_sn, pmra_i))\n",
    "        pmdec_sn = np.concatenate((pmdec_sn, pmdec_i))\n",
    "        parallax_sn = np.concatenate((parallax_sn, parallax_i))\n",
    "        starprob = np.concatenate((starprob, starprob_i))\n",
    "        spCl = np.concatenate((spCl, spCl_i))\n",
    "        zsp = np.concatenate((zsp, zsp_i))\n",
    "\n",
    "    return pm_flx, pm_err, tile_id, pmra_sn, pmdec_sn, parallax_sn, starprob, N_minijpas,\\\n",
    "        spCl, zsp\n",
    "\n",
    "pm_flx, pm_err, tile_id, pmra_sn, pmdec_sn, parallax_sn, starprob, N_minijpas,\\\n",
    "    spCl, zsp = load_stuff()\n",
    "\n",
    "N_sources = pm_flx.shape[1]\n",
    "is_minijpas_source = np.ones(N_sources).astype(bool)\n",
    "is_minijpas_source[N_minijpas:] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = flux_to_mag(pm_flx[-2], w_central[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_lya = 1215.67 # A\n",
    "\n",
    "z_nb_Arr = w_central[:-4] / w_lya - 1\n",
    "print(N_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_mask = mask_proper_motion(parallax_sn, pmra_sn, pmdec_sn)\n",
    "mag_mask = (mag > 17) & (mag < 24)\n",
    "\n",
    "mask = pm_mask & mag_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lya search\n",
    "cont_est_lya, cont_err_lya = estimate_continuum(pm_flx, pm_err, IGM_T_correct=True)\n",
    "line = is_there_line(pm_flx, pm_err, cont_est_lya, cont_err_lya, 20, mask=mask)\n",
    "lya_lines, lya_cont_lines = identify_lines(line, pm_flx, pm_err, first=True)\n",
    "lya_lines = np.array(lya_lines)\n",
    "\n",
    "# Other lines\n",
    "cont_est_other, cont_err_other = estimate_continuum(pm_flx, pm_err, IGM_T_correct=False)\n",
    "line_other = is_there_line(pm_flx, pm_err, cont_est_other, cont_err_other,\n",
    "    400, obs=True, mask=mask)\n",
    "other_lines = identify_lines(line_other, pm_flx, pm_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min = 17\n",
    "mag_max = 24\n",
    "\n",
    "mag_cut = (mag > mag_min) & (mag < mag_max)\n",
    "\n",
    "z_Arr = np.zeros(N_sources)\n",
    "z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "##\n",
    "nb_min = 5\n",
    "nb_max = 25\n",
    "\n",
    "nbs_to_consider = np.arange(nb_min, nb_max + 1)\n",
    "\n",
    "nb_cut = (np.array(lya_lines) >= nb_min) & (np.array(lya_lines) <= nb_max)\n",
    "\n",
    "z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5)/ w_lya - 1\n",
    "z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5)/ w_lya - 1\n",
    "\n",
    "z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "\n",
    "mask = z_cut & mag_cut\n",
    "\n",
    "nice_lya = nice_lya_select(\n",
    "    lya_lines, other_lines, pm_flx, pm_err, cont_est_lya, z_Arr, mask=mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(nice_lya)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, src in enumerate(np.where(nice_lya)[0]):\n",
    "#     if k == 5: break\n",
    "#     fig = plt.figure(figsize=(8, 6))\n",
    "#     ax = plot_JPAS_source(pm_flx[:, src], pm_err[:, src])\n",
    "#     print(f'z_NB = {z_Arr[src]}')\n",
    "    \n",
    "#     ax.plot(w_central[:56], cont_est_lya[:, src], ls='--', c='black')\n",
    "\n",
    "#     ax.axvline(w_central[lya_lines[src]], label='Selected NB')\n",
    "#     ax.legend(fontsize=13)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_cor = np.array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.2364775 , 0.94020108, 0.9336366 , 1.26013918, 0.89037066,\n",
    "       0.9590503 , 1.17125337, 1.04022941, 1.00937226, 0.92926172,\n",
    "       1.43682693, 0.97655271, 1.21604177, 1.18544034, 1.61925284,\n",
    "       1.38372073, 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
    "       1.        , 1.        , 1.        , 1.        , 1.        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, L_Arr, _, _, _ = EW_L_NB(\n",
    "    pm_flx, pm_err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, nice_lya=nice_lya,\n",
    "    F_bias=F_cor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_bins = np.load('npy/puricomp2d_L_bins.npy')\n",
    "r_bins = np.load('npy/puricomp2d_r_bins.npy')\n",
    "puri2d = np.load('npy/puri2d.npy')\n",
    "comp2d = np.load('npy/comp2d.npy')\n",
    "lyacomp = np.load('npy/lya_comp.npy')\n",
    "\n",
    "# Selection algorithm weights\n",
    "weights = weights_LF(\n",
    "    L_Arr[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins, z_Arr[nice_lya],\n",
    "    starprob[nice_lya], tile_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins_1 = 9\n",
    "N_bins_2 = 6\n",
    "bins = np.concatenate((\n",
    "    np.linspace(42, 44.25, N_bins_1 + 1),\n",
    "    np.linspace(44.25, 45.5, N_bins_2 + 1)[1:]\n",
    "))\n",
    "\n",
    "# total_hist_cor, b = np.histogram(L_Arr[nice_lya], bins=bins, weights=weights)\n",
    "total_hist, b = np.histogram(L_Arr[nice_lya], bins=bins)\n",
    "\n",
    "LF_bins = np.array([(b[i] + b[i + 1]) / 2 for i in range(len(b) - 1)])\n",
    "\n",
    "bin_width = np.array([b[i + 1] - b[i] for i in range(len(b) - 1)])\n",
    "\n",
    "volume = z_volume(z_min, z_max, 0.895 + 0.24)\n",
    "volume_mj = z_volume(z_min, z_max, 0.895)\n",
    "volume_jn = z_volume(z_min, z_max, 0.24)\n",
    "\n",
    "total_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's compute the error contribution due to L uncertainty as in Spinoso2020:\n",
    "# Perturbing the L with its error and computing 1000 Luminosity functions with\n",
    "# the result.\n",
    "\n",
    "def LF_perturb_err(L_Arr, L_e_Arr, nice_lya, mag, z_Arr, starprob,\n",
    "    bins, L_binning, which_w=[0, 2]):\n",
    "    N_bins = len(bins) - 1\n",
    "\n",
    "    hist_i_mat = np.zeros((1000, N_bins))\n",
    "\n",
    "    L_binning_position = binned_statistic(\n",
    "        L_Arr, None, 'count', bins=L_binning\n",
    "    ).binnumber\n",
    "    L_binning_position[L_binning_position > len(L_binning) - 2] = len(L_binning) - 2\n",
    "\n",
    "    L_err = L_e_Arr[:, L_binning_position - 1]\n",
    "\n",
    "    N_sources = len(L_Arr)\n",
    "    for k in range(1000):\n",
    "        randN = np.random.randn(N_sources)\n",
    "        L_perturbation = np.zeros(N_sources)\n",
    "        L_perturbation[randN >= 0.] = L_err[0, randN >= 0.] * randN[randN >= 0.]\n",
    "        L_perturbation[randN < 0.] = L_err[1, randN < 0.] * randN[randN < 0.]\n",
    "\n",
    "        L_perturbed = L_Arr + L_perturbation\n",
    "        L_perturbed[np.isnan(L_perturbed)] = 0.\n",
    "\n",
    "        w = weights_LF(\n",
    "            L_perturbed[nice_lya], mag[nice_lya], puri2d, comp2d, L_bins, r_bins,\n",
    "            z_Arr[nice_lya], starprob[nice_lya], tile_id, which_w\n",
    "        )\n",
    "        hist = np.histogram(L_perturbed[nice_lya], bins=bins)[0]\n",
    "        hist_poiss_err = np.round(\n",
    "            hist[0] ** 0.5 * np.random.randn(len(bins) - 1), 0\n",
    "        ).astype(int)\n",
    "\n",
    "        hist_binnumber = binned_statistic(L_perturbed[nice_lya], None, 'count', bins=bins)[2]\n",
    "\n",
    "        L_Arr_to_hist = np.array([])\n",
    "        w_Arr_to_hist = np.array([])\n",
    "        for bin in range(N_bins):\n",
    "            where_bin = np.where(hist_binnumber == bin + 1)[0]\n",
    "            try:\n",
    "                idx = np.random.choice(\n",
    "                    where_bin, size=(hist_poiss_err[bin] + hist[bin]),\n",
    "                    replace=True\n",
    "                )\n",
    "                L_Arr_to_hist = np.hstack([L_Arr_to_hist, L_perturbed[nice_lya][idx]])\n",
    "                w_Arr_to_hist = np.hstack([w_Arr_to_hist, w[idx]])\n",
    "            except:\n",
    "                pass\n",
    "        hist_i_mat[k], _ = np.histogram(L_Arr_to_hist, bins=bins, weights=w_Arr_to_hist)\n",
    "\n",
    "    L_LF_err_percentiles = np.percentile(hist_i_mat, [16, 50, 84], axis=0)\n",
    "    return L_LF_err_percentiles\n",
    "\n",
    "L_e_Arr = np.load('npy/L_nb_err.npy')\n",
    "L_binning = np.load('npy/L_nb_err_binning.npy')\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(\n",
    "    L_Arr, L_e_Arr, nice_lya, mag, z_Arr, starprob, bins, L_binning\n",
    ")\n",
    "L_LF_err_plus = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median = L_LF_err_percentiles[1]\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(\n",
    "    L_Arr[is_minijpas_source], L_e_Arr, nice_lya[is_minijpas_source],\n",
    "    mag[is_minijpas_source], z_Arr[is_minijpas_source], starprob[is_minijpas_source],\n",
    "    bins, L_binning\n",
    ")\n",
    "L_LF_err_plus_mj = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus_mj = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median_mj = L_LF_err_percentiles[1]\n",
    "\n",
    "L_LF_err_percentiles = LF_perturb_err(\n",
    "    L_Arr[~is_minijpas_source], L_e_Arr, nice_lya[~is_minijpas_source],\n",
    "    mag[~is_minijpas_source], z_Arr[~is_minijpas_source], starprob[~is_minijpas_source],\n",
    "    bins, L_binning\n",
    ")\n",
    "L_LF_err_plus_jn = L_LF_err_percentiles[2] - L_LF_err_percentiles[1]\n",
    "L_LF_err_minus_jn = L_LF_err_percentiles[1] - L_LF_err_percentiles[0]\n",
    "hist_median_jn = L_LF_err_percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# yerr_cor_plus = (total_hist_cor + L_LF_err_plus ** 2) ** 0.5\\\n",
    "#      / volume / bin_width\n",
    "# yerr_cor_minus = (total_hist_cor + L_LF_err_minus ** 2) ** 0.5\\\n",
    "#      / volume / bin_width\n",
    "# xerr = bin_width / 2\n",
    "\n",
    "# ax.errorbar(LF_bins, total_hist / volume / bin_width,\n",
    "#     yerr= total_hist ** 0.5 / volume / bin_width,\n",
    "#     xerr=xerr,\n",
    "#     marker='.', linestyle='', markersize=15, label='Uncorrected')\n",
    "# ax.errorbar(LF_bins + 0.007, total_hist_cor / volume / bin_width,\n",
    "#     yerr= [yerr_cor_minus, yerr_cor_plus],\n",
    "#     xerr=xerr,\n",
    "#     marker='.', linestyle='', markersize=15, label='Corrected')\n",
    "yerr_cor_plus = (hist_median + L_LF_err_plus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "yerr_cor_minus = (hist_median + L_LF_err_minus ** 2) ** 0.5\\\n",
    "     / volume / bin_width\n",
    "xerr = bin_width / 2\n",
    "ax.errorbar(LF_bins, hist_median / volume / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus], xerr=xerr,\n",
    "    marker='s', linestyle='', color='k', capsize=4,\n",
    "    label='miniJPAS + J-NEP', zorder=99)\n",
    "\n",
    "\n",
    "yerr_cor_plus = (hist_median_mj + L_LF_err_plus_mj ** 2) ** 0.5\\\n",
    "     / volume_mj / bin_width\n",
    "yerr_cor_minus = (hist_median_mj + L_LF_err_minus_mj ** 2) ** 0.5\\\n",
    "     / volume_mj / bin_width\n",
    "xerr = bin_width / 2\n",
    "ax.errorbar(LF_bins + 0.012, hist_median_mj / volume_mj / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus], xerr=xerr,\n",
    "    marker='^', linestyle='', markersize=10, label='miniJPAS')\n",
    "\n",
    "\n",
    "yerr_cor_plus = (hist_median_jn + L_LF_err_plus_jn ** 2) ** 0.5\\\n",
    "     / volume_jn / bin_width\n",
    "yerr_cor_minus = (hist_median_jn + L_LF_err_minus_jn ** 2) ** 0.5\\\n",
    "     / volume_jn / bin_width\n",
    "xerr = bin_width / 2\n",
    "ax.errorbar(LF_bins + 0.024, hist_median_jn / volume_jn / bin_width,\n",
    "    yerr= [yerr_cor_minus, yerr_cor_plus], xerr=xerr,\n",
    "    marker='^', linestyle='', markersize=10, label='J-NEP')\n",
    "\n",
    "\n",
    "Lx = np.linspace(10 ** 42, 10 ** 46, 10000)\n",
    "phistar1 = 3.33e-6\n",
    "Lstar1 = 44.65\n",
    "alpha1 = -1.35\n",
    "\n",
    "phistar2 = -3.45\n",
    "Lstar2 = 42.93\n",
    "alpha2 = -1.93\n",
    "\n",
    "phistar1_err = 0.19e-6\n",
    "Lstar1_err = 0.65\n",
    "alpha1_err = 0.84\n",
    "phistar2_err = 0.255\n",
    "Lstar2_err = 0.13\n",
    "alpha2_err = 0.12\n",
    "\n",
    "Phi_center = double_schechter(\n",
    "     Lx, phistar1, 10 ** Lstar1, alpha1, 10 ** phistar2, 10 ** Lstar2, alpha2\n",
    ") * Lx * np.log(10)\n",
    "\n",
    "ax.plot(np.log10(Lx), Phi_center)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$L_{\\mathrm{Ly}\\alpha}$ (erg s$^{-1}$)', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Phi$ (Mpc$^{-3}\\,\\Delta\\logL^{-1}$)',\n",
    "    fontsize=15)\n",
    "ax.set_ylim(1e-8, 1e-3)\n",
    "ax.set_xlim(42., 46)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_hist)\n",
    "print(hist_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "ax.hist(starprob[nice_lya], 10)\n",
    "\n",
    "ax.set_xlabel('p(star)', fontsize=15)\n",
    "ax.set_ylabel('N', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} candidates'.format(count_true(nice_lya)))\n",
    "print('{} QSO'.format(count_true(spCl[nice_lya] == 'QSO')))\n",
    "print('{} GALAXY'.format(count_true(spCl[nice_lya] == 'GALAXY')))\n",
    "print('{} No SDSS counterpart'.format(count_true(spCl[nice_lya].astype(str) == 'nan')))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "ax.scatter(zsp[nice_lya], z_Arr[nice_lya], c='k')\n",
    "\n",
    "ax.set_xlabel('SDSS z$_\\mathrm{spec}$', fontsize=15)\n",
    "ax.set_ylabel('NB z', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perc_total = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, which_w=[])[1]\n",
    "# perc_0 = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, which_w=[0])[1]\n",
    "# perc_1 = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, which_w=[1])[1]\n",
    "# perc_2 = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, which_w=[2])[1]\n",
    "# perc_012 = LF_perturb_err(L_Arr, L_e_Arr, nice_lya, bins, L_binning, which_w=[0, 1, 2])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(7, 12))\n",
    "\n",
    "# ax.plot(LF_bins, perc_0 / perc_total, ls='--', label='Detection puri/comp')\n",
    "# ax.plot(LF_bins, perc_1 / perc_total, ls='--', label=r'$L_{Lya}$ completeness')\n",
    "# ax.plot(LF_bins, perc_2 / perc_total, ls='--', label='r completeness curve')\n",
    "# ax.plot(LF_bins, perc_012 / perc_total, c='k')\n",
    "# ax.hlines(1, 42, 46, color='dimgray', linewidth=1, ls='dotted')\n",
    "\n",
    "# ax.set_xlim((43.25, 44.9))\n",
    "# ax.set_ylim((0, 8))\n",
    "\n",
    "# ax.legend(fontsize=15)\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46cea94afe1f0d88e229837b28e72c2401fa9cb21844b20e15824a5f97d32088"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
