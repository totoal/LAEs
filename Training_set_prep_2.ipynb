{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from my_functions import *\n",
    "from load_mocks import load_QSO_mock, load_SF_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_prep(pm_flx, pm_err, L_lya, L_Arr, zspec, N_samples=3_000):\n",
    "    # L_min = 42\n",
    "    # L_max = 45.5\n",
    "    # my_L_Arr = L_min + np.random.rand(N_samples) * (L_max - L_min)\n",
    "\n",
    "    # where_close_L = np.zeros(N_samples).astype(int)\n",
    "    # for src in range(N_samples):\n",
    "    #     where_close_L[src] = np.argmin(np.abs(my_L_Arr[src] - L_lya))\n",
    "    where_close_L = np.arange(N_samples)\n",
    "\n",
    "    sampled_pm_flx = pm_flx[:, where_close_L]\n",
    "    sampled_pm_err = pm_err[:, where_close_L]\n",
    "    sampled_L_Arr = L_Arr[where_close_L]\n",
    "    sampled_zspec = zspec[where_close_L]\n",
    "    sampled_labels = L_lya[where_close_L]\n",
    "\n",
    "    return sampled_pm_flx, sampled_pm_err, sampled_L_Arr, sampled_zspec, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_or_t = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qso_name = f'QSO_double_{t_or_t}_minijpas_0'\n",
    "sf_name = f'LAE_12.5deg_z2-4.25_{t_or_t}_minijpas_0'\n",
    "qso_flx, qso_err, EW_qso, qso_zspec, qso_L_lya = load_QSO_mock(qso_name, add_errs=True, how_many=10)\n",
    "sf_flx, sf_err, EW_sf, sf_zspec, sf_L_lya= load_SF_mock(sf_name, add_errs=True, how_many=10)\n",
    "\n",
    "qso_cont_est_lya, qso_cont_err_lya = estimate_continuum(qso_flx, qso_err, IGM_T_correct=True)\n",
    "qso_line = is_there_line(qso_flx, qso_err, qso_cont_est_lya, qso_cont_err_lya, 30)\n",
    "qso_lya_lines, qso_lya_cont_lines, _ = identify_lines(\n",
    "    qso_line, qso_flx, qso_err, first=True, return_line_width=True\n",
    ")\n",
    "\n",
    "qso_z_Arr = np.zeros(len(qso_zspec))\n",
    "qso_z_Arr[np.where(np.array(qso_lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(qso_lya_cont_lines)[np.where(np.array(qso_lya_lines) != -1)])\n",
    "\n",
    "_, _, L_qso_Arr, _, _, _ = EW_L_NB(\n",
    "    qso_flx, qso_err, qso_cont_est_lya, qso_cont_err_lya, qso_z_Arr, qso_lya_lines, N_nb=0\n",
    ")\n",
    "\n",
    "sf_cont_est_lya, sf_cont_err_lya = estimate_continuum(sf_flx, sf_err, IGM_T_correct=True)\n",
    "sf_line = is_there_line(sf_flx, sf_err, sf_cont_est_lya, sf_cont_err_lya, 30)\n",
    "sf_lya_lines, sf_lya_cont_lines, _ = identify_lines(\n",
    "    sf_line, sf_flx, sf_err, first=True, return_line_width=True\n",
    ")\n",
    "\n",
    "sf_z_Arr = np.zeros(len(sf_zspec))\n",
    "sf_z_Arr[np.where(np.array(sf_lya_lines) != -1)] =\\\n",
    "    z_NB(np.array(sf_lya_cont_lines)[np.where(np.array(sf_lya_lines) != -1)])\n",
    "\n",
    "_, _, L_sf_Arr, _, _, _ = EW_L_NB(\n",
    "    sf_flx, sf_err, sf_cont_est_lya, sf_cont_err_lya, sf_z_Arr, sf_lya_lines, N_nb=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_qso_flx, sampled_qso_err, sampled_qso_L, sampled_qso_zspec, qso_labels =\\\n",
    "    set_prep(qso_flx, qso_err, qso_L_lya, L_qso_Arr, qso_zspec, len(qso_L_lya))\n",
    "sampled_sf_flx, sampled_sf_err, sampled_sf_L, sampled_sf_zspec, sf_labels =\\\n",
    "    set_prep(sf_flx, sf_err, sf_L_lya, L_sf_Arr, sf_zspec, len(sf_L_lya))\n",
    "\n",
    "dataset_qso = np.hstack(\n",
    "    (\n",
    "        sampled_qso_flx[2:55].T,\n",
    "        sampled_qso_flx[-3:].T,\n",
    "        np.abs(sampled_qso_err[2:55].T / sampled_qso_flx[2:55].T),\n",
    "        np.abs(sampled_qso_err[-3:].T / sampled_qso_flx[-3:].T),\n",
    "        sampled_qso_L.reshape(-1, 1),\n",
    "        sampled_qso_zspec.reshape(-1, 1)\n",
    "    )\n",
    ")\n",
    "dataset_sf = np.hstack(\n",
    "    (\n",
    "        sampled_sf_flx[2:55].T,\n",
    "        sampled_sf_flx[-3:].T,\n",
    "        np.abs(sampled_sf_err[2:55].T / sampled_sf_flx[2:55].T),\n",
    "        np.abs(sampled_sf_err[-3:].T / sampled_sf_flx[-3:].T),\n",
    "        sampled_sf_L.reshape(-1, 1),\n",
    "        sampled_sf_zspec.reshape(-1, 1)\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = np.vstack([dataset_qso, dataset_sf])\n",
    "labels = np.concatenate([qso_labels, sf_labels])\n",
    "\n",
    "# Shuffle\n",
    "perm = np.random.permutation(dataset.shape[0])\n",
    "dataset = dataset[perm]\n",
    "\n",
    "where = np.isfinite(dataset[:, -2]) & (labels > 43)\n",
    "\n",
    "dataset = dataset[where]\n",
    "\n",
    "labels = labels[perm][where]\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset).to_csv(f'MLmodels/datasets/dataset_magAll_{t_or_t}.csv')\n",
    "pd.DataFrame(labels).to_csv(f'MLmodels/datasets/tags_magAll_{t_or_t}.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
