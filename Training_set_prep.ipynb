{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from my_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_central = central_wavelength()\n",
    "nb_fwhm_Arr = nb_fwhm(range(60))\n",
    "w_lya = 1215.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SF catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/LAE_10deg_z2-4_0/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "sf_flx = data.to_numpy()[:, 1 : 60 + 1].T\n",
    "sf_err = data.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "## Load my QSO catalog\n",
    "\n",
    "filename = '/home/alberto/almacen/Source_cats/QSO_100000_0/'\n",
    "files = glob.glob(filename +'data*')\n",
    "files.sort()\n",
    "fi = []\n",
    "\n",
    "for name in files:\n",
    "    fi.append(pd.read_csv(name))\n",
    "\n",
    "data_qso = pd.concat(fi, axis=0, ignore_index=True)\n",
    "\n",
    "qso_flx = data_qso.to_numpy()[:, 1 : 60 + 1].T\n",
    "qso_err = data_qso.to_numpy()[:, 60 + 1 : 120 + 1].T\n",
    "\n",
    "sf_L = data['L_lya'].to_numpy()\n",
    "qso_L = data_qso['L_lya'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_lya_search(flx, err, L_lya, mag_min, mag_max):\n",
    "    # Lya search\n",
    "    cont_est_lya, cont_err_lya = estimate_continuum(flx, err, IGM_T_correct=True)\n",
    "    line = is_there_line(flx, err, cont_est_lya, cont_err_lya, 20)\n",
    "    lya_lines, lya_cont_lines, _ = identify_lines(\n",
    "        line, flx, err, first=True, return_line_width=True\n",
    "    )\n",
    "    lya_lines = np.array(lya_lines)\n",
    "\n",
    "    # Other lines\n",
    "    cont_est_other, cont_err_other = estimate_continuum(flx, err, IGM_T_correct=False)\n",
    "    line_other = is_there_line(flx, err, cont_est_other, cont_err_other,\n",
    "        400, obs=True)\n",
    "    other_lines = identify_lines(line_other, flx, err)\n",
    "\n",
    "    # Compute z\n",
    "    N_sources = flx.shape[1]\n",
    "    z_Arr = np.zeros(N_sources)\n",
    "    z_Arr[np.where(np.array(lya_lines) != -1)] =\\\n",
    "        z_NB(np.array(lya_cont_lines)[np.where(np.array(lya_lines) != -1)])\n",
    "\n",
    "    nb_min = 3\n",
    "    nb_max = 20\n",
    "\n",
    "    z_min = (w_central[nb_min] - nb_fwhm_Arr[nb_min] * 0.5) / w_lya - 1\n",
    "    z_max = (w_central[nb_max] + nb_fwhm_Arr[nb_max] * 0.5) / w_lya - 1\n",
    "\n",
    "    z_cut = (z_min < z_Arr) & (z_Arr < z_max)\n",
    "\n",
    "    mag = flux_to_mag(flx[-2], w_central[-2])\n",
    "    mag[np.isnan(mag)] = 99.\n",
    "\n",
    "    nice_lya = nice_lya_select(\n",
    "        lya_lines, other_lines, flx, err, cont_est_lya, z_Arr\n",
    "    )\n",
    "    # nice_lya = (nice_lya & z_cut & (L_lya > 0))\n",
    "    nice_lya = z_cut & (L_lya > 0) & (mag > mag_min) & (mag < mag_max) & nice_lya\n",
    "\n",
    "\n",
    "    _, _, L_Arr, _, _, _ = EW_L_NB(\n",
    "        flx, err, cont_est_lya, cont_err_lya, z_Arr, lya_lines, N_nb=0\n",
    "    )\n",
    "\n",
    "    return nice_lya, z_Arr, L_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sources(flx, err, L_lya, mag_min, mag_max, N_samples=100_000):\n",
    "    out_flx = np.array([])\n",
    "    n_iter = 0\n",
    "    while True:\n",
    "        n_iter += 1\n",
    "        # print(f'n_iter = {n_iter}')\n",
    "        this_flx = flx + err * np.random.normal(size=err.shape)\n",
    "\n",
    "        this_nice_lya, this_z_Arr, this_L_Arr = nice_lya_search(\n",
    "            this_flx, err, L_lya, mag_min, mag_max\n",
    "        )\n",
    "\n",
    "        if len(out_flx) == 0:\n",
    "            out_flx = flx[:, this_nice_lya]\n",
    "            out_err = err[:, this_nice_lya]\n",
    "            out_z = this_z_Arr[this_nice_lya]\n",
    "            out_L = this_L_Arr[this_nice_lya]\n",
    "            out_L_lya = L_lya[this_nice_lya]\n",
    "        else:\n",
    "            out_flx = np.hstack((out_flx, this_flx[:, this_nice_lya]))\n",
    "            out_err = np.hstack((out_err, err[:, this_nice_lya]))\n",
    "            out_z = np.concatenate((out_z, this_z_Arr[this_nice_lya]))\n",
    "            out_L = np.concatenate((out_L, this_L_Arr[this_nice_lya]))\n",
    "            out_L_lya = np.concatenate((out_L_lya, L_lya[this_nice_lya]))\n",
    "        \n",
    "        print(f'Sampled {len(out_z)} / {N_samples}')\n",
    "        \n",
    "        if len(out_z) >= N_samples:\n",
    "            break\n",
    "\n",
    "    randomize = np.random.choice(np.arange(0, len(out_L)), N_samples)\n",
    "\n",
    "    out_flx = out_flx[:, randomize]\n",
    "    out_err = out_err[:, randomize]\n",
    "    out_z = out_z[randomize]\n",
    "    out_L = out_L[randomize]\n",
    "    out_L_lya = out_L_lya[randomize]\n",
    "\n",
    "    return out_flx, out_err, out_z, out_L, out_L_lya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_dataset(N_samples, mag_min, mag_max):\n",
    "    N_sources = qso_flx.shape[1]\n",
    "    random_perm = np.random.permutation(np.arange(N_sources))\n",
    "\n",
    "    dataset = np.array([]).reshape(0, 120)\n",
    "    L_labels = np.array([])\n",
    "\n",
    "    n_folds = 5\n",
    "    N_sources_k = N_sources // n_folds\n",
    "    N_samples_k = N_samples // n_folds\n",
    "    for k in range(n_folds):\n",
    "        print(f'Fold #{k + 1}')\n",
    "        fold_idx = random_perm[k * N_sources_k : (k + 1) * N_sources_k]\n",
    "\n",
    "        sf_flx_data, sf_err_data, sf_z_data, sf_L_data, sf_L_Lya_data =\\\n",
    "            sample_sources(\n",
    "                sf_flx[:, fold_idx], sf_err[:, fold_idx], sf_L[fold_idx],\n",
    "                mag_min, mag_max, N_samples_k // 2\n",
    "            )\n",
    "        qso_flx_data, qso_err_data, qso_z_data, qso_L_data, qso_L_Lya_data =\\\n",
    "            sample_sources(\n",
    "                qso_flx[:, fold_idx], qso_err[:, fold_idx], qso_L[fold_idx],\n",
    "                mag_min, mag_max, N_samples_k // 2\n",
    "            )\n",
    "\n",
    "        pm_flx = np.hstack((qso_flx_data, sf_flx_data))\n",
    "        pm_err = np.hstack((qso_err_data, sf_err_data))\n",
    "        z_Arr = np.concatenate((qso_z_data, sf_z_data))\n",
    "        L_Arr = np.concatenate((qso_L_data, sf_L_data))\n",
    "\n",
    "        L_labels_k = np.concatenate((qso_L_Lya_data, sf_L_Lya_data))\n",
    "\n",
    "        dataset_k = np.hstack(\n",
    "            (\n",
    "                pm_flx[:55].T,\n",
    "                pm_flx[-4:].T,\n",
    "                np.abs(pm_err[:55].T / pm_flx[:55].T),\n",
    "                np.abs(pm_err[-4:].T / pm_flx[-4:].T),\n",
    "                L_Arr.reshape(-1, 1),\n",
    "                z_Arr.reshape(-1, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset = np.vstack((dataset, dataset_k))\n",
    "        L_labels = np.concatenate((L_labels, L_labels_k))\n",
    "\n",
    "    return dataset, L_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_min_list = [15, 23, 23.5]\n",
    "mag_max_list = [23, 23.5, 24]\n",
    "\n",
    "for mag_min, mag_max in zip(mag_min_list, mag_max_list):\n",
    "    print(f'Ensembling dataset mag{mag_min}-{mag_max}')\n",
    "    dataset, L_tags = ensemble_dataset(100_000, mag_min, mag_max)\n",
    "\n",
    "    pd.DataFrame(dataset).to_csv(f'MLmodels/datasets/dataset_mag{mag_min}-{mag_max}_5fold_nice_train.csv')\n",
    "    pd.DataFrame(L_tags).to_csv(f'MLmodels/datasets/tags_mag{mag_min}-{mag_max}_5fold_nice_train.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ade4bca3e0042e0da78fecdb82351169c0f2ccedb06a0d7cf7342df8f7e47af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
